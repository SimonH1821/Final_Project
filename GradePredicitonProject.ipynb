{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# School grade prediction project\n",
    "\n",
    "For this project I will be looking to create a model to predict student grades initially based on the Portugause school data set which I found here:\n",
    "https://data.world/uci/student-performance/workspace/file?filename=student-mat.csv# \n",
    "The aim of the model will be to predict if a student is below a given grade. This is so that education providers are able to see which students are likely to need assistance to attain basic passing grades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the start of the project I will perform analysis on the data to understand what is happening, correlations etc. This may also involve removal of certain columns that may no add value to the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the data from the file\n",
    "\n",
    "analysis_df = pd.read_csv(\"D:\\Simon\\Documents\\Degree\\CondaPlace\\envs\\SchoolGradePredict\\student-mat.csv\", delimiter = \";\")\n",
    "#check the dataframe has data in it.\n",
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attributes for both student-mat.csv (Math course)datasets:\n",
    "1 school - student's school (binary: \"GP\" - Gabriel Pereira or \"MS\" - Mousinho da Silveira) \n",
    "2 sex - student's sex (binary: \"F\" - female or \"M\" - male)\n",
    "3 age - student's age (numeric: from 15 to 22)\n",
    "4 address - student's home address type (binary: \"U\" - urban or \"R\" - rural)\n",
    "5 famsize - family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n",
    "6 Pstatus - parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n",
    "7 Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "8 Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "9 Mjob - mother's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "10 Fjob - father's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "11 reason - reason to choose this school (nominal: close to \"home\", school \"reputation\", \"course\" preference or \"other\")\n",
    "12 guardian - student's guardian (nominal: \"mother\", \"father\" or \"other\")\n",
    "13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "16 schoolsup - extra educational support (binary: yes or no)\n",
    "17 famsup - family educational support (binary: yes or no)\n",
    "18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "19 activities - extra-curricular activities (binary: yes or no)\n",
    "20 nursery - attended nursery school (binary: yes or no)\n",
    "21 higher - wants to take higher education (binary: yes or no)\n",
    "22 internet - Internet access at home (binary: yes or no)\n",
    "23 romantic - with a romantic relationship (binary: yes or no)\n",
    "24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "29 health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "30 absences - number of school absences (numeric: from 0 to 93)\n",
    "\n",
    "# these grades are related with the course subject, Math or Portuguese:\n",
    "31 G1 - first period grade (numeric: from 0 to 20)\n",
    "31 G2 - second period grade (numeric: from 0 to 20)\n",
    "32 G3 - final grade (numeric: from 0 to 20, output target)\n",
    "\n",
    "The list is above from: https://data.world/uci/student-performance/workspace/file?filename=student.txt and details what each of the columns are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 33 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   school      395 non-null    object\n",
      " 1   sex         395 non-null    object\n",
      " 2   age         395 non-null    int64 \n",
      " 3   address     395 non-null    object\n",
      " 4   famsize     395 non-null    object\n",
      " 5   Pstatus     395 non-null    object\n",
      " 6   Medu        395 non-null    int64 \n",
      " 7   Fedu        395 non-null    int64 \n",
      " 8   Mjob        395 non-null    object\n",
      " 9   Fjob        395 non-null    object\n",
      " 10  reason      395 non-null    object\n",
      " 11  guardian    395 non-null    object\n",
      " 12  traveltime  395 non-null    int64 \n",
      " 13  studytime   395 non-null    int64 \n",
      " 14  failures    395 non-null    int64 \n",
      " 15  schoolsup   395 non-null    object\n",
      " 16  famsup      395 non-null    object\n",
      " 17  paid        395 non-null    object\n",
      " 18  activities  395 non-null    object\n",
      " 19  nursery     395 non-null    object\n",
      " 20  higher      395 non-null    object\n",
      " 21  internet    395 non-null    object\n",
      " 22  romantic    395 non-null    object\n",
      " 23  famrel      395 non-null    int64 \n",
      " 24  freetime    395 non-null    int64 \n",
      " 25  goout       395 non-null    int64 \n",
      " 26  Dalc        395 non-null    int64 \n",
      " 27  Walc        395 non-null    int64 \n",
      " 28  health      395 non-null    int64 \n",
      " 29  absences    395 non-null    int64 \n",
      " 30  G1          395 non-null    int64 \n",
      " 31  G2          395 non-null    int64 \n",
      " 32  G3          395 non-null    int64 \n",
      "dtypes: int64(16), object(17)\n",
      "memory usage: 102.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#list the info for the columns to understand the datatypes of each one. \n",
    "analysis_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that there are a number of columns that are not integers and will be difficult to work with. \n",
    "\n",
    "For these will look how many columns will need transformation into an integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic'] 17\n"
     ]
    }
   ],
   "source": [
    "#loop over all of the columns in the dataframe that are not of the integer data type\n",
    "non_int_columns = [column for column in analysis_df.columns if analysis_df[column].dtype != 'int64']\n",
    "#print out the list of items and the cound of items that are not integers\n",
    "print(non_int_columns,len(non_int_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP    349\n",
      "MS     46\n",
      "Name: school, dtype: int64\n",
      "F    208\n",
      "M    187\n",
      "Name: sex, dtype: int64\n",
      "U    307\n",
      "R     88\n",
      "Name: address, dtype: int64\n",
      "GT3    281\n",
      "LE3    114\n",
      "Name: famsize, dtype: int64\n",
      "T    354\n",
      "A     41\n",
      "Name: Pstatus, dtype: int64\n",
      "other       141\n",
      "services    103\n",
      "at_home      59\n",
      "teacher      58\n",
      "health       34\n",
      "Name: Mjob, dtype: int64\n",
      "other       217\n",
      "services    111\n",
      "teacher      29\n",
      "at_home      20\n",
      "health       18\n",
      "Name: Fjob, dtype: int64\n",
      "course        145\n",
      "home          109\n",
      "reputation    105\n",
      "other          36\n",
      "Name: reason, dtype: int64\n",
      "mother    273\n",
      "father     90\n",
      "other      32\n",
      "Name: guardian, dtype: int64\n",
      "no     344\n",
      "yes     51\n",
      "Name: schoolsup, dtype: int64\n",
      "yes    242\n",
      "no     153\n",
      "Name: famsup, dtype: int64\n",
      "no     214\n",
      "yes    181\n",
      "Name: paid, dtype: int64\n",
      "yes    201\n",
      "no     194\n",
      "Name: activities, dtype: int64\n",
      "yes    314\n",
      "no      81\n",
      "Name: nursery, dtype: int64\n",
      "yes    375\n",
      "no      20\n",
      "Name: higher, dtype: int64\n",
      "yes    329\n",
      "no      66\n",
      "Name: internet, dtype: int64\n",
      "no     263\n",
      "yes    132\n",
      "Name: romantic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#list over the columns to identify the counts for each value. \n",
    "for col in non_int_columns:\n",
    "    print(analysis_df[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this I am not able to see all of the items in the list so cannot verify the data when it is transformed. As such I will list out the unique values with the column name to see what the options are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GP' 'MS'] school\n",
      "['F' 'M'] sex\n",
      "['U' 'R'] address\n",
      "['GT3' 'LE3'] famsize\n",
      "['A' 'T'] Pstatus\n",
      "['at_home' 'health' 'other' 'services' 'teacher'] Mjob\n",
      "['teacher' 'other' 'services' 'health' 'at_home'] Fjob\n",
      "['course' 'other' 'home' 'reputation'] reason\n",
      "['mother' 'father' 'other'] guardian\n",
      "['yes' 'no'] schoolsup\n",
      "['no' 'yes'] famsup\n",
      "['no' 'yes'] paid\n",
      "['no' 'yes'] activities\n",
      "['yes' 'no'] nursery\n",
      "['yes' 'no'] higher\n",
      "['no' 'yes'] internet\n",
      "['no' 'yes'] romantic\n"
     ]
    }
   ],
   "source": [
    "for col in non_int_columns:\n",
    "    print(analysis_df[col].unique(),col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GP    349\n",
      "MS     46\n",
      "Name: school, dtype: int64, F    208\n",
      "M    187\n",
      "Name: sex, dtype: int64, U    307\n",
      "R     88\n",
      "Name: address, dtype: int64, GT3    281\n",
      "LE3    114\n",
      "Name: famsize, dtype: int64, T    354\n",
      "A     41\n",
      "Name: Pstatus, dtype: int64, other       141\n",
      "services    103\n",
      "at_home      59\n",
      "teacher      58\n",
      "health       34\n",
      "Name: Mjob, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "#create a list of items that can be iterated over to see the values for each of the non integer based items. \n",
    "val_counts = []\n",
    "for col in non_int_columns:\n",
    "    val_counts.append(analysis_df[col].value_counts())\n",
    "    \n",
    "\n",
    "#print out the first set. \n",
    "print(val_counts[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[other       217\n",
      "services    111\n",
      "teacher      29\n",
      "at_home      20\n",
      "health       18\n",
      "Name: Fjob, dtype: int64, course        145\n",
      "home          109\n",
      "reputation    105\n",
      "other          36\n",
      "Name: reason, dtype: int64, mother    273\n",
      "father     90\n",
      "other      32\n",
      "Name: guardian, dtype: int64, no     344\n",
      "yes     51\n",
      "Name: schoolsup, dtype: int64, yes    242\n",
      "no     153\n",
      "Name: famsup, dtype: int64, no     214\n",
      "yes    181\n",
      "Name: paid, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "#print out a second set of items\n",
    "print(val_counts[6:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[yes    201\n",
      "no     194\n",
      "Name: activities, dtype: int64, yes    314\n",
      "no      81\n",
      "Name: nursery, dtype: int64, yes    375\n",
      "no      20\n",
      "Name: higher, dtype: int64, yes    329\n",
      "no      66\n",
      "Name: internet, dtype: int64, no     263\n",
      "yes    132\n",
      "Name: romantic, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "#print out the final set of variables so that all can be verified. \n",
    "print(val_counts[12:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the list of all of the values I can convert them to integer values and verify that they feature the correct values. \n",
    "\n",
    "I will first do this by creating a new dataframe and then convert the items to integers so they are usable in the neural networks and machine learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new dataframe for the transformations and machine learning models.\n",
    "df_working = analysis_df.copy()\n",
    "df_working.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import items to do a linear regression model and encode the non integer columns.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 33 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   school      395 non-null    int32\n",
      " 1   sex         395 non-null    int32\n",
      " 2   age         395 non-null    int64\n",
      " 3   address     395 non-null    int32\n",
      " 4   famsize     395 non-null    int32\n",
      " 5   Pstatus     395 non-null    int32\n",
      " 6   Medu        395 non-null    int64\n",
      " 7   Fedu        395 non-null    int64\n",
      " 8   Mjob        395 non-null    int32\n",
      " 9   Fjob        395 non-null    int32\n",
      " 10  reason      395 non-null    int32\n",
      " 11  guardian    395 non-null    int32\n",
      " 12  traveltime  395 non-null    int64\n",
      " 13  studytime   395 non-null    int64\n",
      " 14  failures    395 non-null    int64\n",
      " 15  schoolsup   395 non-null    int32\n",
      " 16  famsup      395 non-null    int32\n",
      " 17  paid        395 non-null    int32\n",
      " 18  activities  395 non-null    int32\n",
      " 19  nursery     395 non-null    int32\n",
      " 20  higher      395 non-null    int32\n",
      " 21  internet    395 non-null    int32\n",
      " 22  romantic    395 non-null    int32\n",
      " 23  famrel      395 non-null    int64\n",
      " 24  freetime    395 non-null    int64\n",
      " 25  goout       395 non-null    int64\n",
      " 26  Dalc        395 non-null    int64\n",
      " 27  Walc        395 non-null    int64\n",
      " 28  health      395 non-null    int64\n",
      " 29  absences    395 non-null    int64\n",
      " 30  G1          395 non-null    int64\n",
      " 31  G2          395 non-null    int64\n",
      " 32  G3          395 non-null    int64\n",
      "dtypes: int32(17), int64(16)\n",
      "memory usage: 75.7 KB\n"
     ]
    }
   ],
   "source": [
    "#create a label encoder object. \n",
    "le = LabelEncoder()\n",
    "\n",
    "#loop over all of the non integer columns and transform them to integers \n",
    "for col in non_int_columns:\n",
    "    df_working[col] = le.fit_transform(df_working[col])\n",
    "\n",
    "#print the infor again and check they are all integers.\n",
    "df_working.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0    349\n",
      "1     46\n",
      "Name: school, dtype: int64, 0    208\n",
      "1    187\n",
      "Name: sex, dtype: int64, 1    307\n",
      "0     88\n",
      "Name: address, dtype: int64, 0    281\n",
      "1    114\n",
      "Name: famsize, dtype: int64, 1    354\n",
      "0     41\n",
      "Name: Pstatus, dtype: int64, 2    141\n",
      "3    103\n",
      "0     59\n",
      "4     58\n",
      "1     34\n",
      "Name: Mjob, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "#as per the above iteration of this I want to go through and verify the items that are in the list and confirm what the new items are\n",
    "val_counts_working = []\n",
    "for col in non_int_columns:\n",
    "    val_counts_working.append(df_working[col].value_counts())\n",
    "\n",
    "\n",
    "print(val_counts_working[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2    217\n",
      "3    111\n",
      "4     29\n",
      "0     20\n",
      "1     18\n",
      "Name: Fjob, dtype: int64, 0    145\n",
      "1    109\n",
      "3    105\n",
      "2     36\n",
      "Name: reason, dtype: int64, 1    273\n",
      "0     90\n",
      "2     32\n",
      "Name: guardian, dtype: int64, 0    344\n",
      "1     51\n",
      "Name: schoolsup, dtype: int64, 1    242\n",
      "0    153\n",
      "Name: famsup, dtype: int64, 0    214\n",
      "1    181\n",
      "Name: paid, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "print(val_counts_working[6:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1    201\n",
      "0    194\n",
      "Name: activities, dtype: int64, 1    314\n",
      "0     81\n",
      "Name: nursery, dtype: int64, 1    375\n",
      "0     20\n",
      "Name: higher, dtype: int64, 1    329\n",
      "0     66\n",
      "Name: internet, dtype: int64, 0    263\n",
      "1    132\n",
      "Name: romantic, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "print(val_counts_working[12:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New values translations\n",
    "\n",
    "|Category | Was | Mapped to|\n",
    "| --- | --- | --- |\n",
    "|School | GP | 0 |\n",
    "|School | MS | 1 |\n",
    "|Sex | F | 0 |\n",
    "|Sex | M | 1 |\n",
    "|Address | U | 1 |\n",
    "|Address | R | 0 |\n",
    "|Famsize | GT3 | 0 |\n",
    "|Famsize | LE3 | 1 |\n",
    "|Pstatus | A | 0 |\n",
    "|Pstatus | T | 1 |\n",
    "|Mjob | at_home | 0 |\n",
    "|Mjob | health | 1 |\n",
    "|Mjob | other | 2 |\n",
    "|Mjob | services | 3 |\n",
    "|Mjob | teacher | 4 |\n",
    "|Fjob | teacher | 4 |\n",
    "|Fjob | other | 2 |\n",
    "|Fjob | services | 3 |\n",
    "|Fjob | health | 1 |\n",
    "|Fjob | at_home | 0 |\n",
    "|Reason | course | 0 |\n",
    "|Reason | other | 2 |\n",
    "|Reason | home | 1 |\n",
    "|Reason | reputation | 3 |\n",
    "|Guardian | mother | 1 |\n",
    "|Guardian | father | 0 |\n",
    "|Guardian | other | 2 |\n",
    "|schoolsup | yes | 1 |\n",
    "|schoolsup | no | 0 |\n",
    "|Famsup | no | 0 |\n",
    "|Famsup | yes | 1 |\n",
    "|Paid | no | 0 |\n",
    "|Paid | yes | 1 |\n",
    "|Activities | no | 0 |\n",
    "|Activities | yes | 1 |\n",
    "|Nursery | yes | 1 |\n",
    "|Nursery | no | 0 |\n",
    "|Higher | yes | 1 |\n",
    "|Higher | no | 0 |\n",
    "|Internet | no | 0 |\n",
    "|Internet | yes | 1 |\n",
    "|Romantic | no | 0 |\n",
    "|Romantic | yes | 1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFMAAASMCAYAAABETMJrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAACt00lEQVR4nOzde7ymdVkv/s81wwzDSUBQ8zyaGBop4GiaaVjo1g5aaZnVLrIiK7XDzrSduU07mbXbedj6IzMs3WqHHZKa6FZJ8xCMgiAgSkipmIIgcmZm1vX7Yz3UcloDcztrvmutWe/36/W85n7u0+d7r3nWs9Zc872vp7o7AAAAAOyedcs9AAAAAIDVRDEFAAAAYALFFAAAAIAJFFMAAAAAJlBMAQAAAJhAMQUAAABgAsUUAAAAYFWqqtdW1Rer6uO72F5V9bKquqSqzquq45ciVzEFAAAAWK1OTfL429j+hCRHzR4nJ3nVUoQqpgAAAACrUne/L8lVt7HLk5L8ec/7cJLDquque5qrmAIAAADsq+6e5DMLnn92tm6P7LenJ9hXbLvy0h6V9bNbfnVUVJ6z6fphWd/2b5cNy/qpw44blnVLhr00ctb2K4ZlHbpu07CsTTXureYutf+wrEvnrhuWda91Bw3L+q4b1w/LetX+XxmW9eB1hw7LSpL3b/vCsKybevuwrGM23mlY1r/uuHZY1gG1YVjWkevGvU99evs1w7Ieud+dh2Vd2jcMy7prjft5eW12DMv6hrlxr8Mvr5sblnVp3zgs69reNizrjgPfN27pca/DSg3LSpL/8y9/OzZwoJH/nh1t452+/mcyf3vOrU7p7lOWazy3UkwBAAAAVqRZ4WRPiiefS3LPBc/vMVu3R9zmAwAAAOyrTk/yY7NP9Xl4kmu6+/N7elIzUwAAAIBVqaremOSEJEdW1WeT/I8kG5Kku1+d5O1JvjPJJUluSPITS5GrmAIAAACr2dy4XjcrTXc/7Xa2d5KfX+pct/kAAAAATKCYAgAAADCBYgoAAADABIopAAAAABNoQAsAAACrWc8t9wjWHDNTAAAAACZQTAEAAACYYEUWU6rqpKp6xRKd67KqOnIpzgUAAACgZwoAAACsZnN6pow2dGZKVR1UVW+rqo9V1cer6qlV9dCq+uBs3VlVdchs97tV1Tuq6lNV9fsLzvG0qjp/dvxLbm89AAAAwFIaPTPl8Uku7+7vSpKqOjTJOUme2t1nV9Udktw42/fYJMcluTnJxVX18iQ7krwkyUOSXJ3knVX1vUnOWmx9d5826LoAAACANWJ0z5Tzkzy2ql5SVY9Kcq8kn+/us5Oku7/S3dtn+767u6/p7puSXJjk3kkemuTM7r5itt8bkjz6NtYDAAAALKmhxZTu/mSS4zNfVPmtJN9/G7vfvGB5R/bCLJqqOrmqtlbV1tf8+RuX+vQAAACw13XP7bOPlWrobT5VdbckV3X366vqy0l+Lsldq+qhs9t8Dsl/3OazmLOSvGz26TxXJ3lakpffxvrb1N2nJDklSbZdeWl/7VcGAAAArBWje6Z8U5KXVtVckm1JfjZJJXl5VR2Q+ULKibs6uLs/X1XPS/Le2XFv6+63JMmu1gMAAAAspaHFlO4+I8kZi2x6+E7PT509bj3uuxcsvzHJf7on5zbWb/6aBgsAAACwiNEzUwAAAIClNLdye4vsq0Z/mg8AAADAqqaYAgAAADCBYgoAAADABIopAAAAABNoQAsAAACrWWtAO5qZKQAAAAATKKYAAAAATKCYAgAAADCBnikAAACwms3tWO4RrDlmpgAAAABMoJgCAAAAMIHbfGZ+dsuvDst61dbfH5b1U1ueMyzrvxz2wGFZ+3cNy7q2xn3M2Anr7zIs6ys1birg8beMe6u5dEMPy7ok47L+rW8alvXBAw4elvWBKy8elvXAIx86LGu0DbV+WNant18zLOtxA98TL62bh2VduO1Lw7IeuWHc1/CjO64elnXs+sOHZX3LTePe6z+y/8ZhWcfdvG1YVg38efl1Gw8alnXmuq8My7p/bxqWNfIDdjdk3O/0sNQUUwAAAGA165FlMBK3+QAAAABMopgCAAAAMIFiCgAAAMAEeqYAAADAajanZ8poZqYAAAAATKCYAgAAADCBYgoAAADABIopAAAAABNoQAsAAACrWLcGtKOZmQIAAAAwgWIKAAAAwASKKQAAAAATrJqeKVV1UJK/THKPJOuTvDjJJUn+Z5KDk1yZ5KQkNyQ5K8kTu/viqnpjkvd0958sx7gBAABgr5rTM2W0VVNMSfL4JJd393clSVUdmuTvkzypu6+oqqcm+e3ufnpVPTPJqVX1x0kOV0gBAAAAlspqKqacn+QPq+olSd6a5OokxyR5V1Ul87NVPp8k3f2uqvqBJK9M8uDlGS4AAACwL1o1xZTu/mRVHZ/kO5P8VpL3JLmgux+x875VtS7JAzJ/y8/hST672Dmr6uQkJyfJI+94XI4+5L57afQAAADAvmLVNKCtqrsluaG7X5/kpUm+OcmdquoRs+0bquobZ7v/UpKLkvxwkj+rqg2LnbO7T+nuLd29RSEFAACAVann9t3HCrVqZqYk+aYkL62quSTbkvxsku1JXjbrn7Jfkv9VVduT/FSSh3X3tVX1viTPT/I/lmncAAAAwD5k1RRTuvuMJGcssunRi6x7wILjfnmvDQoAAABYc1bNbT4AAAAAK8GqmZkCAAAALGJux3KPYM0xMwUAAABgAsUUAAAAgAkUUwAAAAAmUEwBAAAAmEADWgAAAFjNem65R7DmmJkCAAAAMIFiCgAAAMAEiikAAAAAE+iZAgAAAKvZnJ4po5mZAgAAADBBdfdyj2FFuPjoJwz7QvzOTQeOisprtr50WNa3P/inh2U9dMOdhmWN/A750C3/NjBtnLttuMOwrIMGTrjbUOPq0T9x07CovGvT/sOyvpBbhmU98caxkzF/bvsFw7LuvWnce+K99zt0WNaVczcOy9qv1g/LuvTmK4Zl3X3j4cOyfqCPHJZ1yX47hmVdn3H/2/v1cxuGZY38H9VtA7P+qa4dlvWd2w8ZlvW2/b4yLOsL268flrWtx30vJ8mHLz+zhgYOdPMF795n/2G//zd+x4r8ezMzBQAAAGACPVMAAABgNWs9U0YzMwUAAABgAsUUAAAAgAkUUwAAAAAm0DMFAAAAVrM5PVNGMzMFAAAAYALFFAAAAIAJFFMAAAAAJlBMAQAAAJhAA1oAAABYxbp3LPcQ1hwzUwAAAAAmUEwBAAAAmGDVFFOq6rSq+khVXVBVJ8/W/WRVfbKqzqqqP6mqV8zW36mq/qaqzp49Hrm8owcAAAD2FaupZ8rTu/uqqjogydlV9bYkv5Hk+CTXJnlPko/N9v3jJH/U3f9YVfdKckaSByzHoAEAAGCv6rnlHsGas2pmpiR5dlV9LMmHk9wzyX9N8g/dfVV3b0vyVwv2PTHJK6rq3CSnJ7lDVR288wmr6uSq2lpVW9/85c/s/SsAAAAAVr1VMTOlqk7IfIHkEd19Q1WdmeQT2fVsk3VJHt7dN93Webv7lCSnJMnFRz+hl2q8AAAAwL5rtcxMOTTJ1bNCytFJHp7koCTfVlWHV9V+SZ68YP93JnnWrU+q6tiRgwUAAAD2XatiZkqSdyR5RlVdlOTizN/q87kkv5PkrCRXZX6myjWz/Z+d5JVVdV7mr/F9SZ4xetAAAACw183pmTLaqiimdPfNSZ6w8/qq2trdp8xmpvxtktNm+1+Z5KlDBwkAAACsCavlNp9deeGsyezHk3w6s2IKAAAAwN6yKmam7Ep3/8pyjwEAAABYW1Z1MQUAAADWvNYzZbTVfpsPAAAAwFCKKQAAAAATKKYAAAAATKCYAgAAADCBBrQAAACwms3tWO4RrDlmpgAAAABMoJgCAAAAMIFiCgAAAMAEeqYAAADAatZzyz2CNae6e7nHsCJ83WEPGPaF+C+HPXBUVC7d9uVhWe/52J8My3rxlt8YlnVJ3zAs6xFzBw3LumL9uO/9g7uGZf1z3Tws6yu9bVhWZdzX8C1XnDMs6wfv/JBhWV+eu2VYVpLca9247+eRNg18Lf5r3zgs67514LCsmzPu/ffhN4+bhPzu/ce9J64f+DrcODDrwIGTxs+du2ZY1o6B/8g7Yt0Bw7LW17jXxj2z/7CsI+bGvQ5vHvclTJI8719ePzhxnJvO+qt99h/2mx72Ayvy781tPgAAAAATKKYAAAAATKBnCgAAAKxmc3qmjGZmCgAAAMAEiikAAAAAEyimAAAAAEygZwoAAACsZgM/gpx5ZqYAAAAATKCYAgAAADCBYgoAAADABIopAAAAABMsSwPaqjopyZbufuYi267r7oPHjwoAAABWoTkNaEdbFTNTqsqnDgEAAAArwl4pplTVaVX1kaq6oKpOnq37iar6ZFWdleSRC/a9T1V9qKrOr6rfWrD+hKp6f1WdnuTCqlpfVS+tqrOr6ryq+pnZfnetqvdV1blV9fGqetRs31Nnz8+vql/aG9cJAAAArD17a8bH07v7qqo6IMnZVfW2JL+Z5CFJrkny3iTnzPb94ySv6u4/r6qf3+k8xyc5prs/PSvKXNPdD62q/ZN8oKremeT7k5zR3b9dVeuTHJjk2CR37+5jkqSqDttL1wkAAACsMXurmPLsqvq+2fI9k/zXJGd29xVJUlVvTnL/2fZHJnnybPkvkrxkwXnO6u5Pz5Yfl+RBVfWU2fNDkxyV5Owkr62qDUlO6+5zq+rSJPetqpcneVuSdy42yFmB5uQkOeSAr8uBGw/bg0sGAACAZaBnynBLfptPVZ2Q5MQkj+juB2d+Bsonbuew3sX66xeeOsmzuvvY2eM+3f3O7n5fkkcn+VySU6vqx7r76iQPTnJmkmckec2iod2ndPeW7t6ikAIAAADsjr3RM+XQJFd39w1VdXSShyc5IMm3VdURsxkkP7Bg/w8k+aHZ8o/cxnnPSPKzs+NTVfevqoOq6t5JvtDdf5L5osnxVXVkknXd/TdJnp/524UAAAAA9tjeuM3nHUmeUVUXJbk4yYeTfD7JC5N8KMmXk5y7YP9fSPJ/quq5Sd5yG+d9TZLNST5aVZXkiiTfm+SEJM+pqm1JrkvyY0nunuTPqurWYtGv7fFVAQAAAGQvFFO6++YkT1hk05lJ/myR/T+d5BELVj1/tv7M2TG37jeX5L/PHgu9bvbYmdkoAAAA7PO6dyz3ENacvfLRyAAAAAD7KsUUAAAAgAkUUwAAAAAm2BsNaAEAAIBR5uaWewRrjpkpAAAAABMopgAAAABMoJgCAAAAMIFiCgAAAMAEGtACAADAatYa0I5mZgoAAADABIopAAAAABMopgAAAABMoGfKzE8ddtywrP27hmUdseFOw7JevOU3hmX9xtYXD8s64cE/NSxr5HfktoH3VT6gDh6WdfncjcOy7rRu07CsDRn3vvGLd/6WYVkXzl07LOvwdfsPy0qSL2fbsKzP77h+WNa91o/7fr5DbRiWdUiP+/+lL9bNw7LeNfBlf1DWD8u6euD317qBP5yvzbifzY+sw4dl1bgfYbmoxv0ecETGvUetG/h7wLXVw7JYQnN6poxmZgoAAADABIopAAAAABMopgAAAABMoGcKAAAArGYD+yEyz8wUAAAAgAkUUwAAAAAmUEwBAAAAmEDPFAAAAFjN5vRMGc3MFAAAAIAJFFMAAAAAJtgrxZSqenZVXVRVb9gL535iVT1vqc8LAAAAsDv2Vs+Un0tyYnd/dqlP3N2nJzl9qc8LAAAAq1LrmTLaks9MqapXJ7lvkr+vqudW1Yeq6pyq+mBVfcNsn5Oq6rSqeldVXVZVz6yqX57t9+GquuNsv2dX1YVVdV5VvWnBsa+YLZ+74HFjVX1bVR1UVa+tqrNm53vSUl8jAAAAsHYt+cyU7n5GVT0+yWOS3JLkD7t7e1WdmOR3kjx5tusxSY5LsinJJUme293HVdUfJfmxJP8ryfOS3Ke7b66qwxbJOjZJqup7kvxqkg8m+c0k7+nup8+OOauq/l93X7/U1woAAACsPXv7o5EPTfK6qjoqSSfZsGDbe7v72iTXVtU1Sf5utv78JA+aLZ+X5A1VdVqS0xYLmJ37pUke093bqupxSZ5YVb8y22VTknsluWjJrgoAAABYs/b2p/m8OPNFk2OSfE/mCxu3unnB8tyC53P5jyLPdyV5ZZLjk5xdVV9V/Kmqg5P8ZZKf7u7P37o6yZO7+9jZ417dvWghpapOrqqtVbX1o9de8rVfJQAAALBm7O1iyqFJPjdbPmnKgVW1Lsk9u/u9SZ47O9fBO+322iR/1t3vX7DujCTPqqqanee4XWV09yndvaW7txx/yP2mDA8AAABWhrm5ffexQu3tYsrvJ/ndqjon028pWp/k9VV1fpJzkrysu79868aquneSpyR5+oImtFsyPxtmQ5LzquqC2XMAAACAJbFXeqZ09+bZ4pVJ7r9g0/Nn209Ncuoi+++87VsXOffC7bsqBv3MpAEDAAAA7Ka9PTMFAAAAYJ+ytz/NBwAAANibVnBvkX2VmSkAAAAAEyimAAAAAEygmAIAAACsSlX1+Kq6uKouqarnLbL9XlX13qo6p6rOq6rvXIpcPVMAAABgNeu12TOlqtYneWWSxyb5bJKzq+r07r5wwW7PT/KX3f2qqnpgkrcn2byn2WamAAAAAKvRw5Jc0t2XdvctSd6U5Ek77dNJ7jBbPjTJ5UsRbGYKAAAAsBrdPclnFjz/bJJv3mmfFyZ5Z1U9K8lBSU5cimAzUwAAAIAVqapOrqqtCx4nTzzF05Kc2t33SPKdSf6iqva4FmJmCgAAAKxmc/tuz5TuPiXJKbvY/Lkk91zw/B6zdQv9ZJLHz871oaralOTIJF/ck3GZmQIAAACsRmcnOaqq7lNVG5P8UJLTd9rnX5N8R5JU1QOSbEpyxZ4GK6YAAAAAq053b0/yzCRnJLko85/ac0FVvaiqnjjb7b8l+emq+liSNyY5qbt7T7Pd5gMAAACsSt399sx/3PHCdS9YsHxhkkcuda5iyswt2ePC1G67tsbdzzZy6tElfcOwrBMe/FPDss782GuGZT3+2GcMyzpw3cZhWRfn+mFZR607eFjW9dkxLOuyHdcNyzpw/aHDsu617qBhWTcN/PtKkpt6XN7RA//ONg38yXJ4rx+W9Y999bCsw7L/sKz71gHDsi7tG4dlHVHjfoZtSA3LGvlz5RM17u/rwIz7Xj4sG4ZlfXT7lcOy7rvfYcOybsm4f6vcPPhnMywlxRQAAABYzXrfbUC7UumZAgAAADCBYgoAAADABIopAAAAABPomQIAAACr2ZyeKaOZmQIAAAAwgWIKAAAAwASKKQAAAAAT6JkCAAAAq1nrmTKamSkAAAAAE+zVYkpV7aiqc6vq41X1V1V14G3s+99385y7tR8AAADA3rC3Z6bc2N3HdvcxSW5J8ozb2Hd3iySKKQAAAMCyGXmbz/uT3K+q7lpV71swY+VRVfV7SQ6YrXtDklTVaVX1kaq6oKpOnq37qv2qanNVffzWgKr6lap64Wz52VV1YVWdV1VvGnidAAAAMM7c3L77WKGGNKCtqv2SPCHJO5L8cJIzuvu3q2p9kgO7+/1V9czuPnbBYU/v7quq6oAkZ1fV33T38xbuV1WbbyP2eUnu0903V9Vhe+GyAAAAgDVobxdTDqiqc2fL70/yp0kenuS1VbUhyWndfe4ujn12VX3fbPmeSY5K8qUJ2ecleUNVnZbktGnDBgAAAFjcqJ4px3b3s7r7lu5+X5JHJ/lcklOr6sd2PqiqTkhyYpJHdPeDk5yTZNMi59+er76Ghft8V5JXJjk+8zNb/lPhqKpOrqqtVbX1Y9de8rVdIQAAALCmDP9o5Kq6d5IvdPefJHlN5osdSbJtNlslSQ5NcnV331BVR2d+NksW2e8LSe5cVUdU1f5JvnuWsS7JPbv7vUmeOzvfwTuPpbtP6e4t3b3lwYfcb4mvFAAAANgXDemZspMTkjynqrYluS7JrTNTTklyXlV9NMnTkzyjqi5KcnGSDy84/t/36+4fqaoXJTkr8zNdPjHbZ32S11fVoUkqycu6+8t797IAAABgGazgRq37qr1aTOnuxWaDvC7J6xZZ/9zMzyK51RN2cc6v2q+7X5bkZYvs+q1TxwsAAABwe4bf5gMAAACwmimmAAAAAEywHD1TAAAAgKXSvdwjWHPMTAEAAACYQDEFAAAAYALFFAAAAIAJ9EwBAACA1WxubrlHsOaYmQIAAAAwgWIKAAAAwASKKQAAAAAT6JkCAAAAq5meKcOZmQIAAAAwgWIKAAAAwARu85k5a/sVw7JOWH+XYVnv2Pa5YVk/sv4ew7JGvnIff+wzhmW949xXD8u65Y+fNyzruvd/cVjWaZeMex1eu27cC/GW9eOmbv7jLZcPy/ovG8f9fb31uk8Oy0qSbzlo87CsLds2DMu6sYZF5Zr147Ketv3wYVk3DfyvrAPneljWDRv3H5Z1bbYPy1qXcS/EOw78BWdDxn0zX9E3D8uqgdf1X9Z/3bCs+9487nt54FsvrGpmpgAAAABMYGYKAAAArGatAe1oZqYAAAAATKCYAgAAADCBYgoAAADABHqmAAAAwGo2p2fKaGamAAAAAEygmAIAAAAwgWIKAAAAwAR6pgAAAMBq1r3cI1hzln1mSlV1Vb1+wfP9quqKqnrrxPOcWVVbln6EAAAAAP9h2YspSa5PckxVHTB7/tgkn1vG8QAAAADs0koopiTJ25N812z5aUneeOuGqjqoql5bVWdV1TlV9aTZ+gOq6k1VdVFV/W2SAxYcc92C5adU1alDrgIAAADY562UnilvSvKC2a09D0ry2iSPmm379STv6e6nV9VhSc6qqv+X5GeS3NDdD6iqByX56DKMGwAAAJbX3Nxyj2DNWRHFlO4+r6o2Z35Wytt32vy4JE+sql+ZPd+U5F5JHp3kZQuOP2/QcAEAAIA1bEUUU2ZOT/IHSU5IcsSC9ZXkyd198cKdq+q2zrWwlfGmXe1UVScnOTlJjjrs6NztoLtPGzEAAACw5qyUninJ/K09v9nd5++0/owkz6pZ9aSqjputf1+SH56tOybztwfd6gtV9YCqWpfk+3YV2N2ndPeW7t6ikAIAAADsjhVTTOnuz3b3yxbZ9OIkG5KcV1UXzJ4nyauSHFxVFyV5UZKPLDjmeUnemuSDST6/90YNAAAArDXLfptPdx+8yLozk5w5W74x881md97nxiQ/tItz/nWSv17KcQIAAMCKpAHtcCtmZgoAAADAaqCYAgAAADCBYgoAAADABMveMwUAAADYA61nymhmpgAAAABMoJgCAAAAMIFiCgAAAMAEeqYAAADAKtZzvdxDWHPMTAEAAACYQDEFAAAAYALFFAAAAIAJ9EwBAACA1WxubrlHsOaYmQIAAAAwgZkpM4eu2zQs6yu1Y1jWSFesH9dBeluPq7weuG7jsKxb/vh5w7I2/sLvDcvaesqvD8u6w8DX4af2G/c6/PT2a4Zl7Vfrh2V9IduGZW3v7cOykuRONe69Y6QvDvweO6BrWNZ1A/97aePAD1z4t/3GfQ1vyr75v6LXZtx7x/psGJa1LeNeiAfVuH9ybMq4n2H/NvC1cc+BX8OvDHw/3DHuLQqWnJkpAAAAABMopgAAAABM4DYfAAAAWM0GtkFgnpkpAAAAABMopgAAAABMoJgCAAAAMIGeKQAAALCazY37uHPmmZkCAAAAMIFiCgAAAMAEiikAAAAAE6y4nilVtSPJ+QtWfW93X7Ybx21O8tbuPmYvDQ0AAABWnrm55R7BmrPiiilJbuzuY5d7EAAAAACLWRW3+VTVQ6rqH6rqI1V1RlXddcH6j1XVx5L8/IL9T6qqVyx4/taqOmH4wAEAAIB9zkosphxQVefOHn9bVRuSvDzJU7r7IUlem+S3Z/v+WZJndfeDl2uwAAAAwNqy4m/zqapjkhyT5F1VlSTrk3y+qg5Lclh3v2+2618kecLYoQIAAMAy0zNluJVYTNlZJbmgux/xVSvniym7sj1fPetm06Inrjo5yclJ8qDDvymbD77Xno0UAAAA2OetxNt8dnZxkjtV1SOSpKo2VNU3dveXk3y5qr51tt+PLDjmsiTHVtW6qrpnkoctduLuPqW7t3T3FoUUAAAAYHes+Jkp3X1LVT0lycuq6tDMj/l/JbkgyU8keW1VdZJ3LjjsA0k+neTCJBcl+ejQQQMAAAD7rBVXTOnugxdZd26SRy+y/iNJFjaf/dXZ+s5Xz1QBAAAAWBIrrpgCAAAATNC93CNYc1ZDzxQAAACAFUMxBQAAAGACxRQAAACACfRMAQAAgNVsbm65R7DmmJkCAAAAMIFiCgAAAMAEiikAAAAAE+iZAgAAAKvZXC/3CNYcM1MAAAAAJlBMAQAAAJhAMQUAAABgAj1TAAAAYDXrueUewZqjmDKzqcZ9KY6/ZVzWZRvuMCzr4K5hWQ+og4dlXZzrh2Vd9/4vDsvaesqvD8t63AW/PSzrLx/0gmFZt2TcD61j9jtiWNandnxlWNb2gV/Dhxy8eVhWknyxbxmWdcGGce+/d+hxk1q3jbusXLl+XOO+dRl3YUfdMu66PrDxxmFZm+ugYVlfN7d+WNY/rxv3vnGX3jAs67N187CswzLu72tbxn1/XbphXNaGge9RA9/mYcm5zQcAAABgAsUUAAAAgAkUUwAAAAAm0DMFAAAAVrO5cX11mGdmCgAAAMAEiikAAAAAEyimAAAAAEygZwoAAACsYj03t9xDWHPMTAEAAACYQDEFAAAAYIIVV0ypqq6q1y94vl9VXVFVb509f2JVPe92znFqVT1lb48VAAAAWHtWYs+U65McU1UHdPeNSR6b5HO3buzu05OcvlyDAwAAgBVlrpd7BGvOipuZMvP2JN81W35akjfeuqGqTqqqV8yWN1fVe6rqvKp6d1Xda8E5TqyqrVX1yar67nFDBwAAAPZlK7WY8qYkP1RVm5I8KMk/7WK/lyd5XXc/KMkbkrxswbbNSR6W+aLMq2fnAgAAANgjK7KY0t3nZb4Y8rTMz1LZlUck+T+z5b9I8q0Ltv1ld89196eSXJrk6L0wVAAAAGCNWYk9U251epI/SHJCkiO+huN3vmnsP91EVlUnJzk5SR5yxwfn6w/e/DXEAAAAwDLqueUewZqzImemzLw2yW929/m3sc8Hk/zQbPlHkrx/wbYfqKp1VfX1Se6b5OKdD+7uU7p7S3dvUUgBAAAAdseKnZnS3Z/NV/dA+arNsz+fleTPquo5Sa5I8hML9vnXJGcluUOSZ3T3TXtrrAAAAMDaseKKKd198CLrzkxy5uzpEUmumq3/lyTfvsj+J+21AQIAAABr2oorptyWqnpGkpOSfP8yDwUAAABYo1ZVMaW7X53k1cs9DgAAAFgx5v7T562wl63kBrQAAAAAK45iCgAAAMAEiikAAAAAE6yqnikAAADATubmlnsEa46ZKQAAAAATKKYAAAAATKCYAgAAADCBnikAAACwms31co9gzTEzBQAAAGACxRQAAACACRRTAAAAACbQM2XmLrX/sKxLN4y7n+2ggX/F/1w3D8u6fO7GYVlHrTt4WNZpl9xjWNYd1o97Hf7lg14wLOsHz3vRsKx3bnnOsKwvz437/jp+/eHDsj4xd+2wrCPXbRqWlSSdcd9j/5ZbhmV9buB13ak2Dsu6KtuGZW3ruWFZV+w/7vebIzIu66aM+xp+pMb9znF4xr3mR/q6gdd1+cD3w00D/196XdWwrFsGvs/fNDBrnzfwZwvzzEwBAAAAmEAxBQAAAGACxRQAAACACRRTAAAAACbQgBYAAABWsznNfEczMwUAAABgAsUUAAAAgAkUUwAAAAAm0DMFAAAAVrGem1vuIaw5ZqYAAAAATLCiiylVtaOqzl3w2FxVW6rqZbdz3Aur6ldGjRMAAABYO1b6bT43dvexO627LMnW8UMBAAAAWOEzUxZTVSdU1Vtny3esqtOq6ryq+nBVPWjBrg+uqg9V1aeq6qeXabgAAACwd831vvtYoVb6zJQDqurc2fKnu/v7dtr+m0nO6e7vrapvT/LnSY6dbXtQkocnOSjJOVX1tu6+fMCYAQAAgH3YSi+mLHabz0LfmuTJSdLd76mqI6rqDrNtb+nuG5PcWFXvTfKwJKftzcECAAAA+75Vd5vPBDvPB/pP84Oq6uSq2lpVWz9+7T8PGhYAAACwmq32Ysr7k/xIMt9LJcmV3f2V2bYnVdWmqjoiyQlJzt754O4+pbu3dPeWYw75+jEjBgAAgKW03H1N9ExZNW79ir4wyWur6rwkNyT58QX7nJfkvUmOTPJi/VIAAACApbCiiyndffAiq49IctVs+1VJvneR4164VwcGAAAALLuqenySP06yPslruvv3FtnnBzM/GaOTfKy7f3hPc1d0MWVnVfXEJL+d5OnLPRYAAABg+VTV+iSvTPLYJJ9NcnZVnd7dFy7Y56gkv5bkkd19dVXdeSmyV1XPlO4+vbuP7u4PLvdYAAAAgGX1sCSXdPel3X1LkjcledJO+/x0kld299VJ0t1fXIrgVTUzBQAAANhJzy33CJbL3ZN8ZsHzzyb55p32uX+SVNUHMn8r0Au7+x17GqyYAgAAAKxIVXVykpMXrDqlu0+ZcIr9khyV+U/5vUeS91XVN3X3l/dkXIopAAAAwIo0K5zsqnjyuST3XPD8HrN1C302yT9197Ykn66qT2a+uHL2noxrVfVMAQAAAJg5O8lRVXWfqtqY5IeSnL7TPqdlflZKqurIzN/2c+meBpuZAgAAAKvZXC/3CJZFd2+vqmcmOSPz/VBe290XVNWLkmzt7tNn2x5XVRcm2ZHkOd39pT3NVkwBAAAAVqXufnuSt++07gULljvJL88eS8ZtPgAAAAATKKYAAAAATOA2HwAAAFjFeo32TFlOZqYAAAAATKCYAgAAADCB23xmLp27bljWJRk3Bevr1h04LOsrvW1Y1p3WbRqWdX12DMu6dt24b8lP7Tc3LOuWjMt655bnDMt6zdaXDst65pbnDsv6VI97P3xsHzos6z39lWFZSXK3OmBY1p163HvHHbqGZW0bOGN507qB/7807kuYuYG/c+w/8P/obhj4s3nbwJ9hV/ct47IyLqsGvm98evuXh2U9ef3dh2VtG/i+sWHge+/Ay4Ilp5gCAAAAq5meKcO5zQcAAABgAsUUAAAAgAkUUwAAAAAmUEwBAAAAmEADWgAAAFjN5sZ98hjzzEwBAAAAmEAxBQAAAGACxRQAAACACfRMAQAAgNVsrpd7BGuOmSkAAAAAEyxLMaXmKeQAAAAAq86wgkZVba6qi6vqz5N8PMlvVNXZVXVeVf3mgv1Oq6qPVNUFVXXybN36qjq1qj5eVedX1S/N1h9bVR+eneNvq+rw2fozq+olVXVWVX2yqh416joBAACAfdvonilHJfnxJHdI8pQkD0tSSU6vqkd39/uSPL27r6qqA5KcXVV/k2Rzkrt39zFJUlWHzc7350me1d3/UFUvSvI/kvzibNt+3f2wqvrO2foTR1wgAAAADKVnynCjb7X5l+7+cJLHzR7nJPlokqMzX2hJkmdX1ceSfDjJPWfrL01y36p6eVU9PslXqurQJId19z/MjntdkkcvyPq/sz8/kvliDAAAAMAeG11MuX72ZyX53e4+dva4X3f/aVWdkPkZJI/o7gdnvtiyqbuvTvLgJGcmeUaS1+xG1s2zP3dkFzNwqurkqtpaVVv/9bp//VqvCQAAAFhDlqsJ7BlJnl5VBydJVd29qu6c5NAkV3f3DVV1dJKHz7YfmWRdd/9NkucnOb67r0ly9YJ+KP81yT/sHHRbuvuU7t7S3VvudfC9lubKAAAAgH3a6J4pSZLufmdVPSDJh6oqSa5L8qNJ3pHkGVV1UZKLM3+rT5LcPcmfLfgEoF+b/fnjSV5dVQdm/lagnxh0CQAAALAidOuZMtqwYkp3X5bkmAXP/zjJHy+y6xN2cYrjFznnuZnNXtlp/QkLlq+MnikAAADAElmu23wAAAAAViXFFAAAAIAJFFMAAAAAJliWBrQAAADAEpnTgHY0M1MAAAAAJlBMAQAAAJhAMQUAAABgAj1TAAAAYDXTM2U4M1MAAAAAJlBMAQAAAJhAMQUAAABgAj1TAAAAYBVrPVOGU0yZude6g4Zl/VvfNCzrJ8ZF5VX717CsDRmXddmO64Zl3bJ+bljWp7dfMyzrmP2OGJb15bmbh2U9c8tzh2W9YutLhmWNvK4L128blvXd2+4wLCtJ3rrfV4Zl3Vj7D8s6tMb96vCl3DIs66qB7x1HrNs0LOvaHvc9dmwOHpZ1dY2bXH3H2jAsa/3A32+uzLjXxo29Y1jW3fc7ZFjWoeMuK+9df/2wrGsHvjY2DPxeTpL/NjSNfZ3bfAAAAAAmUEwBAAAAmMBtPgAAALCa6ZkynJkpAAAAABMopgAAAABMoJgCAAAAMIFiCgAAAMAEGtACAADAaja33ANYe8xMAQAAAJhAMQUAAABgAsUUAAAAgAlWRc+Uqjo1yVu7+6+r6jVJ/md3X7jMwwIAAIBl13O93ENYc1ZcMaWq9uvu7bva3t0/NXI8AAAAAAvt8W0+VfUbVXVxVf1jVb2xqn6lqs6sqi2z7UdW1WWz5c1V9f6q+ujs8S2z9SfM1p+e5MKa94rZef9fkjsvyFt47ldV1daquqCqfnPBPpdV1W/OMs6vqqP39DoBAAAAkj2cmVJVD03y5CQPTrIhyUeTfOQ2Dvliksd2901VdVSSNybZMtt2fJJjuvvTVfX9Sb4hyQOT3CXJhUleu8j5fr27r6qq9UneXVUP6u7zZtuu7O7jq+rnkvxKEjNaAAAAgD22p7f5PDLJW7r7piQ3VdXf3c7+G5K8oqqOTbIjyf0XbDuruz89W350kjd2944kl1fVe3Zxvh+sqpMzfx13zXzx5dZiyv+d/fmRJN8/4ZoAAABg9dAzZbi99Wk+2xece9OC9b+U5AuZn8myJcnGBduunxJQVffJ/IyT7+juByV5205ZN8/+3JFdFI2q6uTZbUJbL7z20inxAAAAwBq1p8WUDyT5nqraVFUHJ/nu2frLkjxktvyUBfsfmuTz3T2X5L8mWb+L874vyVOran1V3TXJYxbZ5w6ZL8BcU1V3SfKEqYPv7lO6e0t3b3ngIfedejgAAACwBu1RMaW7z05yeuZvrfn7JOcnuSbJHyT52ao6J8mRCw7530l+vKo+luTo7Ho2yt8m+VTme6X8eZIPLZL9sSTnJPlEkv+T+cIOAAAAwF61FB+N/Afd/cKqOjDzM0o+0t2fSPKgBfs8P0m6+1M7rX/ubP2ZSc68dWV3d5JnLhbW3ScsWD5pF/tsXrC8NckJi+0HAAAAq97ccg9g7VmKYsopVfXAzPcreV13f3QJzgkAAACwIu1xMaW7f3gpBgIAAACwGuytT/MBAAAA2CcppgAAAABMsBQ9UwAAAIBl0nO93ENYc8xMAQAAAJhAMQUAAABgAsUUAAAAgAn0TAEAAIDVbG65B7D2mJkCAAAAMIFiCgAAAMAEiikAAAAAE+iZMvNdN64flvXBAw4elvWuTTUs6y1f/MCwrF+887cMyzpw/aHDsv7xlsuHZe1X417zn9rxlWFZx68/fFjWp/q6YVnP3PLcYVmv2PqSYVlPPO7nh2Xddb87DstKksNr/2FZI/9n5LK+fljWyK/hHWrjsKwvzd00LOvG3j4s6wvrNw3Lui47hmWNdOjAX80ftGPc99dIF62/ZVjWP+037nv5K3PjrutLO24YlnXQunHvvfu6nuvlHsKaY2YKAAAAwASKKQAAAAATKKYAAAAATKBnCgAAAKxmc8s9gLXHzBQAAACACRRTAAAAACZQTAEAAACYQDEFAAAAYAINaAEAAGAVaw1ohzMzBQAAAGACxRQAAACACW6zmFJVh1XVz+3tQVTVZVV15M55VXW3qvrrvZ0PAAAAsLtub2bKYUn+UzGlqvZWr5Wvyuvuy7v7KXspCwAAAFa/uX34sULdXjHl95J8fVWdW1VnV9X7q+r0JBcmSVWdVlUfqaoLqurk2bpnVNVLbz1BVZ1UVa+YLf9oVZ01O9//V1XrbyPvpVW1uao+vuA8p1XVu2YzWZ5ZVb9cVedU1Yer6o6z/b6+qt4xG9f7q+roJflKAQAAAOT2iynPS/LP3X1skuckOT7JL3T3/Wfbn97dD0myJcmzq+qIJH+T5PsWnOOpSd5UVQ+YLT9ydr4dSX5kV3nd/ZxFxnNMku9P8tAkv53khu4+LsmHkvzYbJ9TkjxrNq5fSfK/b+caAQAAAHbb1Nt1zuruTy94/uyqurVwcs8kR3X3h6vq0qp6eJJPJTk6yQeS/HyShyQ5u6qS5IAkX5yY/97uvjbJtVV1TZK/m60/P8mDqurgJN+S5K9mGUmy/8QMAAAAgF2aWky5/taFqjohyYlJHtHdN1TVmUk2zTa/KckPJvlEkr/t7q756sbruvvX9mC8Ny9YnlvwfC7z17IuyZdnM19u1+zWpJOT5JmHbMnjD7jfHgwNAAAAxusV3FtkX3V7t/lcm+SQXWw7NMnVs0LK0UkevmDb3yZ5UpKnZb6wkiTvTvKUqrpzklTVHavq3hPybld3fyXJp6vqB2YZVVUPvo39T+nuLd29RSEFAAAA2B23WUzp7i8l+cCsCexLd9r8jiT7VdVFmW8c++EFx12d5KIk9+7us2brLkzy/CTvrKrzkrwryV13lbewie1EP5LkJ6vqY0kuyHxRBwAAAGBJ3O5tPt39w7tYf3OSJ9zGcd+9yLo3J3nzIus330beMbP1pyY5dRfH/Pu2WU+Xx+9qXAAAAAB7YmrPFAAAAGAl0TNluNvrmQIAAADAAoopAAAAABMopgAAAABMoJgCAAAAMIEGtAAAALCKtQa0w5mZAgAAADCBYgoAAADABIopAAAAABPomQIAAACrmJ4p45mZAgAAADCBYgoAAADABG7zmXnV/l8ZlvWBKy8elvWDRx43LuvODxmWdeHctcOy7rXuoGFZ/2XjPYZlfSHbhmVtz7h5h58Y+Np4bB86LOvC9eP+vp543M8Pyzr9nFcOy/qWB500LCtJHrXxbsOy7rdj3I/z/Xv/YVmXr+9hWeOSknvuOHBY1iUbxr3/bh/4Vdw48P8D/2nbF4dl3WW/cb9zvHvbFcOyrtl2/bCs4w+697Cs/Wrc6/BJc4cPy7pp3bis6/zXPquYYgoAAACsYnqmjKcWCAAAADCBYgoAAADABIopAAAAABPomQIAAACrWddyj2DNMTMFAAAAYALFFAAAAIAJFFMAAAAAJlBMAQAAAJhAA1oAAABYxXpuuUew9piZAgAAADDB11xMqapfrKoDv4bjrrud7cdW1XcueP7Eqnre1zJGAAAAgKW2JzNTfjHJ5GLKbjg2yb8XU7r79O7+vb2QAwAAADDZbvVMqaqDkvxlknskWZ/kr5LcLcl7q+rK7n5MVV3X3QfP9n9Kku/u7pOq6j5J/k+Sg5O8ZcE5/zzJ/+3u02bP3zDLeFGSA6rqW5P8bpIDkmzp7mdW1alJbkxyXJI7J3l6kh9L8ogk/9TdJ83O9bgkv5lk/yT/nOQnuvs2Z8QAAADAatRztdxDWHN2d2bK45Nc3t0P7u5jkvyvJJcneUx3P+Z2jv3jJK/q7m9K8vkF6/80yUlJUlWHJvmWJG9L8oIkb+7uY7v7zYuc7/DMF09+KcnpSf4oyTcm+abZLUJHJnl+khO7+/gkW5P88m5eJwAAAMBt2t1iyvlJHltVL6mqR3X3NRMyHpnkjbPlv7h1ZXf/Q5KjqupOSZ6W5G+6e/tunO/vurtnY/pCd5/f3XNJLkiyOcnDkzwwyQeq6twkP57k3hPGCwAAALBLu3WbT3d/sqqOz3wvk9+qqncvttuC5U23sW2hP0/yo0l+KMlP7M5Yktw8+3NuwfKtz/dLsiPJu7r7abd3oqo6OcnJSfJNhx+Tex18r90cAgAAALBW7dbMlKq6W5Ibuvv1SV6a5Pgk1yY5ZMFuX6iqB1TVuiTft2D9BzJfLEmSH9np1KdmvpFtuvvC2bqdzzvVh5M8sqruNxv7QVV1/8V27O5TuntLd29RSAEAAGA16rl997FS7e5tPt+U5KzZbTP/I8lvJTklyTuq6r2zfZ6X5K1JPpiv7o3yC0l+vqrOT3L3hSft7i8kuSjJny1Y/d4kD6yqc6vqqdMuJ+nuKzLfi+WNVXVekg8lOXrqeQAAAAAWs7u3+ZyR5IydVm9N8vIF+/x1kr9e5NhPZ75h7K2ef+tCVR2Y5Kj8R0+VdPdVSR6602lOnW07acF+lyU5ZsHzhdves8g5AAAAAPbY7s5MWXJVdWLmZ6W8fGJDWwAAAIBls1szU/aG7v5/8Sk7AAAAsEe6a7mHsOYs28wUAAAAgNVIMQUAAABgAsUUAAAAgAkUUwAAAAAmWLYGtAAAAMCe67nlHsHaY2YKAAAAwASKKQAAAAATKKYAAAAATKBnCgAAAKxiPVfLPYQ1x8wUAAAAgAmqu5d7DCvCr2/+4WFfiG0Z9zX/thuHReU1+183LOvwdfsPy9qQcVXe/3fdPw/L2t7bh2U95ODNw7KOqHGvjav75mFZ3739DsOyPrffuPeo07Z9ZljWB887dVhWkjxzy3OHZX25tw3L+uTNVwzLus/+RwzLunFu3Nfwn758ybCsb7/jA4ZlHZdDhmVdkBuGZX1jDhyWdWCP+51j4Fv9wN+kkn9bP+4jTUb+K+r3L/+HYVn78r8Ot9/yuX12+sZnHvod++xf3T3PfveK/HszMwUAAABgAj1TAAAAYBVzw8l4ZqYAAAAATKCYAgAAADCBYgoAAADABHqmAAAAwCrWcyvyA2/2aWamAAAAAEygmAIAAAAwgWIKAAAAwASKKQAAAAATaEALAAAAq5gGtOPt1ZkpVfXsqrqoqt6wi+1bqupls+WTquoVe3M8AAAAAHtqb89M+bkkJ3b3Zxfb2N1bk2z9Wk5cVft19/Y9GRwAAADAVHttZkpVvTrJfZP8fVU9t6o+VFXnVNUHq+obZvucUFVvXeTYU6vqKQueX7dg//dX1elJLqyq9VX10qo6u6rOq6qfme1316p6X1WdW1Ufr6pH7a3rBAAAANaWvVZM6e5nJLk8yWOSvCrJo7r7uCQvSPI7e3Dq45P8QnffP8lPJrmmux+a5KFJfrqq7pPkh5Oc0d3HJnlwknP3IA8AAABWrO5993F7qurxVXVxVV1SVc+7jf2eXFVdVVuW4ms+qgHtoUleV1VHJekkG/bgXGd196dny49L8qAFs1gOTXJUkrOTvLaqNiQ5rbvP3YM8AAAAYIWpqvVJXpnksUk+m+Tsqjq9uy/cab9DkvxCkn9aquxRH4384iTv7e5jknxPkk23s//2zMZWVeuSbFyw7foFy5XkWd197Oxxn+5+Z3e/L8mjk3wuyalV9WOLhVTVyVW1taq2nnPtJV/blQEAAADL4WFJLunuS7v7liRvSvKkRfZ7cZKXJLlpqYJHFVMOzXxhI0lO2o39L0vykNnyE7PrmSxnJPnZ2QyUVNX9q+qgqrp3ki90958keU3mbw36T7r7lO7e0t1bjjvkfrt1IQAAAMCKcPckn1nw/LOzdf+uqo5Pcs/ufttSBo+6zef3M3+bz/OT7M4F/EmSt1TVx5K8I189G2Wh1yTZnOSjVVVJrkjyvUlOSPKcqtqW5Loki85MAQAAgNWu52q5h7DXVNXJSU5esOqU7j5lN49dl+R/ZvcmdUyyV4sp3b15tnhlkvsv2PT82fYzk5w5Wz41yamz5S8kefiC/Z+78/6z53NJ/vvssdDrZg8AAABglZoVTnZVPPlcknsueH6P/MddMUlySJJjkpw5P/8iX5fk9Kp6Yndv3ZNxjbrNBwAAAGApnZ3kqKq6T1VtTPJDSU6/dWN3X9PdR3b35tlkjw8n2eNCSqKYAgAAAKxC3b09yTMz30/1oiR/2d0XVNWLquqJezN7VM8UAAAAYC/o3nd7ptye7n57krfvtO4Fu9j3hKXKNTMFAAAAYALFFAAAAIAJFFMAAAAAJtAzBQAAAFaxnlvuEaw9ZqYAAAAATKCYAgAAADCBYgoAAADABIopAAAAABNoQAsAAACr2FzXcg9hzanuXu4xrAiPvvt37JNfiH+56YphWd97yAOHZX0524ZlbRvYGnt9xr0J3qk2Dsv6Yt8yLGtTjZtwd2DWD8u6vG8clnV47T8s65CBX8Prs2NYVpK8YutLhmX94UNeMCzr4hr3WrxTxr1PjTTyvf6KjHv/vWLupmFZX7fugGFZ1/b2YVnrBr42NtS4rCvnbh6WddjA32/uODDrnTdcOizr7vsfPizroNowLCtJ3vKvb91nKw6ffMDj98l/zybJ/S96x4r8e3ObDwAAAMAEiikAAAAAE+iZAgAAAKtY65kynJkpAAAAABMopgAAAABMoJgCAAAAMIGeKQAAALCK9ZyeKaOZmQIAAAAwgWIKAAAAwASKKQAAAAAT6JkCAAAAq1j3co9g7VnSmSlVdVJVvWKJznVZVR25FOcCAAAAWCpu8wEAAACYYLeKKVV1UFW9rao+VlUfr6qnVtVDq+qDs3VnVdUhs93vVlXvqKpPVdXvLzjH06rq/NnxL7m99beVPVv/7zNXqmpLVZ05W35hVf1FVX1oNoaf/tq/PAAAAABfbXd7pjw+yeXd/V1JUlWHJjknyVO7++yqukOSG2f7HpvkuCQ3J7m4ql6eZEeSlyR5SJKrk7yzqr43yVmLre/u024n+/Y8KMnDkxyU5Jyqelt3X76b1woAAACwS7tbTDk/yR/OZo68NcmXk3y+u89Oku7+SpJUVZK8u7uvmT2/MMm9kxyR5MzuvmK2/g1JHp2kd7H+tF1ld/f7d2O8b+nuG5PcWFXvTfKwnc4JAAAA+4Seq+UewpqzW7f5dPcnkxyf+cLGbyX5/tvY/eYFyzuyh58YtHN2Vb1gtml7/mP8m3Y+7HaeJ0mq6uSq2lpVWz9//ef2ZJgAAADAGrG7PVPuluSG7n59kpcm+eYkd62qh862H1JVt1U0OSvJt1XVkVW1PsnTkvzDbay/rezjZ5suy/ztQUny5J3ynlRVm6rqiCQnJDl7sUF19yndvaW7t9z1oLvf7tcBAAAAYHdnjXxTkpdW1VySbUl+NkkleXlVHZD5fikn7urg7v58VT0vyXtnx72tu9+SJLtafzvZSfKbSf60ql6c5Mydjjlvds4jk7xYvxQAAABgqexWMaW7z0hyxiKbHr7T81Nnj1uP++4Fy29M8sZFzr2r9Ztni4tmz3qn3H8XQz6vu39sF9sAAABgnzHXeqaMtlu3+QAAAAAwb4+aw65E3f3C5R4DAAAAsO8yMwUAAABggn1uZgoAAACsJa1nynBmpgAAAABMoJgCAAAAMIFiCgAAAMAEeqYAAADAKta93CNYe8xMAQAAAJhAMQUAAABgAsUUAAAAgAkUUwAAAAAm0IB25qbePixrQ60flnXvTXcaljXS53dcPyzr6PWHDsvasm3DsKyRLthQw7L+LbcMy7pTj3sLvbH2H5Y1ssp+vx3jvob/sO6mYVlJ8ocPecGwrP/2kRcNy/rwMb86LOv1m8b9bD4y495/D+5x32WHZtOwrE3rxv1+c33GvTYOq3GvjZsyNyxrW4/LGunI2jgsa+RX8H6b7jwsa9PAf6vsn3FZ+7q5Hvf7NvPMTAEAAACYQDEFAAAAYALFFAAAAIAJ9EwBAACAVaz1TBnOzBQAAACACRRTAAAAACZQTAEAAACYQM8UAAAAWMW6l3sEa4+ZKQAAAAATKKYAAAAATKCYAgAAADDBXu2ZUlXPTvKzST7a3T+yN7MAAABgLZrrWu4hrDl7uwHtzyU5sbs/u5dzAAAAAIbYa7f5VNWrk9w3yd9X1XOr6kNVdU5VfbCqvmG2z0lVdVpVvauqLquqZ1bVL8/2+3BV3XG237Or6sKqOq+q3jRb98Kq+pUFeR+vqs2zxyeq6g1VdVFV/XVVHbi3rhMAAABYW/ZaMaW7n5Hk8iSPSfKqJI/q7uOSvCDJ7yzY9Zgk35/koUl+O8kNs/0+lOTHZvs8L8lx3f2gJM/YjfhvSPK/u/sBSb6S+RkyAAAAAHtsVAPaQ5P8VVV9PMkfJfnGBdve293XdvcVSa5J8nez9ecn2TxbPi/JG6rqR5Ns3428z3T3B2bLr0/yrXs4fgAAAIAk44opL8580eSYJN+TZNOCbTcvWJ5b8Hwu/9HT5buSvDLJ8UnOrqr9Ml9UWTj+hefsnfJ3fp4kqaqTq2prVW394g2fn3A5AAAAsDJ01z77WKlGzkz53Gz5pCkHVtW6JPfs7vcmee7sXAcnuSzzxZVU1fFJ7rPgsHtV1SNmyz+c5B8XO3d3n9LdW7p7y50PvOuUYQEAAABr1Khiyu8n+d2qOifTP0FofZLXV9X5Sc5J8rLu/nKSv0lyx6q6IMkzk3xywTEXJ/n5qrooyeGZ79kCAAAAsMf26kcjd/fm2eKVSe6/YNPzZ9tPTXLqIvvvvO0/9Tzp7huTPG7n9VW1Ocn27v7Rr3ngAAAAALuwV4spAAAAwN41t4J7i+yr9rliSndflvmPWwYAAABYcqN6pgAAAADsExRTAAAAACbY527zAQAAgLWkl3sAa5CZKQAAAAATKKYAAAAATKCYAgAAADCBnikAAACwis11LfcQ1hwzUwAAAAAmUEwBAAAAmEAxBQAAAGACPVNmjtl4p2FZn95+zbCse6w/ZFjWpoy7T+9e6w8elrVpYM3xxoG3On5x/bhPo79Dj/safi4jr2vcX9ihNe7t+rK+fljW/r3/sKxP3nzFsKwkOXDT+mFZHz7mV4dlPfzjvz8s67VbnjMs65CB71P32DYsKteNexnmXwb+XNk48GfzF/umYVl3rk3Dsu5aG4dl3WvgdV04d+2wrLuuO2BY1jesG/c7/ZE98I0DVjHFFAAAAFjFWgPa4dzmAwAAADCBYgoAAADABIopAAAAABPomQIAAACr2NxyD2ANMjMFAAAAYALFFAAAAIAJFFMAAAAAJtAzBQAAAFaxTi33ENYcM1MAAAAAJlBMAQAAAJhgnymmVNWLqurERdafUFVvXY4xAQAAAPuefaZnSne/YLnHAAAAAKPN9XKPYO1ZsTNTqmpzVX2iqt5QVRdV1V9X1YFV9YKqOruqPl5Vp1RVzfY/taqeMlt+/OzYjyb5/mW9EAAAAGCfsmKLKTPfkOR/d/cDknwlyc8leUV3P7S7j0lyQJLvXnhAVW1K8idJvifJQ5J83dghAwAAAPuylV5M+Ux3f2C2/Pok35rkMVX1T1V1fpJvT/KNOx1zdJJPd/enurtnxwEAAAAsiZVeTNn5zq9O8r+TPKW7vynzM1A2fa0nr6qTq2prVW29+NpL92CYAAAAwFqx0osp96qqR8yWfzjJP86Wr6yqg5M8ZZFjPpFkc1V9/ez503Z18u4+pbu3dPeWbzjkvks2aAAAABhlLrXPPlaqlf5pPhcn+fmqem2SC5O8KsnhST6e5N+SnL3zAd19U1WdnORtVXVDkvcnOWTckAEAAIB92Uovpmzv7h/dad3zZ4+v0t0nLVh+R+Z7pwAAAAAsqZV+mw8AAADAirJiZ6Z092VJjlnucQAAAMBK1iu4t8i+yswUAAAAgAkUUwAAAAAmUEwBAAAAmGDF9kwBAAAAbt/ccg9gDTIzBQAAAGACxRQAAACACRRTAAAAACbQMwUAAABWsU4t9xDWHDNTAAAAACZQTAEAAACYwG0+M/+649phWY9bf5dhWe+b+9KwrO3rxn0g1x1qw7Csw3v9sKxrxkXlgB43FXDbwFmHd6qNw7K29bCofCm3DMs6vPYflnX5+nFfxPusP2JYVpLcKeNei6/ftH1Y1mu3PGdY1ilbXzos69lbnjcsa8eGcT/DrqlxP5s3DJxivjHjfmDeY+D38rUDP9z04r5uWNamgf/kuNe6g4ZlXZ9x772HDvwaXl07hmVd7wN9WcXMTAEAAACYwMwUAAAAWMXM8RnPzBQAAACACRRTAAAAACZQTAEAAACYQM8UAAAAWMX0TBnPzBQAAACACRRTAAAAACZQTAEAAACYQM8UAAAAWMU6tdxDWHPMTAEAAACYYEgxpapOqKpvWfD8GVX1Y7dzzGuq6oGz5f++07YP7p2RAgAAANy2Ubf5nJDkuiQfTJLufvXtHdDdP7Xg6X9P8jsLtn3Lfz4CAAAAYO/bo5kpVXVaVX2kqi6oqpNn6x5fVR+tqo9V1buranOSZyT5pao6t6oeVVUvrKpfqaqjq+qsBefbXFXnz5bPrKotVfV7SQ6YHfuG2bbrFhzznKo6u6rOq6rfnK07qKreNhvDx6vqqXtynQAAALBSzdW++1ip9nRmytO7+6qqOiDJ2VX1liR/kuTR3f3pqrrjbPurk1zX3X+QJFX1HUnS3Z+oqo1VdZ/u/nSSpyZ588KA7n5eVT2zu4/dObyqHpfkqCQPS1JJTq+qRye5U5LLu/u7ZvsduofXCQAAAJBkz3umPLuqPpbkw0numeTkJO+bFUbS3Vftxjn+MvNFlGSRYsrteNzscU6SjyY5OvPFlfOTPLaqXlJVj+ruayacEwAAAGCXvuZiSlWdkOTEJI/o7gdnvqBx7tdwqjcn+cGqun+S7u5PTRlGkt/t7mNnj/t195929yeTHJ/5ospvVdULdnENJ1fV1qra+rnrPvs1DB0AAABYa/ZkZsqhSa7u7huq6ugkD0+yKcmjq+o+SVJVd5zte22SQxY7SXf/c5IdSX4ju56Vsq2qNiyy/owkT6+qg2d5d6+qO1fV3ZLc0N2vT/LSzBdWFss+pbu3dPeWux98j924ZAAAAGCt25OeKe9I8oyquijJxZm/1eeKzN/q83+ral2SLyZ5bJK/S/LXVfWkJM9a5FxvznzR4z67yDolyXlV9dHu/pFbV3b3O6vqAUk+VFXJ/CcG/WiS+yV5aVXNJdmW5Gf34DoBAABgxZrLCu7Uuo/6mosp3X1zkifsYvPf77TvJ5M8aMGq9++0/Q+S/MFO605YsPzcJM9d8PzgBct/nOSPd8r/58zPWgEAAABYUnvagBYAAABgTVFMAQAAAJhgT3qmAAAAAMusl3sAa5CZKQAAAAATKKYAAAAATKCYAgAAADCBnikAAACwis0t9wDWIDNTAAAAACZQTAEAAACYQDEFAAAAYAI9UwAAAGAVm6ta7iGsOWamAAAAAExgZsrMAbVhWNaldfOwrP1q/bCs+9aBw7IO6XF1wH/sq4dlPW374cOyrhtYSr1yfQ/LuirbhmVtWjfui3jV3Lj3jTvUxmFZ414ZyY1z414bSZJxb785MuN+ho18/332lucNy3rZ1t8blvWCLc8flnVddgzL2jDw/+iuzfZhWV+qcZ+RsWngG8fNPe66bshNw7I21rjX4cED/74G/kjJ+oyb4XCQ/9tnFfPqBQAAAJhAMQUAAABgArf5AAAAwCo28tZp5pmZAgAAADCBYgoAAADABIopAAAAABPomQIAAACr2LgPO+dWZqYAAAAATKCYAgAAADCBYgoAAACwKlXV46vq4qq6pKqet8j2X66qC6vqvKp6d1Xdeyly9UwBAACAVWyulnsEy6Oq1id5ZZLHJvlskrOr6vTuvnDBbuck2dLdN1TVzyb5/SRP3dNsM1MAAACA1ehhSS7p7ku7+5Ykb0rypIU7dPd7u/uG2dMPJ7nHUgSvuGJKVe3RbJlZZQoAAABY5arq5KrauuBx8oLNd0/ymQXPPztbtys/meTvl2Jce6WYUlWbq+qiqvqTqrqgqt5ZVQdU1ZlVtWW2z5FVddls+aSqOr2q3pPk3VV116p6X1WdW1Ufr6pHzfZ7XFV9qKo+WlV/VVUHz9ZfVlUvqaqPJnne7M9bx3LUwucAAADA6tDdp3T3lgWPU76W81TVjybZkuSlSzGuvTkz5agkr+zub0zy5SRPvp39j0/ylO7+tiQ/nOSM7j42yYOTnFtVRyZ5fpITu/v4JFuT/PKC47/U3cd3928nuaaqjp2t/4kkf7Y0lwQAAAAry1xqn33cjs8lueeC5/eYrfsqVXVikl9P8sTuvnkpvuZ7swHtp7v73NnyR5Jsvp3939XdV82Wz07y2qrakOS07j63qr4tyQOTfKCqkmRjkg8tOP7NC5Zfk+QnquqXM99Y5mF7ciEAAADAinN2kqOq6j6ZL6L8UOYnZ/y7qjouyf+X5PHd/cWlCt6bM1MWVnt2ZL5ws31B5qad9r/+1oXufl+SR2f+i3FqVf1Yksp8weXY2eOB3f2Tix2f5G+SPCHJdyf5SHd/abEBLrz36l+u+9fpVwgAAAAsi+7enuSZSc5IclGSv+zuC6rqRVX1xNluL01ycJK/mrUSOX0pskd/NPJlSR6S5KwkT9nVTrPPff5sd/9JVe2f+VuAfjvJK6vqft19SVUdlOTu3f3JnY/v7puq6owkr8p8g5lFze61OiVJvude391f+2UBAAAAo3X325O8fad1L1iwfOLeyB39aT5/kORnq+qcJEfexn4nJPnYbL+nJvnj7r4iyUlJ3lhV52X+Fp+jb+Mcb0gyl+SdSzBuAAAAgCR7aWZKd1+W5JgFz/9gweYHLVh+/mz7qUlOXbD/65K8bpHzvifJQxdZv3mRYXxrkj/r7h1Txg4AAACridssxht9m88QVfW3Sb4+ybcv91gAAACAfcs+WUzp7u9b7jEAAAAA+6bRPVMAAAAAVrV9cmYKAAAArBVztdwjWHvMTAEAAACYQDEFAAAAYALFFAAAAIAJ9EwBAACAVWxuuQewBpmZAgAAADCBYgoAAADABIopAAAAABPomQIAAACrWC/3ANYgxZSZI9ftPyzrwm1fGpb15e3XD8v6hgMOGZb1xbp5WNZhGffauGngXLGNA99x16WGZW3rge23xl1Wjli3aVjWl+ZuGpZ1zx0HDsv6X1+5ZFhWkhx7xEOHZR3c49487rFtWFR2bNgwLOsFW54/LOtFW39rWNZ/2/Jrw7I+seOaYVlHrz90WNZVfcuwrG0D/zm0oca9b2yf2zEsa6Qv9LjfR4/ffvCwrJHcJsFq5vULAAAAMIFiCgAAAMAEiikAAAAAE+iZAgAAAKvY3MBefswzMwUAAABgAsUUAAAAgAkUUwAAAAAm0DMFAAAAVrG55R7AGmRmCgAAAMAEiikAAAAAEyimAAAAAEwwtJhSVZur6uOLrH9RVZ14O8e+sKp+Ze+NDgAAAFafuX34sVKtiAa03f2CvZ1RVeu7e8fezgEAAAD2bctxm8/6qvqTqrqgqt5ZVQdU1alV9ZQkqarvrKpPVNVHquplVfXWBcc+sKrOrKpLq+rZt66sqh+tqrOq6tyq+v+qav1s/XVV9YdV9bEkjxh7mQAAAMC+aDmKKUcleWV3f2OSLyd58q0bqmpTkv8vyRO6+yFJ7rTTsUcn+S9JHpbkf1TVhqp6QJKnJnlkdx+bZEeSH5ntf1CSf+ruB3f3P+69SwIAAADWiuW4zefT3X3ubPkjSTYv2HZ0kku7+9Oz529McvKC7W/r7puT3FxVX0xylyTfkeQhSc6uqiQ5IMkXZ/vvSPI3uxpIVZ186/kfccfj8g2H3OdrvyoAAABYBl3LPYK1ZzmKKTcvWN6R+eLH13rsfkkqyeu6+9cW2f+m2+qT0t2nJDklSX5i85N7wjgAAACANWqlfTTyxUnuW1WbZ8+fuhvHvDvJU6rqzklSVXesqnvvpfEBAAAAa9yK+DSfW3X3jVX1c0neUVXXJzl7N465sKqen+SdVbUuybYkP5/kX/buaAEAAIC1aGgxpbsvS3LMgud/sMhu7+3uo2u+Acork2yd7fvCnc618DxvTvLmRfIOXpKBAwAAAMysqJkpMz9dVT+eZGOSczL/6T4AAADAIuaWewBr0IorpnT3HyX5o+UeBwAAAMBiVloDWgAAAIAVTTEFAAAAYIIVd5sPAAAAsPv0TBnPzBQAAACACRRTAAAAACZQTAEAAACYQM8UAAAAWMV6uQewBpmZAgAAADCBYgoAAADABIopAAAAABPomTLz6e3XDMt65Ia7DMs6d93Vw7IefvO42ty79h8WlfvWAcOyDpwbd7fjv+1Xw7KOumXcdV2x/7gXx9zAu1Ov7W3Dsm7s7cOyLtkwNyzr2+/4gGFZSXJFbhmWdWg2Dcu6bv2wqFxT414f12XHsKz/tuXXhmX94dbfHZb1ew/5jWFZVw38+7pvHTgsa/+B/8858jV/y/pxPy8/M3f9sKyH12HDsi7dMO5reOjcuN8RbxkXtc8b+NfGjJkpAAAAABMopgAAAABMoJgCAAAAMIFiCgAAAMAEGtACAADAKjauZTu3MjMFAAAAYALFFAAAAIAJFFMAAAAAJtAzBQAAAFYxPVPGMzMFAAAAYALFFAAAAIAJlryYUlUf3I19frGqDlzq7EVyjq2q79zbOQAAAMDaseTFlO7+lt3Y7ReTTCqmVNX6r2E4xyZRTAEAAGCf1fvwY6XaGzNTrpv9eUJVnVlVf11Vn6iqN9S8Zye5W5L3VtV7Z/s+rqo+VFUfraq/qqqDZ+svq6qXVNVHk/zA7PlvzvY7v6qOnu13UFW9tqrOqqpzqupJVbUxyYuSPLWqzq2qpy71tQIAAABrz97umXJc5mehPDDJfZM8srtfluTyJI/p7sdU1ZFJnp/kxO4+PsnWJL+84Bxf6u7ju/tNs+dXzvZ7VZJfma379STv6e6HJXlMkpcm2ZDkBUne3N3Hdveb9+aFAgAAAGvD3i6mnNXdn+3uuSTnJtm8yD4Pz3yx5QNVdW6SH09y7wXbdy6C/N/Znx9ZcL7HJXne7Pgzk2xKcq/bG1xVnVxVW6tq6+XXf+72rwYAAABY8/bby+e/ecHyjl3kVZJ3dffTdnGO63dxzoXnqyRP7u6Lv+rEVd98W4Pr7lOSnJIkJ9zjxJV8OxYAAAAsaq6WewRrz3J9NPK1SQ6ZLX84ySOr6n7Jv/c/uf/E852R5FlVVbNzHLdIDgAAAMAeW65iyilJ3lFV7+3uK5KclOSNVXVekg8lOXri+V6c+R4p51XVBbPnSfLeJA/UgBYAAABYKkt+m093Hzz788zM9y+5df0zFyy/PMnLFzx/T5KHLnKuzbt63t1bk5wwW74xyc8scvxVi50XAAAA4Gu1XDNTAAAAAFalvd2AFgAAANiL5pZ7AGuQmSkAAAAAEyimAAAAAEygmAIAAAAwgZ4pAAAAsIr1cg9gDTIzBQAAAGACxRQAAACACRRTAAAAACbQMwUAAABWsTldU4YzMwUAAABgAsUUAAAAgAnc5jPzyP3uPCzrozuuHpb1A33ksKx373/LsKyDsn5Y1qV947CsGzbuPyzrpswNy/rAxnFfwyMy7mu4/8B69LE5eFjWF9ZvGpa1feCU1ONyyLCsJDlr7pphWZvWjXtP/Jf14/7ONqQGZo37fv7EjnGvjd97yG8My3reR148LOtpD/nFYVmH1cZhWRsHvg7XDfz+uik7hmVtXjfu5+Xh4y4rF6wb97vUF/uGYVnb5gZ+EZP82tA09nWKKQAAALCKjftvUm7lNh8AAACACRRTAAAAACZQTAEAAACYQDEFAAAAYAINaAEAAGAVG/dZe9zKzBQAAACACRRTAAAAACZQTAEAAACYQM8UAAAAWMXmlnsAa9CqnZlSVYdV1c8teH63qvrr5RwTAAAAsO9bsmJKzRtZnDksyb8XU7r78u5+ysB8AAAAYA3ao+JHVW2uqour6s+TfDzJn1bVx6vq/Kp66myfE6rqH6rqLVV1aVX9XlX9SFWdNdvv62f7fU9V/VNVnVNV/6+q7jJb/8Kqem1VnTk7/tmz+N9L8vVVdW5VvXQ2lo/PjllfVX8wG8t5VfWsPblOAAAAgFstRc+Uo5L8eJK7J3lGkgcnOTLJ2VX1vtk+D07ygCRXJbk0yWu6+2FV9QtJnpXkF5P8Y5KHd3dX1U8l+dUk/212/NFJHpPkkCQXV9WrkjwvyTHdfWwyX9hZMKaTk2xOcmx3b6+qOy7BdQIAAMCKM1fLPYK1ZymKKf/S3R+uqj9K8sbu3pHkC1X1D0kemuQrSc7u7s8nSVX9c5J3zo49P/NFkiS5R5I3V9Vdk2xM8ukFGW/r7puT3FxVX0xyl9sZ04lJXt3d25Oku6/a46sEAAAAyNL0TLl+N/a5ecHy3ILnc/mPgs7Lk7yiu78pyc8k2bSL43dkiT6FqKpOrqqtVbX1nGsvWYpTAgAAAPu4pWwY+/4kT531K7lTkkcnOWvC8Ycm+dxs+cd3Y/9rM3/bz2LeleRnqmq/JNnVbT7dfUp3b+nuLccdcr8JQwUAAADWqqUspvxtkvOSfCzJe5L8anf/24TjX5jkr6rqI0muvL2du/tLST4wazL70p02vybJvyY5r6o+luSHJ4wDAAAAVo259D77WKn26HaZ7r4syTGz5U7ynNlj4T5nJjlzwfMTFtvW3W9J8pZFMl640/NjFizvXCS5dSzbk/zy7AEAAACwZJZyZgoAAADAPk8xBQAAAGACxRQAAACACZbkI4YBAACA5bFy27Tuu8xMAQAAAJhAMQUAAABgAsUUAAAAgAn0TAEAAIBVbG65B7AGmZkCAAAAMIFiCgAAAMAEiikAAAAAE+iZAgAAAKvYXHq5h7DmmJkCAAAAMIGZKTOX9g3Dso5df/iwrEuyY1jW+tSwrKuzbVjWEbVxWNa12T4sa6TNddCwrJsG9jK/YeD319U1rvZ93cDr2jiwpn9Bxr3PJ8nXrTtgWNb1A987Rv6dbcz6YVkj33+PXn/osKyrBn4/P+0hvzgs640f+V/Dsv70uBcMy/rM+nE/wy6cu3ZY1vU97ve2b1t3xLCs9627fljWkQN/H924/uBhWXfKhmFZsNTMTAEAAACYwMwUAAAAWMV0TBnPzBQAAACACRRTAAAAACZQTAEAAACYQDEFAAAAYAINaAEAAGAVG/fB6tzKzBQAAACACRRTAAAAACZQTAEAAACYYHgxpaqeXVUXVdUbBuWdWlVPGZEFAAAAo82l99nHSrUcDWh/LsmJ3f3ZpTphVe3X3duX6nwAAAAAuzK0mFJVr05y3yR/X1WvT/K9STYluTHJT3T3xVV10mz9QUmOSvIHSTYm+a9Jbk7ynd19VVWdmeTcJN+a5I2z5/8zycFJrkxyUnd/ftClAQAAAGvE0Nt8uvsZSS5P8pgkr0ryqO4+LskLkvzOgl2PSfL9SR6a5LeT3DDb70NJfmzBfhu7e0uSlyV5eZKndPdDkrx2dhwAAADAklqO23xudWiS11XVUUk6yYYF297b3dcmubaqrknyd7P15yd50IL93jz78xsyX4B5V1UlyfokZqUAAACwz1u5nUX2XctZTHlx5osm31dVm5OcuWDbzQuW5xY8n8tXj/n62Z+V5ILufsSUAVTVyUlOTpItd3xw7nfw5imHAwAAAGvQcn408qFJPjdbPmkPz3VxkjtV1SOSpKo2VNU33t5B3X1Kd2/p7i0KKQAAAMDuWM5iyu8n+d2qOid7OEOmu29J8pQkL6mqj2W+Me237PEIAQAAAHYy/Daf7t48W7wyyf0XbHr+bPupSU5dZP+v2tbdJ+x03nOTPHqRvJP2cMgAAACwYs0t9wDWoOWcmQIAAACw6iimAAAAAEygmAIAAAAwgWIKAAAAwATDG9ACAAAAS6fTyz2ENcfMFAAAAIAJFFMAAAAAJlBMAQAAAJhAzxQAAABYxeaWewBrkJkpAAAAABMopgAAAABMoJgCAAAAMIGeKQAAALCKzaWXewhrjmLKzF1r07Csb7lp3Av9jE3jWhFtTA3LWjfwpbth6HWtH5Z1bbYPy/q6uXHX9ZG6cVjWtoGtvu5YG4ZljfRP2744LOvx+33dsKwkuaBvGJZ12MDXxxf7pmFZ98jGYVlfqnHfz1f1LcOy7lsHDss6rMb9ff3pcS8YlvWT57xoWNaHjnnusKxj6w7Dsq7Yb9zvUl8c+A/Kkb8HjGwuOvLWhWuzY2AaLC23+QAAAABMoJgCAAAAMIHbfAAAAGAV0zFlPDNTAAAAgFWpqh5fVRdX1SVV9bxFtu9fVW+ebf+nqtq8FLmKKQAAAMCqU1Xrk7wyyROSPDDJ06rqgTvt9pNJru7u+yX5oyQvWYpsxRQAAABgNXpYkku6+9LuviXJm5I8aad9npTkdbPlv07yHVW1xx8zppgCAAAArEZ3T/KZBc8/O1u36D7dvT3JNUmO2NNgDWgBAABgFZvbh1vQVtXJSU5esOqU7j5lucZzK8UUAAAAYEWaFU52VTz5XJJ7Lnh+j9m6xfb5bFXtl+TQJF/a03G5zQcAAABYjc5OclRV3aeqNib5oSSn77TP6Ul+fLb8lCTv6e49nsqzZMWUqnp2VV1UVW/Yw/McW1XfueD5Exf7eCMAAABg7Zr1QHlmkjOSXJTkL7v7gqp6UVU9cbbbnyY5oqouSfLLSZakvrCUt/n8XJITu/uzt66oqv1mFzfFsUm2JHl7knT36fnPlSUAAAAgydxyD2AZdffbM6sfLFj3ggXLNyX5gaXOXZKZKVX16iT3TfL3VXVNVf1FVX0gyV9U1Z2q6m+q6uzZ45GzYw6qqtdW1VlVdU5VPWk2LedFSZ5aVedW1VOr6qSqesXsmFOr6lVV9eGqurSqTpid46KqOnXBeB5XVR+qqo9W1V9V1cFLcZ0AAAAAS1JM6e5nJLk8yWOS/FGSB2Z+lsrTkvxxkj/q7ocmeXKS18wO+/XM36v0sNlxL02yIckLkry5u4/t7jcvEnd4kkck+aXMz1j5oyTfmOSbZrcIHZnk+bP845NszfxUHgAAAIA9trc+zef07r5xtnxikgdW1a3b7jCbKfK4JE+sql+Zrd+U5F67ce6/6+6uqvOTfKG7z0+SqrogyebMd+99YJIPzDI3JvnQnl8SAAAAwN4rply/YHldkofP7lP6dzVf6Xhyd1+80/pvvp1z3zz7c27B8q3P90uyI8m7ZrNibtPCz6v+jjtuyYMO+frbOwQAAABWlM4efzgNE434aOR3JnnWrU+q6tjZ4hlJnjUrqqSqjputvzbJIXuQ9+Ekj6yq+83Oe1BV3X+xHbv7lO7e0t1bFFIAAACA3TGimPLsJFuq6ryqujDJM2brX5z5HinnzW7RefFs/Xszf1vQuVX11Klh3X1FkpOSvLGqzsv8LT5H7+E1AAAAACRZwtt8unvzbPGFO62/Msl/KorMeqr8zCLrr0ry0J1WnzrbdtKC/S5LcsyC5wu3vWeRcwAAAADssb3VMwUAAAAYYG65B7AGjbjNBwAAAGCfoZgCAAAAMIFiCgAAAMAEeqYAAADAKtbp5R7CmmNmCgAAAMAEiikAAAAAEyimAAAAAEygmAIAAAAwgQa0AAAAsIrNLfcA1iAzUwAAAAAmUEwBAAAAmEAxBQAAAGACPVNmrs2OYVkf2X/jsKyvn1s/LOtL68bdqXftwLsCrx/42rjjwG/J9dkwLOuf190yLOvwjPv+urrHXdf61LCsQwe+Du+y30HDsg7scV/DJFlX4/JuGvieeOfaNCxr5Hv9poz7ebktPSxr/4H/b7ZxYNZn1o97bXzomOcOy3rEx18yLOt93/hrw7K++S5XDst68ZV3HJZ1nxw4LOsD274wLGtHD3zvXeefo0tlrsf9bGGemSkAAAAAEyimAAAAAEygmAIAAAAwgZvUAAAAYBXTMWU8M1MAAAAAJlBMAQAAAJhAMQUAAABgAj1TAAAAYBWb0zVlODNTAAAAACZQTAEA+P/bu+84Scpy7ePXtcsuSw6CiCBBRBQRVlwUERPKMWNCMXsMBzMoBjzHxBHPMb56FEygoqIgooggBhQJApKWvCKiYERElLDkDdf7x1O92zvMht6tenp6+H33M5+Zru6pu3qnu7rqrvu5HwAAgAFM6mSK7Zm2nzHs7QAAAAAAAJPHpE6mSJopiWQKAAAAAABozdCTKbbfb/tK22faPtr2O5uKknNsX2r7+7Y3aB67tOWn2Z7V/LyR7T/Yni7pQ5L2sX2x7X2G9ywBAAAAAOhGJvG/iWqoyRTbu0h6gaSdJD1d0qzmrm9IOjDJjpIuk/TB5Sy/hyR3S/qApGOSzExyTDfPAgAAAAAA3JsMuzLlsZJ+kOTOJHMlnShpLUnrJzm9eczXJT3e9nrjLa++xQAAAAAA4F5t2MmUtszX4ucyY0V/yfa+ti+wfcFv5l7dzZYBAAAAAIBJZdjJlLMkPdv2DNtrS3qWpNsk3Wj7cc1jXiHp9CQ3j7e8+fkPkh7Z/Lx33/rnSlpnacGTHJZkVpJZD1nnga08IQAAAAAAalo4ib8mqqEmU5KcL+kESZdK+rFKH5SbJb1K0idsX6oyI8+Hml9Z2vJPSnqj7YskbdQX4lRJ29OAFgAAAAAAtGW1YW+ApE8mOcj2mpLOkDQ7ycWSdh37wGUs/42kHfsWva9Z/i9Ju3SwzQAAAAAA4F5qIiRTDrO9vUqvk68nuXDYGwQAAAAAALA0Q0+mJHnpsLcBAAAAAIBRtVAZ9ibc6wy7AS0AAAAAAMBIIZkCAAAAAAAwAJIpAAAAAAAAAxh6zxQAAAAAALDyQs+U6qhMAQAAAAAAGADJFAAAAAAAgAGQTAEAAAAAABgAyRQAAAAAAIAB0IAWAAAAAIARtnDYG3AvRGUKAAAAAADAAEimAAAAAAAADIBhPo3tFq5eLdYj7ppXLdblq0+rFuvihTdXi/VYb1At1m98R7VY0+RqseZVnIt+k9R7HdZ0o+6uFusG1dtv7Lig3v7wlHn/qBbrCdPWrRZLkqZNqfh+Tr3i3k09vVqsK3NrtVh3Vfw/nOZ617Ju1YJqsaZU/Az79cK51WLNdL19xxkP+89qsR4/5yPVYt39xQ9Ui7XZ4fWOb9as+JrfYOoa1WLN8NRqsaZybR8jjGQKAAAAAAAjLKmXSERBKhAAAAAAAGAAJFMAAAAAAAAGQDIFAAAAAABgAPRMAQAAAABghC2sOLkECipTAAAAAAAABkAyBQAAAAAAYAAkUwAAAAAAAAZAzxQAAAAAAEbYwmFvwL0QlSkAAAAAAAADmJDJFNsLbF9se47tS2y/w/Yyt9X2VrYvr7WNAAAAAADg3mmiDvO5I8lMSbJ9X0lHSVpX0geHuVEAAAAAAAATsjKlX5LrJe0r6S0utrL9S9sXNl+7jf0d21Ntf9L25bYvtf3W+lsOAAAAAAAmo4lambKEJFfbnirpvpKul7RnkjttbyvpaEmzxvzKvpK2kjQzyXzbG1bdYAAAAAAAKoky7E241xmJZMoY0yQdanumpAWSHjzOY54i6YtJ5ktSkn/V2zwAAAAAADCZTfhhPpJk+4EqiZPrJb1d0t8l7aRSkTJ9Fda7r+0LbF9wzq1XtbKtAAAAAABgcpvwyRTbG0v6oqRDk0TSepL+lmShpFdImjrOr/1M0uttr9asY9xhPkkOSzIryaxd1962mycAAAAAAAAmlYk6zGcN2xerDOmZL+lISZ9q7vu8pO/ZfqWkn0i6bZzf/7LK8J9Lbc+TdLikQ7veaAAAAAAAaltIz5TqJmQyJcl41Sa9+66StGPfogOb5X+QtEPz83xJBzRfAAAAAAAArZnww3wAAAAAAAAmEpIpAAAAAAAAA5iQw3wAAAAAAMCKKXO1oCYqUwAAAAAAAAZAMgUAAAAAAGAAJFMAAAAAAAAGQM8UAAAAAABG2MJhb8C9EJUpAAAAAAAAAyCZAgAAAAAAMACSKQAAAAAAAAMgmQIAAAAAADAAGtACAAAAADDCogx7E+51qEwBAAAAAAAYAJUpjZum1JtMyhWzhvOqRZIWpOL/oauF0pqaWi3WP3JXtVhrud7b/y+u97zup+nVYjn1Xoh3ZEG1WDXdPO+2arE8rVooSdINC+u97mvawjOqxZpR8TDldt1ZLdb8hfXez3dPrXfMcafqPa/bUu8I5x+r1dvXP3qTG6rFuvuLH6gWa/obPlQt1rTD318t1hoV56K9o+Jr3lPqvebXNtf2Mbp49QIAAAAAAAyAyhQAAAAAAEbYQnqmVEdlCgAAAAAAwABIpgAAAAAAAAyAZAoAAAAAAMAA6JkCAAAAAMAIS+iZUhuVKQAAAAAAAAMgmQIAAAAAADAAkikAAAAAAAADoGcKAAAAAAAjbKHomVLbhKpMsf1p22/ru/1T21/uu/3/bB+wlN/9mu29K2wmAAAAAAC4F5tQyRRJZ0naTZJsT5G0kaSH9d2/m6Szh7BdAAAAAAAAkiZeMuVsSY9pfn6YpMslzbW9ge3VJT1U0r/ZPt/25bYPs+2xK7G9i+2zbV9i+zzb69R7CgAAAAAAYDKbUMmUJNdKmm97C5UqlF9JOlclwTJL0mWSDk2yS5IdJK0h6Vn967A9XdIxkvZPspOkp0i6o96zAAAAAAAAk9lEbEB7tkoiZTdJn5K0WfPzzSrDgJ5k+92S1pS0oaQ5kk7s+/3tJP0tyfmSlOSWepsOAAAAAEBdoQFtdROqMqXR65vycJVhPueoVKb0+qV8XtLeSR4u6XBJM1Y2kO19bV9g+4IL5/5ulTccAAAAAABMfhMxmXK2ytCdfyVZkORfktZXSaj0ms/eYHttSePN3nOlpE1t7yJJttexPW4FTpLDksxKMmvndR7U9vMAAAAAAACT0EQc5nOZyiw+R41ZtnaSG2wfrlKxcp2k88f+cpK7be8j6RDba6j0S3mKpFs733IAAAAAADDpTbhkSpIFktYds+zf+35+n6T3jfN7/Y85X9KunW0kAAAAAAATxMLQM6W2iTjMBwAAAAAAYMIimQIAAAAAADAAkikAAAAAAAADmHA9UwAAAAAAwIqjY0p9VKYAAAAAAAAMgGQKAAAAAADAAEimAAAAAAAADICeKQAAAAAAjLCFdE2pjsoUAAAAAACAAZBMAQAAAAAAGADJFAAAAAAAgAGQTAEAAAAAABgADWgBAAAAABhhNKCtj2RK4+rcUS3W/aavVS3WuZ5bLdZ9vEa1WFe43t9rfU2rFstytVgzNLVarPUrxrpWd1eLdc38m6rF2my1darFumJqvf/Dndfaslqs66YsrBZLktbP9GqxNnK9WL9eWO9zZYsp9T4vp3tyFuv+eeFt1WJtNWXtarGeMOU+1WJdX/EE5eAbNqwWa7PD6z2vaYe/v1qsd88+uFqs1816V7VY62VGtVh3Zn61WPNJAGCETc4jBwAAAAAAgI6QTAEAAAAAABgAw3wAAAAAABhhCUOmaqMyBQAAAAAAYAAkUwAAAAAAAAZAMgUAAAAAAGAA9EwBAAAAAGCELWSa6eqoTAEAAAAAABgAyRQAAAAAAIABkEwBAAAAAAAYQPVkiu2tbF/ewnr+3fahzc/Ptb19332n2Z61qjEAAAAAAJjoMon/TVSTpTLluZK2X96DAAAAAAAAVtWwkilTbR9ue47tk22vYXsb2z+xPdv2L20/RJJsP9v2ubYvsv1z25v0r8j2bpL2kvQJ2xfb3qa564W2z7P9W9uPq/z8AAAAAADAJDWsZMq2kj6X5GGSbpL0AkmHSXprkkdKeqekzzePPVPSrkkeIenbkt7dv6IkZ0s6QdK7ksxM8vvmrtWSPErS2yR9sNunAwAAAAAA7i1WG1Lca5Jc3Pw8W9JWknaTdKzt3mNWb75vLukY25tKmi7pmhWMcdyY9QMAAAAAAKyyYSVT7ur7eYGkTSTdlGTmOI89RNKnkpxg+4mSDhowxgIt5Xna3lfSvpK0y4Yz9aC1t1rBVQMAAAAAMDEkE7dR62Q1URrQ3iLpGtsvlCQXOzX3rSfpr83Pr1rK78+VtM6gQZMclmRWklkkUgAAAAAAwIqYKMkUSXqZpNfavkTSHEnPaZYfpDL8Z7akG5byu9+W9K6mSe02S3kMAAAAAADAKqs+zCfJHyTt0Hf7k313P22cx/9A0g/GWf41SV9rfj5LS06N/MS+x90geqYAAAAAAICWDKtnCgAAAAAAaMFC0TOltok0zAcAAAAAAGDCI5kCAAAAAAAwAJIpAAAAAAAAA6BnCgAAAAAAIyyhZ0ptVKYAAAAAAAAMgGQKAAAAAADAAEimAAAAAAAADICeKQAAAAAAjLCFomdKbVSmAAAAAAAADIBkCgAAAAAAwABIpgAAAAAAAAyAZAoAAAAAAJh0bG9o+2e2r2q+bzDOY2ba/pXtObYvtb3PiqybBrSNuZlXLdZpU26pFuuZ89etFuu0aXdUi3UfTasW68L5N1SL9dSp96sW6zrNrxZrXsWGWDMq5ohfMHWzarHWW1AtlM5d7c5qsVZzvb9X7bZsG3p6tVgLq0WSNp2yRrVYt1XcT62tqdVi/T13VYu1q9evFmuDivupM6bcVi3WvIrvsK21ZrVYa8rVYq1RcSf1ulnvqhbryxd8olqs1zzyndVireV6p4gbV/ysnOxCA9qleY+kU5J81PZ7mtsHjnnM7ZJemeQq2/eXNNv2T5PctKwVU5kCAAAAAAAmo+dI+nrz89clPXfsA5L8NslVzc/XSrpe0sbLWzHJFAAAAAAAMBltkuRvzc/XSdpkWQ+2/ShJ0yX9fnkrZpgPAAAAAACYkGzvK2nfvkWHJTms7/6fSxqvX8J7+28kie2ljoeyvamkIyW9KslyByiSTAEAAAAAYIQtzOTtmdIkTg5bxv1PWdp9tv9ue9Mkf2uSJdcv5XHrSjpJ0nuTnLMi28UwHwAAAAAAMBmdIOlVzc+vkvSDsQ+wPV3S9yV9I8l3V3TFJFMAAAAAAMBk9FFJe9q+StJTmtuyPcv2l5vHvEjS4yX9u+2Lm6+Zy1sxw3wAAAAAAMCkk+Sfkp48zvILJL2u+fmbkr456LpJpgAAAAAAMMKiydszZaJimA8AAAAAAMAASKYAAAAAAAAMoLVkiu1b21oXAAAAAADAREXPFAAAAAAARtjC0DOltpWqTLF9vO3ZtufY3rdv+aebZafY3rhZtp/tX9u+1Pa3m2Vr2f6q7fNsX2T7Oc3yf7d9nO2f2L7K9sf71v002xfavsT2KctZz8OaZRc3cbdd+f8iAAAAAACAxVa2MuU1Sf5lew1J59v+nqS1JF2Q5O22PyDpg5LeIuk9krZOcpft9Zvff6+kXyR5TbPsPNs/b+6bKekRku6SdKXtQyTdKelwSY9Pco3tDZeznjdI+kySb9meLmnqSj5PAAAAAACAJaxsMmU/289rfn6ApG0lLZR0TLPsm5KOa36+VNK3bB8v6fhm2b9J2sv2O5vbMyRt0fx8SpKbJcn2ryVtKWkDSWckuUaSkvxrOev5laT32t5c0nFJrlrJ5wkAAAAAALCEgYf52H6ipKdIekySnSRdpJLEGKs3aOuZkj4naWeVKpbVJFnSC5LMbL62SHJF8/i7+taxQMtO+Iy7niRHSdpL0h2SfmR7j6U8l31tX2D7gj/e+qcVePYAAAAAAODebmV6pqwn6cYkt9t+iKRd+9a1d/PzSyWdaXuKpAckOVXSgc3vri3pp5LeatuSZPsRy4l5jqTH2966eXxvmM+467H9QElXJ/mspB9I2nG8lSY5LMmsJLO2XHuL8R4CAAAAAMCElkn8b6JamWTKTyStZvsKSR9VSXRI0m2SHmX7ckl7SPqQSq+Sb9q+TKWC5bNJbpJ0sKRpki61Pae5vVRJ/iFpX0nH2b5Ei4cTLW09L5J0ue2LJe0g6Rsr8TwBAAAAAADuYeCeKUnukvT0ce5aeym/svs467hD0uvHWf41SV/ru/2svp9/LOnHK7iej6okegAAAAAAAFq1UlMjAwAAAAAA3Fut7Gw+AAAAAABgAliYidtbZLKiMgUAAAAAAGAAJFMAAAAAAAAGQDIFAAAAAABgAPRMAQAAAABghEX0TKmNyhQAAAAAAIABkEwBAAAAAAAYAMkUAAAAAACAAdAzBQAAAACAEbYw9EypjcoUAAAAAACAAZBMAQAAAAAAGADDfBobTlm9WqwHZ0a1WCetdku1WA/R2tViTZGrxXrgauvXi3VXvfK8B7je2//qafWe1xTXe23MqxdKp069rVqsWxbeXS3WcxZuUC3Wm64/tVosSXrQ+pvVizXjvtVibTdlnWqx1qt4mDK1WiRp5/n1Pi9r7n/nTLmjWqyNPL1arIXVIklnzft7tVgbTF2jWqw7Mq9arPUqHme/5pHvrBbrq7M/WS3WgivOqhYrN/+jWiygbVSmAAAAAAAADIDKFAAAAAAARlhEA9raqEwBAAAAAAAYAMkUAAAAAACAAZBMAQAAAAAAGAA9UwAAAAAAGGFJzbnHIFGZAgAAAAAAMBCSKQAAAAAAAAMgmQIAAAAAADAAeqYAAAAAADDCFirD3oR7HSpTAAAAAAAABjCyyRTbm9g+yvbVtmfb/pXt59m+j+1Tbd9q+9BhbycAAAAAAJhcRjKZYtuSjpd0RpIHJnmkpBdL2lzSnZLeL+mdw9tCAAAAAAAwWY1qz5Q9JN2d5Iu9BUn+KOmQ5uaZth80lC0DAAAAAKCihJ4ptY1kZYqkh0m6cNgbAQAAAAAA7n1GNZmyBNufs32J7fOHvS0AAAAAAGByG9VkyhxJO/duJHmzpCdL2niQldje1/YFti/47dxrWt5EAAAAAAAwGY1qMuUXkmbYfmPfsjUHXUmSw5LMSjLrwets3d7WAQAAAACASWskG9Amie3nSvq07XdL+oek2yQdKEm2/yBpXUnTm8f9W5JfD2drAQAAAADozkLRgLa2kUymSFKSv6lMhzzefVvV3RoAAAAAAHBvMarDfAAAAAAAAIaCZAoAAAAAAMAARnaYDwAAAAAAkBJ6ptRGZQoAAAAAAMAASKYAAAAAAAAMgGQKAAAAAADAAOiZAgAAAADACFtIz5TqqEwBAAAAAAAYAMkUAAAAAACAAZBMAQAAAAAAGAA9UwAAAAAAGGERPVNqozIFAAAAAABgAFSmNO7OgmqxFlaLJP19/m3VYj126rrVYs11vczr3RX/YlOrRZJuqZhKnSZXi3V3xaz8tIoXAOZqXrVY/1xwe7VYd07ZoFqs2tdrNlu93nOb4Xp7j41SL9aNrvfZPLXifqqm9RbWe17Xp96+Y/rUtavFqnnlcUHqHXPU3G94Sr3X4Z2ZXy3WWq53KrXgirOqxZr60MdWi7Xw2quqxQLaRmUKAAAAAADAAEimAAAAAAAADIBhPgAAAAAAjLCEBrS1UZkCAAAAAAAwAJIpAAAAAAAAAyCZAgAAAAAAMAB6pgAAAAAAMMIWip4ptVGZAgAAAAAAMACSKQAAAAAAAAMgmQIAAAAAADAAeqYAAAAAADDCEnqm1DaylSm2N7F9lO2rbc+2/Svbz7O9Z3P7sub7HsPeVgAAAAAAMHmMZDLFtiUdL+mMJA9M8khJL5a0uaQbJD07ycMlvUrSkUPbUAAAAAAAMOmM6jCfPSTdneSLvQVJ/ijpkDGPmyNpDdurJ7mr5gYCAAAAAIDJaVSTKQ+TdOEKPO4Fki4kkQIAAAAAmKwW0jOlulFNpizB9uck7a5SrbJLs+xhkj4m6d+GuW0AAAAAAGByGcmeKSrDd3bu3UjyZklPlrSxJNneXNL3Jb0yye+XthLb+9q+wPYFv7v1D91uMQAAAAAAmBRGNZnyC0kzbL+xb9makmR7fUknSXpPkrOWtZIkhyWZlWTWg9beqqttBQAAAAAAk8hIJlNSJtF+rqQn2L7G9nmSvi7pQElvkfQgSR+wfXHzdd/hbS0AAAAAAJhMRrZnSpK/qUyHPJ4P19wWAAAAAACGJTSgrW4kK1MAAAAAAACGhWQKAAAAAADAAEimAAAAAAAADGBke6YAAAAAAABpoeiZUhuVKQAAAAAAAAMgmQIAAAAAADAAkikAAAAAAAADoGcKAAAAAAAjLKFnSm1UpgAAAAAAAAyAZAoAAAAAAMAASKYAAAAAAAAMgJ4pAAAAAACMsIX0TKmOZErDcrVY0yrGmpcF1WLdVe9pVXWX6v0f1rSg4t+r5kvjTtX7IKn5vKa5XiHhWlOmV4t16ySuj1zL06rFWl1Tq8Wq6TYtrBZrrYrFujVf9ndX3FHNW1jv83Jj1Xt/za14HDBjSr1D86kVX4lrV/wMm1/xOGBj1/u8zM3/qBZr4bVXVYs15f7bVosFtG0SH8YCAAAAAAC0j2QKAAAAAADAAEimAAAAAAAADICeKQAAAAAAjLBU7BeEgsoUAAAAAACAAZBMAQAAAAAAGADJFAAAAAAAgAHQMwUAAAAAgBG2MPRMqY3KFAAAAAAAgAGQTAEAAAAAABgAyRQAAAAAAIABjGzPFNubSPq0pF0l3Sjpbkkfl/RXSYf1HibpoCTfH8pGAgAAAADQsdAzpbqRTKbYtqTjJX09yUubZVtK2kvSTyXNSjLf9qaSLrF9YpL5Q9tgAAAAAAAwaYxkMkXSHpLuTvLF3oIkf5R0yJjHzZBEig4AAAAAALRmVHumPEzShUu70/ajbc+RdJmkN1CVAgAAAAAA2jKqlSlLsP05SburVKvskuRcSQ+z/VBJX7f94yR3DncrAQAAAABoXxiQUd2oVqbMkbRz70aSN0t6sqSN+x+U5ApJt0raYbyV2N7X9gW2L/jdrX/obmsBAAAAAMCkMarJlF9ImmH7jX3L1pQk21vbXq35eUtJD5H0h/FWkuSwJLOSzHrQ2lt1u8UAAAAAAGBSGMlhPkli+7mSPm373ZL+Iek2SQeqDPd5j+15khZKelOSG4a2sQAAAAAAYFIZyWSKJCX5m6QXL+XuI2tuCwAAAAAAuPcY2WQKAAAAAACQEhrQ1jaqPVMAAAAAAACGgmQKAAAAAADAAEimAAAAAAAADICeKQAAAAAAjDB6ptRHZQoAAAAAAMAASKYAAAAAAAAMgGQKAAAAAADAAOiZAgAAAADACKNjSn1UpgAAAAAAAAyAZAoAAAAAAMAASKYAAAAAAAAMIglfK/klaV9iEWsixCMWsYhFLGIRi1gTJ9Zkfm7EIta9LRZffC3ti8qUVbMvsYg1QeIRi1jEIhaxiEWsiROrdjxiEYtYQGUkUwAAAAAAAAZAMgUAAAAAAGAAJFNWzWHEItYEiUcsYhGLWMQiFrEmTqza8YhFLGIBlTnJsLcBAAAAAABgZFCZAgAAAAAAMACSKQAAAAAAAAMgmQIAAAAAADAAkikryPaGy/oa9va1xfaaw96Gttlew/Z2Q4g7xfa6teNOBran297R9sNtT+841v1s72X72bbv12UsYGl4HWKs5jNkt4rxXrgiyzAxTNa/l+21bE/puz1lMhyb2t7G9urNz0+0vZ/t9Ye8WSOjeR1MaX6ebnvnyXT+hdFFMmXFzZZ0QfN97NcFXQS0/doxt6fa/mBHsXaz/WtJv2lu72T78x3F2t/2ui6+YvtC2//WUaxnS7pY0k+a2zNtn9BFrGb9RzXPbS1Jl0v6te13dRTrCNtfHfvVUazHj/fVUaxnSvq9pM9KOlTS72w/vaNYr5N0nqTnS9pb0jm2X9NRrMfa/pnt39q+2vY1tq/uIM6DbR9u+2Tbv+h9tR2nL9Ypti9vbu9o+31dxGrWv6bt99s+vLm9re1ndRDnsc17WLZfbvtTtrdsO05fvCqvQ9szbB9g+zjb37P9dtszOohzou0TlvbVdrwm5gttr9P8/L7mOe7cUazZtt9se4Mu1t+TZKGkz3UZY4z/XMFlq6z5/1u/7/YGtt/UcoznL+urzVh9MavsoxrV/l5Snb9Z4xRJ/cmTNSX9vIM4kup9Nkv6nqQFth+kMgvNAyQd1UGccdl+SEfrnTbOso1ajvFcSX+T9Ffbz5H0S0mfkHRpc5wPDA2z+Uxgto+StL6k10raUNLXJJ2e5J0dxDpX5SD+hCSPaJZdnmSHDmJdkmQn20+V9HpJ75d0ZJLWD3xtz5a0h6TT+p7XZUke3nasZt0XJ5lp+2WSdpb0Hkmzk+zYQawX9N2cIel5kq5Nsl8HsU4cE+tRKs9rjw5i/UbSs5L8rrm9jaSTkrR+IGD7Skm7Jflnc/s+ks5O0nolU/O83q6SgF3QW96L3WKcSyR9cZw4s9uM08Q6XdK7JH2p6/1Gs+5jVJ7XK5Ps4HK18uwkM1uOc6mknSTtqLLf/bKkFyV5Qptx+uJVeR3a/o6kuZK+2Sx6qaT1k7R6Ndt27//p+ZLu1xfvJZL+nuTtbcZrYl6aZEfbu0v6sMqB9geSPLqDWA+S9GpJ+6hcTDlC0snp4IDK9icl/UrScV2sv4nxdEnPkPQiScf03bWupO2TPKqDmBePfd/avqi3H2kpxhHLuDtJukhYdr6PGsbfq4nb+d9sGXHusazFeLU+my9MsrPLBbY7kxzSxf/fMuL/KckWLa7vSZKOVDkmvFDSvkn+0Nx3YZvH9LYvkvR0SWtIukTSLkmubC5yfC/JrLZiAYNabdgbMIps7yWpd1X+tCQ/7CJOkpfa3kfSZZJuk/TSJGd1EauJ92fb/YsWLO2xq6gX5BkqSZQ5HhO4RfOS3Dxm9V1mEKc1WfrnSjo0yTzbncRL8r3+27aPlnRmR7GWyPzbfoCk/+silqS5vURK42qVE8Au/HPMuuc2y7pwc5Ifd7TufvOTfKFCHElaM8l5Y95f8zuMt02SfWy/RJKS3N7RvmN+kjRXwA5N8hWPqRRsWa3X4Q5Jtu+7fapLRWKrkpwuSbb/35iD3BNtd1LJqcWfV8+UdFiSk2x/uItAzf7pvbbfL+lZkr6qcsX5CEmfSfKvFsO9XtIBzfrvUPn8TJI2h5Beq5IU2kvlhLJnrspJZhem2nYvQWR7qqRWh3QmeXWb61tBNfZRw/h7SRX+Zo3bbO+c5MImziMl3dFBnJ5an83zmtfFqyT1jqnuUdWxKmx/dml3qVycbdPHJT21OYbfW9LPbL8iyTlafJzfmiTXSYuSQlc2y/7oviFhwDCQTBmQ7Y9K2kXSt5pF+9veLcl/dRBrW0n7q5QGPlTSK5os9u1tx5L0Z5ex2WmSAftLuqKDOJI02/bJkraW9J8updkLO4o1x/ZLVQ4CtpW0n6SzO4olSV+S9AeVzPkZTdb8lg7j9dtW0n0rxfqLymuyNX1l1xfY/pGk76gkvl4o6fyWYx3Q/Pg7Sefa/kET6zmSLm0zVp9TbX9C0nGS7uot7B0wtujEpvT6+2PitHmC13NDUznUO7jeW6UUtyt3216jL9426nuOLZpr+z8lvULS45qDtVYPescY93XYe50m+VRLcS60vWtzsCvbj1ZHw1Qba9l+YJKrm3hbS1qro1h/tf0lSXtK+phLb4LODrJt76hSnfIMlc/ob0naXdIvJM1sK06Sddpa1zJiXCLpkqYadjVJW/ROVjr0E0nHNH8zqSSNftJFINubSPpfSfdP8nTb20t6TJKvdBCu831U39/rW0m6TF6PVetv9jZJx9q+VuWk/H4qVWCt8uJhgLU+m18t6Q2S/ifJNc3+8MgOYrxD47/mXtJyrOlJ5khSku/avkLScbYPVAcXLW1PaYY+vqZvWVcJPWCFMcxnQE3598zmDd17I1/U0TCO30h6S5KfN1c2DpD0miQP6yDWRpI+I+kpKh9eJ0vav+0yxybWFJWDzauT3OTSQGrzJK2fxDYltu+V1OvJ8lNJH05yZ9uxlrENq3VxwGN7rsoHlpvv10n6z7EVKy3FOkSLPxx7f78/JHl5izGqlWR7Ob2Hkvx3W7H6Yp46fqh2h0rZvmYpcR7YZpwm1gNVxn7vJulGSddIenmv1LeDeHtKep+k7VX2UY+V9O9JTms5zv1UhsCcn+SXtreQ9MQk32gzTl+8Kq/H5mB3O0l/ahZtIelKlWqitP05ZvtpKq+Pq1X2U1tKen2Sn7YZp4m1pqSnSbosyVW2N5X08CQndxBrtqSbJH1FpcT8rr77jkvSWj+O5rP/ZZK2TnJwUxW4aZLz2orRF+vZkj6pcpK0te2Zkj6UZK8OYk1RORl/crPoZ5K+nKT1iljbP1YZivXelCHGq6kct7U+3LfWPqqJdY3GOWntYl/fxKv5N5umsq+SpCuTzOsgxnifyT2tfzY3MddQh8lKl/5o70tyj4uGtq9JsnWLsS5QGZJ9Xd+yzSX9UKVCq7VEsO1dVPbtd45ZvqWkxyX55vi/CXSPZMqAmmTKE3tXeZtEwGkdJVPWTXLLmGUPTvLbtmPVZPuxki5Ocpvtl6v0FvlMkj92EOtxKuOVF/QtW1Q+2kG8D4y3PMmHuohXi+1X9d2cr5JI6WzIWW2215akJLcOe1tGkUuz1ilJuhqO1R/rPpJ2VTk5PyfJDR3F2VLStk0ye01JU2s8vy55OU10O9oHry6p1+/oN/2Jhw5i7a7yNzvC9saS1k4yXnJxVWJMkfSeJP/b5nqXEe8LKpWbeyR5qEvT25OT7NJBrKo9xmqxfX6SXdzXn8Ld9uCotY+6T9/NGSpVnBsmGfc4ZKLzcpoCJzmuo7iLqueWtayFOJ0nK5tzkjuSdDksqhfrKZL+0VRK9S9fT+VC8P+0GOs5KhddP9fcPlfSxs3dByY5tq1YwKAY5jO4j0i6qMloW6V3yns6irWG7U9L2izJ03qlqZJaT6Z4/HGWN0u6IMkPWg73BUk72d5JpRzxy5K+IamL5o4/lXS+7Rcmub5Z9mWVBE4Xbuv7eYbKePpWh0t5OTNUdJEoSvL1tte5NM2VjUNUruhJpWv7/kn+0kGsHVTKbDdsbt+g0jhwTgex1pP0QS3ut3S6yoHUzR3E2kHlyuiimVq6qKpwmdnhlZK2krSam9YA6aAJcp/NJE1V+fx6vO3WD7Jt/4ekfVVeF9s0Mb+oxVdkW9V8nox3hbntK6PjXj1J8qfxlq8s23sk+cU4J0fbdPH3amJ+UNIslavZR6gMy/qmFu9HWpFkYfO8qiRTJD06pWnlRU38G93ddPGd9xiz/Z0kL7J92Xjr7uLClEoPjvv04tneVeX4piud76OkcRuk/l+TEGs1mbK0v1XfdrT1N1vWrCxRGYbThe/qnseEx0p6ZMtxDlJp3n+aJCW5uKnubNPjJG2uZhawMUmHdyf5boux1lLZ314yTqwDW4wjSe+W9OK+26urtFxYS2V/TzIFQ0MyZUBJjrZ9msqbWCoZ0euW8Sur4mtqSlOb279V6dzexTjfGSpXD3s7pBeolOzvZPtJSd7WYqyazR2vVJnV4XTbr21KH7tqdqsk/6//tstMDG2XtPdizFA5ebhE5TntqNL/4DFtBap4ENXvCJXpAnszjLy8WbZnB7EOk3RAklMlyfYTJR2uMmylbV9VmS77Rc3tV6g8r1an6GxOKp+okkz5kUoH/DNVEpZt+5Gkc1SaZHfV92gRl6m/d5Q0py9eFwfZb1Y56D1XkpphI132I+qfoW2Gyv63i14IJ2nx0MAZKn2rrpTU9tDRJ6j0Dhnv5Kirk6LnSXqEyqwSSnKtm6mSO/Bz2+9U+TxelEBPN32J5rkMJ+4lAjbWaPcY27/53tV0weM5QNIJKsm8s1RO+PbuIlDFfdTYCytTVI4Hujiur/K3SuWGwS5TBT9M0npjEr/rqu9CRIvGS1a2/V5eXtKhzWRKzQTH9CR/7rt9ZpNM/GdTGQsMDcmUlbOLFl9djqQTl/HYVbFRku+4NEJUkvm2u5phZ0dJj+0Nh2lKi3+p0lDvspZj1WzumCQ/dJl69JjmQKfm2LY1Va4StCbJk6QyNl/Szkkua27voHLlo029g6g3N997zdJeru7+HzdO0t8/5Wu239ZRrLV6iRRJSnJahx/M2yTpn876v21f3EGcvVWm9b0oyatdmi92NZ54RpIDlv+w1uyaJWej6cpdSe7uHfS69FjobL+Re05bfZbt1ntijB2u0ZyMvamDOB9svtc8Obq7SdL3kg5dHmD3mmG+uW9ZJHXRq+KzKs2k72v7f1Te3+/rII4kvVXl4s1dko5WuRBwcJsBkvQaVL8pyRJXr21/TC1f0W4SUU9ovrZTSSR20oOjUWsfJS2+sCI1w2+1OFnfmi6G/y2P7WeqJDr6qyvbHi69ncoxzvpaMvE7V9J/tBxLqpOsrJl0qBlrg/4bSd7Sd3NjAUNEMmVAvudsPvvZfkw6mM1HdUtTN5C0dt/611IZe7vAdttj3PdRae74miTXuTR3/ETLMXosLbqy/HiV6oAuqilKsCUrOaaq7ORbPRjts10vkSJJSS633eoMO72DKNt79saaNw60faG6GeL2T5deOkc3t1+i7qYrvtpletP+JFGr46T73GF79yRnSot6B3UxrvmOZijCfNvrSrpe0gM6iCNJRzZDYn6o7mcOkqRf2d4+SevT+Y5xuu3/UhlquadKwqGrpHlvnHvPFJXy8vW6iteT5EKXGX06U+mkSJK+4zLLyPrNa/I1KlVmrUuLTRxXINa3mqEbT1b5PHtukk5m2kuZKfC9WlwN26U9dc/EydPHWbZKmmOYlyT5tEq1SNdq7aMWXVippTkGPURlJr/pKsc4t6Xdabpl+4sqF6KepDIse29JXSSXfyDpB80x/K/aXv84+pOVR6mZEKHlGDWTDjVjnWv7P5IssU+3/Xp18NoABkED2gG57mw+O6t8cO2gMjxgY0l7p5tZb16rcrXrNC3uBfO/Kie0ByV5V8vxhtbc0fYWbfcI6Ft3f4PH+ZL+no6mLrR9tEqJea/q4GUqDRfbnv5OTQXFm9M0nXWZRvvz6aCBX/N/eIjKcKWoXLnZr4u/mUszx/9WqcCSSjXWQUlu7CDWTElfVzlJtqR/qczycMmyfm8l4nxe0n+plN++Q9KtKg2fW68SsP1mSf+jMrNJ78Mk6W42iSeolOtfp3JAanUzC40lvU5lFjCrHPR+OR19YHrxrBxW2W9co9JP58yW4/RXEfWSNhsmeWqbcfrijXtSlKSTYZ1N4mvR3yzJzzqKs6bK0JEtkuzbXGXeLskPO4o3VdIm6rsA1tH+8MEqQ862GhOrtd49tt+okpx8oKTf9921jqSz0uIMcX0xP61S/Tp2WFbr/cVq7aOaWNX6cDXxLlD5XDlWZUjRKyU9OMl/thzn0iQ79n1fW9KPkzyu5Tj9sxTeQ7rt/dUJ299SaSA9XtLhiW0eH1aOdV9Jx6u8p3rv20eqDC16bpK/txULGBTJlAG57mw+L1Q5iH+Ayhj6R0t6fxcHAE28+6sMvblCpUrlL0nO6CDOouaOSbZpDkS/mKS15o62353k4x6/sW5nH5K2j0zyiuUtaynWDElv1OIDqTMkfSEdTPts+5EqVT29q+U3qVQWdfJanMyaahFlzExdHcXaStK6XSRgm/VfLelR6Wi2inHi/U7lJHaJHi1tlqE3J65zkjxkuQ8eMV5yCubesIDvdbHPaOJVOSmqzfYxkmarNKveoUmunN1RcvmtKifMf5e0QN2enF+i0mh5dhNL0rjD0FYlxnoqV7Q/oiUrG+d2VdHmStPSN7E630f1xfqeyoW2XoP4V0jaKS1OzT0m3gVJZvXez82yi8ZUrbYR57wkj7J9jkpPsX+q7JMf1HKcVy3r/rTceN/2zyS9MMlNze0NJH27zWR2zaTDMBIctvfQ4h5fc5L8ou0YwKAY5jO4mrP5vD/Jsc0O90kqU6p9QSWp0irbr1NpDLe5pItVpvX7lco0iW2r0dyxVwbd2kHgClqikaNLr4W2O8JLkpLc2Vz5/VGSK7uI0Rdrtkoz4vWa213MQNNLgI13tSgqlRzfTPL7e/72wLH+L8nbbJ+4jFhfSnLOqsbqi7m/SlO2uZIObyrP3pPk5JbW/5Akv/E4sz25u+nAfyfp9g7WuzT/SHJClwGaYQFXdlnBNlaTOP9Jkrm236cys8SH2/6bJfnvvphTVCrZOkmkNHrD2G5vkvX/lLRpmwFsn5lkd9tzteR7uZd0aHUIQmObJPvYfolKkNubaqYu7K9S9dLVUMd+85N8ocsAzWfHzZJeMqbiZm3ba3fxnqs8HKbzfVSfWn24em53mUnqYtsfl/Q3lQq3Vrj0Rjtb0gkuM8V9XOUkPSqVba1qO1myAjbqJVKa+De2feybMmvlbmOSDid1kXSoGasv5i9UmpsDEwbJlAGl7mw+vStDz5R0eJKTbLc9vrJnf5XndE6SJ7l0Oe9q6sfOmzsmObH5vujDsu/kofWKAJeGur0eC731W9LdKjPGtM72Xiq9ZqZL2roZRvKhJHt1EGsTldfD/ZM83c003UnanFmqlwC7YCn330dlRoSdWojV65HyyaXcv5FKJU6bjQRfk+Qztp+q8lxe0WxHK8kUlSE9/6ElmxL2RN0kRm9TObA+VUv2TOmqPPoi20ep9C/pj9f2TBkbqDQLPE9LDgto/b3V6CXOd5f0FJX3deuJ8+b/7g0qny3nS1rX9meSdNWz6od9J0W9xHarJ0VJdm++dzVzz3jutr2GFvcz20Z9r8eW/VndTuPb70Tbb1JpeNtpDyTbb1FpmP53LTnrTRcVN+urbwr33vKO9lO19lFSvT5cPa9QSZ68RdLbtbhqui2bS/o/lZ4se0o6S+Uz7ewuk4kuM2QdqPJ539/bqe3PzIX9SXqXIc2dDA+omXQgwYF7O4b5rATbm0naUkt+KHcxHOaHkv6q8qGys8qH5HlJ2jiZHBvr/CS7NFc1Hp3kLttzkrQ9ZaaaKxo3qRzcvFVl/PSvk7Te9G68kwdJnZ082P5IWh4/vIxYs1VOkE/rldnavixjZuxoKdaP1UzTnWSnJgF2URexlrMdr0/ypRbWs9yqA9vP7iXl2tA31OEzKn+z73dRIl3T0sqku7riZ/uIcRYnyWtajvOE8ZYnOb3NOH3xLkryCNsfkXRZkqM6Kp+/OMlM2y9T+Ux5j6TZXQwZaeKtoTIU8XEqJw2/VHdDEWsOsdxTpcfY9irJ0Meq9D86rcUYvf42D1OZdeQkLXly/qm2YvXFvGacxUkHPZCa4TCPrlFxY/tsjTOFexf7qVr7qCbWTN2zD9er0tGwzibmxpKU5B8dxpiu0pNlN5XeaY+RdFM6miXJ9skq/XTeqXK8+CqVCqO2Z5Z6msrFtdNV/l6Pk7Rvkp+2GQdAXSRTBuQydd8+Kl3hF11N6agaYE1JT1M5uL7K9qaSHt7WsIAxsb4v6dWS3qZygn6jpGlJntFBrGrNHWufPDQxN5C0rZa8wtFFsu2cJLv2n3S5byxzy7F6ybb+WBenxR4BtpdZGt3me8z2hUl2bn7+3phS6U40B9mbSdpapbpmqkpSpZVhYLaXOU6+oyujaEGtxLntOZJmqswkcWiS021f0kWCvon3HZVhbb0m2S+VtF6S1qdv7X9PN7dXk3Rphydg91EZDmuVis5W+wZ5yf4295C+IVstxZui0s/hmDbXu4x4p0raMx01aB8Ta4nXxmTjjvtwNcdsH1SpSJkiLWqUfUg6mJnLZTjxY1SSlI9Rmbr4snQ01brt2Uke6SV7wZyfZJfl/e5KxNpIZb8hdbDfAFAfw3wG91yV8ctdlfQukjJN4XF9t/+mMka1i1jPa348qDnIWU/ST9qO4yWbO3YybeUY02xPU/m7HZpknu3OMoiu23tmju2XSprq0sR3P5Xxxl2oMU33Y1RK2o9W6afTVQ8CjVl3JzPPjOO1KieyV6f0WLiPSgKzLc9uvt9X5Yper+z2SSqvi9aSKba/k+RFXnIq8EXaTuh52f10Wi/X95L9N6arzATS+hSgfV6kkjj/ZJKbmsR5qzOoNb6k0nT2EklnNGXmXTZC3mFMMuNU261OGTukIZaPVZkh6ySXadz/qxku1VqT0baTJSsQb6Htd6lcoa/hakmn2e684kYVpnCvvY9qYi4xm4/trmbzebtKYmOXJNc0sR4o6Qu2354y7fQqs32YSiXWXJVjgLMlfSodzK43xrzm+99cpnK/VtKGy3j8qlhdpYJoNUnb2+7kYhuAekimDO5qlQPrzpMpw9JVKXuz7trNHWufPNTsPfNWSe9VeS0erVLhc3BHsQ5Qme5xG9tnqZmmu+UY91O5Mv8SlSvYJ0k6OsmcluNISx7sVinPa05WrpH0YJeZmNpe/6ulRSXL2zfJVzUn5l9rOdz+zfdntbzepVleP51Wpa//RnNV9jlafDWxNS6zwfWc1rfsLnXwXJN8VlL/DGd/tN1lc84Lbe+appGz7Uer5eeV5COSPlJziKVKP5udbO+ksm/8iqRvSBp3eNiq8PhNsm9W+X/8UstDpn5u+5265xTCXcyy86fma3rz1aW7VfoQvVd9U7ir3UR61X1U46sqs/n0Kr1eoTIct+3ZfF6hUkW0qIoiydVNIvFkSa0kUyRtoZJsuEqlUu8vKkPCu/bhJjH1DkmHqAwHf3vbQZZW2a4yEyOAEcUwnxXUd7VhM5US/VNUp+HipGP7DEmPkFSruePY+Kt1VVrsir1navCSzdJWUxm7b0lXJpm3zF9etbirqyRVPiHpv5Mc2vL6F6i89ixpDS2ekaazGUCWVrWUlpvc2b4iyUP7bk9RqQZ76DJ+bWVjfWzsuPLxlrUY74VJjl3eso5id9HD5BqVz5XxqrBa71Xhuo04ZfsKlX1GL3G+haQrVYYIpI0KJi9jFiuVIK3PYtUbNmL7A5L+muQrXQ0lcemxtLFKwlwqJ2O3qLxu1k2LPWFcsWdKTa44hXvNfdR4Q23bHn7brPPyJDsMet9KxrJKdcpuzdcOKpUcv0qyzKFvE53tKyXtWKOyHUA9VKasuN7VhtkqV+ix8t5fK9DSTh5UhsR04S9NzOMl/cz2jZJaK/2W6vYWUXkevROEY7ruLdIkUZ6pkkjZSuUq+vfbjpNkatvrXAG1qpZOsf1TLXny9fMO4kilkmhs4uTp4yxry39KGntSMt6yVTKm/8wUlWaIrTdNTbJ12+tcjh9pnEacHXpahRgHSNpXdWexmtsML3q5pMc3CctpHcSRpN3G9G44sS9p32rVXs3Xo0sj03ernDh3OYOKVHcK9yr7qEat2XzuXsn7BpZyhfdy2zepVGDdrFIB+SiVIU2ts/1glWqzTZLsYHtHSXslaXv2zElf2Q7cG5FMWUFpur7bXkvSnUkWNLenqpQlYgV1OYxoHFVPHpbSe+bHLYeZlL1FbH9D5SrUj1SqUS7vMt4Q3JnkTtuyvXpzNX27toMkeYvt56kZRy/psCStJqRsv1FlFq4H2u6fOWIdleksW2X76ZKeIWkz2/3DVNZVqXJo27P7fp6vMlTwOR3EWcRlqvPe3+y0JD/sIMyMJAcs/2HtaLOHyDJi7Nt873K40lj7qAxFfG2S62xvoVJF14W1x1QIbiFp7ea+Vk9kXZreHyBpiyT7Nr24tuvotfgtleFEz1LfDCodxJEqTOE+hH2UVP7fvtEMUZHKxAHjzrC2inbq60fUz+pLhK0q2/tpcUXKPJWeKWerDGe6rK044zhcpUfVlyQpyaUuM0G2nUy5XeV1SGU7MImQTBncKZKeIunW5vYaKmNGdxvaFo0IL9nU8R46au5Y9eTBfVNx9pJGto9UGXPclsnaW+TlKge9+0var1T7Supw6E1lNaqW+hs8t17R0+colSThR1RmyOqZ21F/hWtVqgP3UqkOXBRPHYxtT0ezRiyN7Y+qVC19q1m0v+3dkvxXy6E6b8Q5LE1S72hJ30ny+w7jTFXZ3y5K3jSJjm90FPIdks60/XuVfeHWkt7UXNhpe2rfI1TeX73jmb+qVFR0kUy5TzM8av/ms/J02+d3EEcq+9zjO1p3T9V9VOPJKq+BXnLtVkm72J6S5OK2glSs5NxK5fX29l7Pr0rWTHJe3zGH1E0C7ARR2Q5MOvRMGVCtMaqTme2DVWYlOlLl4PBlkjZN8oEOYr1d5QCjysnD2HHzzYH3Zelues5J11vk3sD2E9TMmJWk7avLP5D01i4bPI9pnHoPHb6/9pL0wySdVJl5KTNx9HTYW+RSSTN7z6vZb1zURk+RMXHeLOl/VJo6LmrEOeo9MSTJpbn4Ps3XQpWqh+908T5oriw/P+3PmrK0eKtLekhz88qWm872x7kgyaz+/kDuaOps2+ck2bUZkvhZlWTEd5Ns03asmlxmD1xNpbrnyo5jHaUyBPEElc/kZ0m6VE1SIsnHu4w/Wdj+scq0z8c2vZD2Vqk6e3oHsdZQhdcGgHqoTBncbbZ37jW1sz1L3YxRncz2GnNw9gXbl0hqPZmiOl38q0/POcl7i0xatneXtG2SI5qeAZtJGq/p46rYQGXa7C4bPM/W4vfT2GFmrb+/+rxI0qdtf0/SV5P8puX115yJY6z1VRotSiXR1oV3SHpQjUactTVDij4u6ePN8JT3S/qYpC72YbdKusz2z7Tke6zNYSN7JPnFmP49UplRTUlam+q8z93NyV6abdhG3fV3qDKDiiQ1r4ePSNpeS/Zn6WI/9TRJn1SZoWhr2zNVpivuosH+5pJ2TnKrJNn+oEql6uNV9tEkU1bMm1WO0x5i+68qn8kvazuI7Wer3msDQCUkUwa3v6RjbV/b3N5U5UoYVtxttl8m6dsqB20vUd8BacuqnDyk4vSc94LeIpNSc6A7S2V2kyNUGtF9U9JjWw7VeYPnITRO7cV9ue11VfYZX7Mdlf/Lo5PMbWH9bQ+bWFEfkXRR09PBKidD71n2r6yUmo04qxtTnbJApcFpF45rvrr0BEm/0OL+Pf3Jy3QU/yBJP5H0ANvfUtk3dTLkra8Py82Suu53c4RK89JPN7FerdJYugsHqTRLPU2Sklxsu6v95X21ZLJrnkoT1Tts0+R0xf1V5TVyqqQNVWbLepWkD7Uc5yDd87Ux8lWBwL0dyZTBba0yre8Wkp4v6dHqvpfEZPNSSZ9pvqLSsPKlHcWqffLwQ9trJbnN9stVZsL5TMuNGCd7b5HJ6nkq+44LJSnJtbbXaTtIzQbPLi++l0naOsnBTXPM+yU5r6uYSW6x/V2VYWdvU/l/fZftzyY5ZFXWbfv/krzN9okaZ7/e1RXEJEfbPk2lb4okHZjkug5Cdd6Ic1hsn6uSoDxW0guTXN1VrBpJtyyeBvaNkl6gJWek6+SYI8nJtmerTNtuSft3dSGiSTC8VfecpruL99gaSU6x7eaz+KDmeXZRDTsvyc1j+m90dYz4LUnnNkM7pZJ4O6rpp/PrjmJORj9QGfp4ocpws66M99qoMasagA6RTBnc+5Mc2zSSfJJKyd4XVJIqWAFJ/qCOZ8boU/vk4Qsqne93UqmK+bJKY8IntBUgSVdX1NCtu5OkqabozQzWOtu7qpTNP1SlnHiqpNs6SrJ9XuVgcA9JB6s0W/yeFicFWtX0THm1pAepvK8eleR6l1lIfq3yvFfFkc33T67ielbGLlo8m08kndhBjOPVfSPOYXllrT4Etq/R+Mm2Lq4yH6/FJ3q9XimdnJzbPiXJk1WGioxd1rbjJX1F5XXe9QnlXS7TV19l+y0qlQhrL+d3VtYc2y+VNLUZXrSfyow0rWsS2D/W4urGNyTpDVVsfZjKJLZ5khrTuFd7bQCoh2TK4BY0358p6fAkJ9lue/q0SWlIzR2PV92Th/nNCfNzJB3azFbw2orxMQE1FRw/tP0lSes3M6q8RmVKxrYdKunFKlfoZ0l6paQHdxBHkh7dNOy7SJKS3Gh7ekexpHKF/tNJzuhfmOT2Nt5nSWY332tO3z7ebD772X5M27P5DHEYU2dsvzzJNyU90/Yzx96f5FMdhJ3V9/MMSS9UGR7Qhc5P9GzPkLSmpI1sb6DFfZDWVenr1IU7k3x2+Q9beV48u97xKs9vP5Wk7x7qZgphqVTbvFfl4s1Rkn6q9qfYXaRJngyz19NkcLbthyfpcvplacnXxtEqr42DO44JoGPM5jMg2z9Uuaqxp8oQjjsknddFt/vJxnbv4OWxKo3gjmluv1DSr5O8YSgb1iLbp6uMOX+1ylXm6yVdkuThQ90wDJ3tyyQdIOnfVE5WfprkZx3E6c3IcWlvNpj+2TlajnWuyjSq5zdJlY0lndxFrJoqN6ysOZtP1edVg+3XJ/lS05NorCRpu+/B0rZjdpJHdrDewyQd0uWJnu39VYbM3V/l+KaXTLlF5aJRq7PENTFfKmlbSSdryarRC1uM8WtJT1GZxv2JGtMsOx1OCW57zSSTtj/RZNB8JkflwvK2kq5WeS32hky3uv8dE3uqpLWS3LLcBwOY0KhMGdyL1HRrT3KT7U0lvWvI2zQSeldFbb9R0u5J5je3vyjpl13EHMLJwz4q/V9em+S6pofEJzqKhdFyoaSbknS9v7i9qQ652PbHVaYh72poWG8Wqfva/h9Je0t6X9tBbM/Vsqva2h7CVLNhZc/66n42n2E8r04l+VLz48+TnNV/n+22mzv31rtz380pKpUqrR5PjTnRe7Xtzk70knxG0mdsv3VV+w4N4OGSXqFSJdIb5pPmdlu+KOkUldnFZmtx897e99aPA2zvpjK8d21JWzRDfl+f5E1tx8Iqe1bNYC5TWb9BpcL9fEnr2v5MEo4RgRFGZQqqs32lpMf0rgo1ZcXnJNmug1hnavHJw7PVnDwkabXxXFMm/QaVXg6XSfpKL1kESJLt36i8Pv6oJadTbbv6YEuViqhpKlONrifp80l+12acvngPkfRklROUU5Jc0UWcJtbBKsmhI5t4L5O0aQfv59lJHmn7sl5VWVeVB826XyLpoyqzSSyazSfJMcv8xcHjVH1eNdm+MMnOy1vWUqxTtTi5N1/SH1QusPy2xRhbLuv+lpua98fdTfdsCvuNDuL8TtL2Se5ue93jxPpCkjd2HaeJda5KUvmEXoWe7cuT7FAjPiYu2xcnmekym+XOKjO2ze6yAgZA96hMwTB8VPecBvSgjmLV6uL/dZVpCX8p6ekqlTD7txwDo+2pNYL0nWTdIem/u4xl+7OSvp3kc13G6bPXmCGVX7B9idp/P9dsWFlzNp+qz6sG249RGWq2se0D+u5aV6X5cheernvOsPNitTiValfJkmWxfaSkbSRdrMX94aLS7Lltl6tUY13fwbqXUCuR0hfvz2NmbFmwtMfiXmWa7WmSnqvSU29eryE9gNFFMgXVJTnC9k9VSnyvUBnP3NV0dLVOHrbvu9L7FUmdTQ2L0VTr5KjyTCOzJb3P9nYqw32+3TebRBdua67qfVvlOb5EfVU+q2pIDSt7pki6QeVz+cG2Hzy20e7KGvLz6tp0lX36apL6pxq/RaVCoAvH654z7EwGs1Q+y2qc4K0v6Te2z9eSPVM6mX68oj831T1pTpz3VznOAb6kUsV2iaQzmuozeqYAI45hPqjO9utUDjA2V7kCtqukXyVpbax07+TB9rtVpm9dX+XkYT1JH09yTluxmnhLlJN3VV4OLI/t+/TdXDTTSNtDYcbE3FDlSv2LJW2RZNuO4mwl6TMqTawj6SxJb0uZbr2N9Q+lYaXtj6n0W5qjvv4RbZ1YDrMRZy22t6yYsJyUwzZsHytpvyR/qxDrCeMtrz2TVttsb6Syj3qKyvvsZEn7J/nnUDcME5Lt1RgSDow2kimormmst4tKn5SZTc+F/03y/BZjVD15sL1Ai6+QW9Iakm7X4maBbTfIBFZY130xbD9KJRnwHElXJHl2V7G6ZHs/SW9UaUzZm9VkUcPKDmfzuVLSjknuWu6DV279Q3leNdn+maQXJrmpub2BSqVU68PrasywMwzN0NuZKpWVnVeL2N5Ei4e2nZek8yE/XWpmaPlGkpcNe1sw8TQXOj4oaXeV/e+Zkj5Eog0YbQzzwTDcmeRO27K9epLfNMME2lS1i3+SrsbmAwOpMdNIX6yPS3qepN+rTHV+cO9ktqN4R2j8IUyvaWP9ST4r6bM1G1Y2rlZpGNxJMmWIz6umjfpfe0lutH3fjmLtLunfmyF1VaZSreSgWoFsv0hlprvTVP7/DrH9riTfrbUNbUuywPaWtqfXaKyLkfNtSWeoVHFKpYH6MSoX/gCMKCpTUJ3t76vMqvM2lTH7N0qaluQZHcSazCcPwD3UmGmkL9brJX0vyQ1tr3sp8V7Qd3OGSiLn2iT71YjfNtuHqPytNpO0k0oCuL8iYCSf1zA0jcWfl+RPze2tJB3X0Ww+4860M4ymsaOqaRy9Z68axfbGKtNb77Ts35zYbH9D0kMlnaAlZ2371NA2ChPCeMMD+2dWAzCaSKZgqJpx0+tJ+glXcoBVZ/sdWlyFpebnm1WmYLy4g3gbSNpWJblRArbUOHUFYk+RdGaS3WrEa5vtZTZ/TfL1Wtsy6mw/TdJhkk5Xee0/TtK+SX461A0bAbbPTLK77blasvKrs2GqY08im/fyJaN6YtnXp+0mSZ8ee3+STmdWw8Rn+1MqQ+i+0yzaW9KjkrxzeFsFYFWRTAGAScT2USpDe05QORl6lqRLVaZxPTbJx1uM1Xkz6eXE307SSUkeVCNeV2yvpTL8cUFze6qk1ZPcPtwtGy3NsJ59JV2k0rfq+lqJPaw4l3mDv6JSkXV0s3gfSZcmOXBoG7YK+vq0/USlT9sSJkOTZ6ycviSlJa2lxVNlT5V0Kz31gNFGzxQAmFw2l7RzklslyfYHJZ0k6fEq/YNaS6aoJFJ6zaSf1Gsm3eL6lzDOlfPrJI3kydcYp6iciN3a3F5DZRaQkay4GYalJfZUhpJiAkmSpmn1B1T6z0jSYUm+P8TNWlW9Pm1bS+qfHr6TPm0YHUkWTdnezHy3RCUngNFGMgUAJpf7aslGpvMkbZLkDtttNzit0Ux6kf6D0klmRi/5JUlJbrW95jA3aARVTexhlc2W9OckBwx7Q9pwL2nyjFWwlITv2ZKePMTNArCKpgx7AwAArfqWpHNtf7CpSjlL0lHNUJJftxzrL7bXl3S8pJ/Z/oGkzppw2j5lRZaNoNv6Z2GyPUvSHUPcnlF0Z5I7JS1K7EnqLLGHVfZoSb+y/Xvbl/a+hr1Rq4pECpahl/D9Y5InSXqESj8zACOMyhQAmESSHGz7x5Ie2yx6Q5Je2fnLWo71vObHg5pZhNZT6RnQKtszJK0paaOm4W2vue66Kn0XRt3+ko61fW1ze1OVHhJYcWMTezeqw8QeVtlTh70BQGVVKzkB1EEyBQAmmSZ5csFyH7gKmiapc5I8pIl5eofhXq8ylfr9VYYH9PoQzJV0SIdxa9la5SrlFpKer3LVnu7wA6iV2EM7mEYa90IkfIFJiNl8AAArpRnW89Ykf6oU7wOS/i/JLbbfL2lnSQcnubBG/K7YvjTJjrZ3l3SwpE9K+kCSRw950wAALbP9BDUJ3yR3D3t7AKw8eqYAAFbWBpLm2D7F9gm9rw7j7d0kUnZXmaXly5K+0GG8WnpTZT5T0uFJTpI0fYjbAwDoSJLTk5xAIgUYfQzzAQCsrBmSntV325I+1mG8eyQdbH+4w3i1/NX2lyTtKeljtlcXFzsAAAAmNJIpAICVtdrYXim21+gw3mRNOrxI0tMkfTLJTbY3lfSuIW8TAAAAloGeKQCAgdh+o6Q3SXqgpN/33bWOpLOSvLyjuGuqJB0uS3JVk3R4eJKTu4gHAAAALA3JFADAQGyvp9Iv5SOS3tN319wk/xrOVgEAAAD1kEwBAAAAAAAYwGQYaw4AAAAAAFANyRQAAAAAAIABkEwBAAAAAAAYAMkUAAAAAACAAZBMAQAAAAAAGMD/B7yPGBnrdtiiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now that the new values are mapped I can see any potential correlations in the data\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df_working.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the training and test split 70:30\n",
    "x= df_working.drop('G3',axis=1)\n",
    "y=df_working['G3']\n",
    "x_train,x_test, y_train,y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_G3_score = LinearRegression()\n",
    "\n",
    "regression_G3_score.fit(x_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error test data: 1.816499763315606\n",
      "Mean absolute error test data: 1.3675782854924798\n",
      "R2 score test data: 0.8353733289332167\n",
      "Root Mean square error train data: 1.8578415320927608\n",
      "Mean absolute error train data: 1.2297036406531032\n",
      "R2 score train data: 0.8374274083860604\n"
     ]
    }
   ],
   "source": [
    "score_prediction = regression_G3_score.predict(x_test)\n",
    "score_prediction_train = regression_G3_score.predict(x_train)\n",
    "\n",
    "print(\"Root mean square error test data: \" + str(np.sqrt(mean_squared_error(y_test,score_prediction))))\n",
    "print(\"Mean absolute error test data: \" + str(mean_absolute_error(y_test,score_prediction)))\n",
    "print(\"R2 score test data: \" + str(r2_score(y_test,score_prediction)))\n",
    "\n",
    "print(\"Root Mean square error train data: \" + str(np.sqrt(mean_squared_error(y_train,score_prediction_train))))\n",
    "print(\"Mean absolute error train data: \" + str(mean_absolute_error(y_train,score_prediction_train)))\n",
    "print(\"R2 score train data: \" + str(r2_score(y_train,score_prediction_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this I can see that on the test data it appears that the error is around 2 grades. This equates to 10% away from the grade on the scale of 0-20.\n",
    "\n",
    "As this is for all variables I would like to see scatter plots to assess correlation to the grade.\n",
    "\n",
    "I would also like to see the distribution of the grades. \n",
    "\n",
    "From https://www.studyineurope.eu/study-in-portugal/grades i can see that under 10 is a fail. 10 - 11 is an E, 12-13 D, 14-15 C, 16-17 B & 18-20 A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10.0, 15.0]     169\n",
      "(5.0, 10.0]      140\n",
      "(-0.021, 5.0]     46\n",
      "(15.0, 20.0]      40\n",
      "Name: G3, dtype: int64\n",
      "10    56\n",
      "11    47\n",
      "0     38\n",
      "15    33\n",
      "8     32\n",
      "13    31\n",
      "12    31\n",
      "9     28\n",
      "14    27\n",
      "16    16\n",
      "6     15\n",
      "18    12\n",
      "7      9\n",
      "5      7\n",
      "17     6\n",
      "19     5\n",
      "20     1\n",
      "4      1\n",
      "Name: G3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Print the values of the overall grades in 4 bins and then each category. \n",
    "print(analysis_df['G3'].value_counts(bins = 4))\n",
    "print(analysis_df['G3'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='G3', ylabel='Count'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#As there are 20 different grades from 0 - 20 I have chosen 20 bins to see the all of the grades.\n",
    "sns.histplot(df_working['G3'],bins = 20, kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='G3', ylabel='Count'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#grouped histogram to show the bins in groups of 5\n",
    "sns.histplot(df_working['G3'], bins = 4, kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Simon\\Documents\\Degree\\CondaPlace\\envs\\SchoolGradePredict\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='G3'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#A box plot of the grade details to see the distribution. \n",
    "sns.boxplot(df_working['G3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a list to create scatter plots against\n",
    "col_list = []\n",
    "\n",
    "for ele in df_working.columns:\n",
    "    if ele != 'G3':\n",
    "        col_list.append(ele)\n",
    "\n",
    "len(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each column create a scatter plot to compate the variables against the grades. \n",
    "#plt.figure(figsize=(2,2))\n",
    "#for col in col_list:\n",
    " \n",
    "  #  df_working.plot.scatter(x=\"G3\", y=col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plots were not the most informative and infact were basically a replication of the heatmap that I did earlier in the project. As such this is not the best way to select parameters. \n",
    "\n",
    "With a quick search I found the following: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html. This relates to the model though and not feratures.\n",
    "\n",
    "For the feature selection can use https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'Medu', 'Fedu', 'reason', 'failures', 'higher', 'romantic', 'goout', 'G1', 'G2']\n"
     ]
    }
   ],
   "source": [
    "# I wanted to see the best column names so i used the following: https://stackoverflow.com/questions/46927545/get-feature-names-of-selectkbest-function-python adapted to the below\n",
    "\n",
    "#create selector object with the f_regression and a k value of 10 so top 10 items.\n",
    "selector = SelectKBest(f_regression, k=10)\n",
    "#fit and transform the data\n",
    "x_fregress_10 = selector.fit_transform(x, y)\n",
    "# get the names of the columns\n",
    "x.columns[selector.get_support(indices=True)]\n",
    "# create a list of the names\n",
    "vector_names = list(x.columns[selector.get_support(indices=True)])\n",
    "print(vector_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fr10,x_test_fr10, y_train_fr10,y_test_fr10 = train_test_split(x_fregress_10, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_G3_score_fr10 = LinearRegression()\n",
    "\n",
    "regression_G3_score_fr10.fit(x_train_fr10,y_train_fr10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error test data: 1.949015176269677\n",
      "Mean absolute error test data: 1.141774823526546\n",
      "R2 score test data: 0.8380904572359037\n",
      "Root Mean square error train data: 1.8929523142453157\n",
      "Mean absolute error train data: 1.1197432328771404\n",
      "R2 score train data: 0.8192969142046818\n"
     ]
    }
   ],
   "source": [
    "score_prediction = regression_G3_score_fr10.predict(x_test_fr10)\n",
    "score_prediction_train = regression_G3_score_fr10.predict(x_train_fr10)\n",
    "\n",
    "print(\"Root mean square error test data: \" + str(np.sqrt(mean_squared_error(y_test_fr10,score_prediction))))\n",
    "print(\"Mean absolute error test data: \" + str(mean_absolute_error(y_test_fr10,score_prediction)))\n",
    "print(\"R2 score test data: \" + str(r2_score(y_test_fr10,score_prediction)))\n",
    "\n",
    "print(\"Root Mean square error train data: \" + str(np.sqrt(mean_squared_error(y_train_fr10,score_prediction_train))))\n",
    "print(\"Mean absolute error train data: \" + str(mean_absolute_error(y_train_fr10,score_prediction_train)))\n",
    "print(\"R2 score train data: \" + str(r2_score(y_train_fr10,score_prediction_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to loop through from k=2 to k=31 so 29 iterrations need a list for RMSE, MAE and R2 a val for k\n",
    "#create lists to store results \n",
    "rmse_vals_test = []\n",
    "rmse_vals_train = []\n",
    "mae_vals_test = []\n",
    "mae_vals_train = []\n",
    "r2_vals_test = []\n",
    "r2_vals_train = []\n",
    "col_names = []\n",
    "#create a model\n",
    "regression_G3_kloop = LinearRegression()\n",
    "#start at 2 columns.\n",
    "k_val = 2\n",
    "#loop over 30 times for the different k values \n",
    "for i in range(30):\n",
    "    #create selector and get column names \n",
    "    selector = SelectKBest(f_regression, k=k_val+i)\n",
    "    x_fregress_loop = selector.fit_transform(x, y)\n",
    "    x.columns[selector.get_support(indices=True)]\n",
    "    vector_names_loop = list(x.columns[selector.get_support(indices=True)])\n",
    "    #add the list of columns to the list\n",
    "    col_names.append(vector_names_loop)\n",
    "    #test train split\n",
    "    x_train_fr_loop,x_test_fr_loop, y_train_fr_loop,y_test_fr_loop = train_test_split(x_fregress_loop, y, test_size=0.3)\n",
    "    #train the model\n",
    "    regression_G3_kloop.fit(x_train_fr_loop,y_train_fr_loop)\n",
    "\n",
    "    #predict scores\n",
    "    score_prediction_loop = regression_G3_kloop.predict(x_test_fr_loop)\n",
    "    score_prediction_train_loop = regression_G3_kloop.predict(x_train_fr_loop) \n",
    "\n",
    "    #add the RMSE, MAE and R2 values for test and train \n",
    "    rmse_vals_test.append(np.around(np.sqrt(mean_squared_error(y_test_fr_loop,score_prediction_loop)), decimals=4))\n",
    "    rmse_vals_train.append(np.around(np.sqrt(mean_squared_error(y_train_fr_loop,score_prediction_train_loop)), decimals=4))\n",
    "\n",
    "    mae_vals_test.append(np.around(mean_absolute_error(y_test_fr_loop,score_prediction_loop), decimals=4))\n",
    "    mae_vals_train.append(np.around(mean_absolute_error(y_train_fr_loop,score_prediction_train_loop), decimals=4))\n",
    "\n",
    "    r2_vals_test.append(np.around(r2_score(y_test_fr_loop,score_prediction_loop), decimals=4))\n",
    "    r2_vals_train.append(np.around(r2_score(y_train_fr_loop,score_prediction_train_loop), decimals=4))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best k val rmse: 4  with a val of: 1.5219  columns are: ['Medu', 'failures', 'G1', 'G2'] 2\n",
      "best k val mae: 4  with a val of: 0.8914  columns are: ['Medu', 'failures', 'G1', 'G2'] 2\n",
      "best k val r2: 4  with a val of: 0.8769  columns are: ['Medu', 'failures', 'G1', 'G2'] 2\n",
      "all matched values\n"
     ]
    }
   ],
   "source": [
    "#find the lowest values for the training predictions on RMSE and MAE then the max r2 val. The addition of the 2 also accounts for the k value above starting at 2\n",
    "rmse_lowest = np.argmin(rmse_vals_train)\n",
    "print(\"best k val rmse: \" + str(rmse_lowest+2),\" with a val of: \"+str(rmse_vals_train[rmse_lowest]),\" columns are: \"+str(col_names[rmse_lowest]),rmse_lowest)\n",
    "mae_lowest = np.argmin(mae_vals_train)\n",
    "print(\"best k val mae: \" + str(mae_lowest+2),\" with a val of: \"+str(mae_vals_train[mae_lowest]),\" columns are: \"+str(col_names[mae_lowest]),mae_lowest)\n",
    "r2_highest = np.argmax(r2_vals_train)\n",
    "print(\"best k val r2: \" + str(r2_highest+2),\" with a val of: \"+str(r2_vals_train[r2_highest]),\" columns are: \"+str(col_names[r2_highest]),r2_highest)\n",
    "if((rmse_lowest == mae_lowest)&(r2_highest!=rmse_lowest)):\n",
    "    print(\"r2 value at low RMSE, MAE: \" + str(r2_vals_train[rmse_lowest]),rmse_lowest)\n",
    "elif(rmse_lowest != mae_lowest):\n",
    "    print(\"r2 value at low RMSE: \" + str(r2_vals_train[rmse_lowest]),rmse_lowest+2)\n",
    "    print(\"r2 value at low MAE: \" + str(r2_vals_train[mae_lowest]),mae_lowest+2)\n",
    "else:\n",
    "    print(\"all matched values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best k val rmse: 2  with a val of: 1.6218  columns are: ['G1', 'G2'] 0\n",
      "best k val mae: 2  with a val of: 1.0127  columns are: ['G1', 'G2'] 0\n",
      "best k val r2: 2  with a val of: 0.8697  columns are: ['G1', 'G2'] 0\n",
      "all matched values\n"
     ]
    }
   ],
   "source": [
    "#find the lowest values for the test predictions on RMSE and MAE then the max r2 val. The addition of the 2 also accounts for the k value above starting at 2\n",
    "rmse_lowest = np.argmin(rmse_vals_test)\n",
    "print(\"best k val rmse: \" + str(rmse_lowest+2),\" with a val of: \"+str(rmse_vals_test[rmse_lowest]),\" columns are: \"+str(col_names[rmse_lowest]),rmse_lowest)\n",
    "mae_lowest = np.argmin(mae_vals_test)\n",
    "print(\"best k val mae: \" + str(mae_lowest+2),\" with a val of: \"+str(mae_vals_test[mae_lowest]),\" columns are: \"+str(col_names[mae_lowest]),mae_lowest)\n",
    "r2_highest = np.argmax(r2_vals_test)\n",
    "print(\"best k val r2: \" + str(r2_highest+2),\" with a val of: \"+str(r2_vals_test[r2_highest]),\" columns are: \"+str(col_names[r2_highest]),r2_highest)\n",
    "if((rmse_lowest == mae_lowest)&(r2_highest!=rmse_lowest)):\n",
    "    print(\"r2 value at low RMSE, MAE: \" + str(r2_vals_test[rmse_lowest]),rmse_lowest)\n",
    "elif(rmse_lowest != mae_lowest):\n",
    "    print(\"r2 value at low RMSE: \" + str(r2_vals_test[rmse_lowest]),rmse_lowest+2)\n",
    "    print(\"r2 value at low MAE: \" + str(r2_vals_test[mae_lowest]),mae_lowest+2)\n",
    "else:\n",
    "    print(\"all matched values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['G1', 'G2'],\n",
       " ['failures', 'G1', 'G2'],\n",
       " ['Medu', 'failures', 'G1', 'G2'],\n",
       " ['Medu', 'failures', 'higher', 'G1', 'G2'],\n",
       " ['age', 'Medu', 'failures', 'higher', 'G1', 'G2']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#have a look at the highest contributing attributes for the first 5 k values. \n",
    "col_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data above I found that the MAE for both was close to 1 and the RMSE was around 1.5. I would think this is acceptable for guessing if a student was likely to fail or what grade they would get. it is +- 5% as it is out of 20. This would provide some insights into which students may require assistance to get a basic pass in these subjects.\n",
    "\n",
    "The main issue on this is that key attributes seem to be the G1 and G2 scores that are interim values. These would not be available if you wanted to make an intervention early on in the childs carrer.\n",
    "\n",
    "I will now go onto the neural network and see if i can achieve better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the elements required for the neural networks \n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import callbacks\n",
    "\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.491530</td>\n",
       "      <td>-2.841206</td>\n",
       "      <td>-12.283642</td>\n",
       "      <td>-0.582036</td>\n",
       "      <td>-2.038270</td>\n",
       "      <td>-12.544426</td>\n",
       "      <td>-1.467899</td>\n",
       "      <td>-1.068619</td>\n",
       "      <td>-3.207543</td>\n",
       "      <td>-0.336276</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.205651</td>\n",
       "      <td>-4.329617</td>\n",
       "      <td>-3.475109</td>\n",
       "      <td>-2.073513</td>\n",
       "      <td>-2.268926</td>\n",
       "      <td>-2.557392</td>\n",
       "      <td>-2.843418</td>\n",
       "      <td>-0.708786</td>\n",
       "      <td>-3.822936</td>\n",
       "      <td>-3.181473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.491530</td>\n",
       "      <td>-2.841206</td>\n",
       "      <td>-12.897785</td>\n",
       "      <td>-0.582036</td>\n",
       "      <td>-2.038270</td>\n",
       "      <td>-1.821676</td>\n",
       "      <td>-3.971142</td>\n",
       "      <td>-3.602016</td>\n",
       "      <td>-3.207543</td>\n",
       "      <td>-3.018303</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.205651</td>\n",
       "      <td>-3.085831</td>\n",
       "      <td>-3.475109</td>\n",
       "      <td>-2.880363</td>\n",
       "      <td>-2.268926</td>\n",
       "      <td>-2.557392</td>\n",
       "      <td>-2.843418</td>\n",
       "      <td>-0.740012</td>\n",
       "      <td>-3.822936</td>\n",
       "      <td>-3.252150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.491530</td>\n",
       "      <td>-2.841206</td>\n",
       "      <td>-14.126071</td>\n",
       "      <td>-0.582036</td>\n",
       "      <td>2.820006</td>\n",
       "      <td>-1.821676</td>\n",
       "      <td>-3.971142</td>\n",
       "      <td>-3.602016</td>\n",
       "      <td>-3.207543</td>\n",
       "      <td>-3.018303</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.205651</td>\n",
       "      <td>-4.329617</td>\n",
       "      <td>-3.475109</td>\n",
       "      <td>-3.687212</td>\n",
       "      <td>-1.008560</td>\n",
       "      <td>-1.351613</td>\n",
       "      <td>-2.843418</td>\n",
       "      <td>-0.646334</td>\n",
       "      <td>-3.641400</td>\n",
       "      <td>-3.040119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.491530</td>\n",
       "      <td>-2.841206</td>\n",
       "      <td>-14.126071</td>\n",
       "      <td>-0.582036</td>\n",
       "      <td>-2.038270</td>\n",
       "      <td>-1.821676</td>\n",
       "      <td>-1.467899</td>\n",
       "      <td>-2.757550</td>\n",
       "      <td>-2.543836</td>\n",
       "      <td>-1.677290</td>\n",
       "      <td>...</td>\n",
       "      <td>2.277296</td>\n",
       "      <td>-5.573403</td>\n",
       "      <td>-4.477389</td>\n",
       "      <td>-3.687212</td>\n",
       "      <td>-2.268926</td>\n",
       "      <td>-2.557392</td>\n",
       "      <td>-1.808727</td>\n",
       "      <td>-0.771238</td>\n",
       "      <td>-2.915253</td>\n",
       "      <td>-2.616059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.491530</td>\n",
       "      <td>-2.841206</td>\n",
       "      <td>-13.511928</td>\n",
       "      <td>-0.582036</td>\n",
       "      <td>-2.038270</td>\n",
       "      <td>-1.821676</td>\n",
       "      <td>-2.302313</td>\n",
       "      <td>-1.913085</td>\n",
       "      <td>-1.880129</td>\n",
       "      <td>-3.018303</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.205651</td>\n",
       "      <td>-4.329617</td>\n",
       "      <td>-3.475109</td>\n",
       "      <td>-3.687212</td>\n",
       "      <td>-2.268926</td>\n",
       "      <td>-1.954503</td>\n",
       "      <td>-1.808727</td>\n",
       "      <td>-0.740012</td>\n",
       "      <td>-3.732168</td>\n",
       "      <td>-2.898766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>8.202627</td>\n",
       "      <td>1.159976</td>\n",
       "      <td>-11.055356</td>\n",
       "      <td>-0.582036</td>\n",
       "      <td>2.820006</td>\n",
       "      <td>-12.544426</td>\n",
       "      <td>-3.136728</td>\n",
       "      <td>-2.757550</td>\n",
       "      <td>-1.216422</td>\n",
       "      <td>-1.677290</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.205651</td>\n",
       "      <td>-3.085831</td>\n",
       "      <td>-1.470549</td>\n",
       "      <td>-2.073513</td>\n",
       "      <td>1.512172</td>\n",
       "      <td>-0.145833</td>\n",
       "      <td>-2.326073</td>\n",
       "      <td>-0.630721</td>\n",
       "      <td>-3.459863</td>\n",
       "      <td>-2.969443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>8.202627</td>\n",
       "      <td>1.159976</td>\n",
       "      <td>-12.897785</td>\n",
       "      <td>-0.582036</td>\n",
       "      <td>2.820006</td>\n",
       "      <td>-1.821676</td>\n",
       "      <td>-2.302313</td>\n",
       "      <td>-3.602016</td>\n",
       "      <td>-1.216422</td>\n",
       "      <td>-1.677290</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.205651</td>\n",
       "      <td>-6.817190</td>\n",
       "      <td>-2.472829</td>\n",
       "      <td>-1.266663</td>\n",
       "      <td>0.251806</td>\n",
       "      <td>-0.748723</td>\n",
       "      <td>-3.360764</td>\n",
       "      <td>-0.755625</td>\n",
       "      <td>-3.006021</td>\n",
       "      <td>-2.474705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>8.202627</td>\n",
       "      <td>1.159976</td>\n",
       "      <td>-10.441213</td>\n",
       "      <td>-6.342696</td>\n",
       "      <td>-2.038270</td>\n",
       "      <td>-1.821676</td>\n",
       "      <td>-3.971142</td>\n",
       "      <td>-3.602016</td>\n",
       "      <td>-1.880129</td>\n",
       "      <td>-3.018303</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.205651</td>\n",
       "      <td>-3.085831</td>\n",
       "      <td>-1.470549</td>\n",
       "      <td>-2.880363</td>\n",
       "      <td>0.251806</td>\n",
       "      <td>-1.351613</td>\n",
       "      <td>-2.843418</td>\n",
       "      <td>-0.755625</td>\n",
       "      <td>-3.369094</td>\n",
       "      <td>-3.040119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>8.202627</td>\n",
       "      <td>1.159976</td>\n",
       "      <td>-12.283642</td>\n",
       "      <td>-6.342696</td>\n",
       "      <td>2.820006</td>\n",
       "      <td>-1.821676</td>\n",
       "      <td>-2.302313</td>\n",
       "      <td>-2.757550</td>\n",
       "      <td>-1.216422</td>\n",
       "      <td>-3.018303</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.205651</td>\n",
       "      <td>-4.329617</td>\n",
       "      <td>-2.472829</td>\n",
       "      <td>-4.494062</td>\n",
       "      <td>0.251806</td>\n",
       "      <td>-0.748723</td>\n",
       "      <td>-1.808727</td>\n",
       "      <td>-0.802464</td>\n",
       "      <td>-3.278326</td>\n",
       "      <td>-2.757412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>8.202627</td>\n",
       "      <td>1.159976</td>\n",
       "      <td>-11.669499</td>\n",
       "      <td>-0.582036</td>\n",
       "      <td>2.820006</td>\n",
       "      <td>-1.821676</td>\n",
       "      <td>-3.971142</td>\n",
       "      <td>-3.602016</td>\n",
       "      <td>-1.880129</td>\n",
       "      <td>-5.700331</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.205651</td>\n",
       "      <td>-5.573403</td>\n",
       "      <td>-4.477389</td>\n",
       "      <td>-2.880363</td>\n",
       "      <td>0.251806</td>\n",
       "      <td>-1.351613</td>\n",
       "      <td>-1.808727</td>\n",
       "      <td>-0.724399</td>\n",
       "      <td>-3.550631</td>\n",
       "      <td>-2.969443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       school       sex        age   address   famsize    Pstatus      Medu  \\\n",
       "0   -1.491530 -2.841206 -12.283642 -0.582036 -2.038270 -12.544426 -1.467899   \n",
       "1   -1.491530 -2.841206 -12.897785 -0.582036 -2.038270  -1.821676 -3.971142   \n",
       "2   -1.491530 -2.841206 -14.126071 -0.582036  2.820006  -1.821676 -3.971142   \n",
       "3   -1.491530 -2.841206 -14.126071 -0.582036 -2.038270  -1.821676 -1.467899   \n",
       "4   -1.491530 -2.841206 -13.511928 -0.582036 -2.038270  -1.821676 -2.302313   \n",
       "..        ...       ...        ...       ...       ...        ...       ...   \n",
       "390  8.202627  1.159976 -11.055356 -0.582036  2.820006 -12.544426 -3.136728   \n",
       "391  8.202627  1.159976 -12.897785 -0.582036  2.820006  -1.821676 -2.302313   \n",
       "392  8.202627  1.159976 -10.441213 -6.342696 -2.038270  -1.821676 -3.971142   \n",
       "393  8.202627  1.159976 -12.283642 -6.342696  2.820006  -1.821676 -2.302313   \n",
       "394  8.202627  1.159976 -11.669499 -0.582036  2.820006  -1.821676 -3.971142   \n",
       "\n",
       "         Fedu      Mjob      Fjob  ...  romantic    famrel  freetime  \\\n",
       "0   -1.068619 -3.207543 -0.336276  ... -2.205651 -4.329617 -3.475109   \n",
       "1   -3.602016 -3.207543 -3.018303  ... -2.205651 -3.085831 -3.475109   \n",
       "2   -3.602016 -3.207543 -3.018303  ... -2.205651 -4.329617 -3.475109   \n",
       "3   -2.757550 -2.543836 -1.677290  ...  2.277296 -5.573403 -4.477389   \n",
       "4   -1.913085 -1.880129 -3.018303  ... -2.205651 -4.329617 -3.475109   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "390 -2.757550 -1.216422 -1.677290  ... -2.205651 -3.085831 -1.470549   \n",
       "391 -3.602016 -1.216422 -1.677290  ... -2.205651 -6.817190 -2.472829   \n",
       "392 -3.602016 -1.880129 -3.018303  ... -2.205651 -3.085831 -1.470549   \n",
       "393 -2.757550 -1.216422 -3.018303  ... -2.205651 -4.329617 -2.472829   \n",
       "394 -3.602016 -1.880129 -5.700331  ... -2.205651 -5.573403 -4.477389   \n",
       "\n",
       "        goout      Dalc      Walc    health  absences        G1        G2  \n",
       "0   -2.073513 -2.268926 -2.557392 -2.843418 -0.708786 -3.822936 -3.181473  \n",
       "1   -2.880363 -2.268926 -2.557392 -2.843418 -0.740012 -3.822936 -3.252150  \n",
       "2   -3.687212 -1.008560 -1.351613 -2.843418 -0.646334 -3.641400 -3.040119  \n",
       "3   -3.687212 -2.268926 -2.557392 -1.808727 -0.771238 -2.915253 -2.616059  \n",
       "4   -3.687212 -2.268926 -1.954503 -1.808727 -0.740012 -3.732168 -2.898766  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "390 -2.073513  1.512172 -0.145833 -2.326073 -0.630721 -3.459863 -2.969443  \n",
       "391 -1.266663  0.251806 -0.748723 -3.360764 -0.755625 -3.006021 -2.474705  \n",
       "392 -2.880363  0.251806 -1.351613 -2.843418 -0.755625 -3.369094 -3.040119  \n",
       "393 -4.494062  0.251806 -0.748723 -1.808727 -0.802464 -3.278326 -2.757412  \n",
       "394 -2.880363  0.251806 -1.351613 -1.808727 -0.724399 -3.550631 -2.969443  \n",
       "\n",
       "[395 rows x 32 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalise the data around the mean\n",
    "train_data_rnn = x.copy()\n",
    "mean = train_data_rnn.mean(axis=0)\n",
    "train_data_rnn -= mean\n",
    "std = train_data_rnn.std(axis=0)\n",
    "train_data_rnn /= std\n",
    "\n",
    "train_data_rnn -= mean\n",
    "train_data_rnn /= std\n",
    "\n",
    "train_data_rnn\n",
    "#x_train,x_test, y_train,y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test train split of the data. \n",
    "x_train_rnn,x_test_rnn, y_train_rnn,y_test_rnn = train_test_split(train_data_rnn, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a basic neural network with 4 layers  and output\n",
    "def build_model_reg():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',input_shape=(x_train_rnn.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,489\n",
      "Trainable params: 11,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build a model and view a summary\n",
    "model_reg = build_model_reg()\n",
    "model_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 3ms/step - loss: 59.1375 - mae: 6.5572\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 24.1499 - mae: 3.7078\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 21.8509 - mae: 3.4872\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 20.4453 - mae: 3.4205\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 20.4875 - mae: 3.4401\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 17.8258 - mae: 3.2590\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 17.7601 - mae: 3.2611\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 16.7401 - mae: 3.1358\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 17.5973 - mae: 3.1907\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 15.7774 - mae: 3.0465\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 16.9606 - mae: 3.2290\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 15.7455 - mae: 3.0151\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 15.3956 - mae: 3.0563\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 14.6466 - mae: 2.9565\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 14.3066 - mae: 2.9554\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 13.9339 - mae: 2.8831\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 14.2207 - mae: 2.9522\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 13.4753 - mae: 2.8627\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 13.1976 - mae: 2.7785\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 13.1285 - mae: 2.8305\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 11.8542 - mae: 2.6362\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 13.3371 - mae: 2.7964\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 11.9165 - mae: 2.6050\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 11.6242 - mae: 2.6276\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 11.7243 - mae: 2.6460\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 11.1756 - mae: 2.5357\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 9.5248 - mae: 2.3860\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 11.5692 - mae: 2.6548\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 9.5744 - mae: 2.3693\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 9.5506 - mae: 2.3820\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 8.7223 - mae: 2.2269\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 10.2396 - mae: 2.5647\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 8.7842 - mae: 2.2446\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 9.0241 - mae: 2.2409\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 8.1850 - mae: 2.2148\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 7.5046 - mae: 2.0733\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 8.7672 - mae: 2.2529\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 6.7908 - mae: 1.9625\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 9.1857 - mae: 2.3412\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 7.2543 - mae: 2.0268\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 6.2812 - mae: 1.8395\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 8.0646 - mae: 2.1471\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 6.1744 - mae: 1.8817\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 7.2781 - mae: 2.0512\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 6.0328 - mae: 1.8552\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 6.9068 - mae: 2.0656\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 6.5563 - mae: 1.9218\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 5.4477 - mae: 1.7434\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 7.0598 - mae: 2.0621\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 4.6926 - mae: 1.5820\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 4.8518 - mae: 1.6621\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 7.4263 - mae: 2.1689\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 4.0336 - mae: 1.4942\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 7.1699 - mae: 2.0859\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 4.4534 - mae: 1.5469\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 6.5032 - mae: 1.9124\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 4.8871 - mae: 1.6331\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 4.3578 - mae: 1.5849\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 5.6480 - mae: 1.8347\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 623us/step - loss: 4.9249 - mae: 1.6962\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 3.7455 - mae: 1.4157\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 6.0356 - mae: 1.8893\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 4.5232 - mae: 1.6576\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 5.2544 - mae: 1.7762\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 4.6227 - mae: 1.6625\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.8466 - mae: 1.2582\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 5.4782 - mae: 1.7665\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 3.8535 - mae: 1.5506\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 4.4414 - mae: 1.6228\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 3.3515 - mae: 1.3463\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 5.1431 - mae: 1.7792\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 3.5718 - mae: 1.3700\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 3.1373 - mae: 1.2994\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 3.7037 - mae: 1.4498\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 3.8896 - mae: 1.4956\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 4.2517 - mae: 1.5987\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 2.6937 - mae: 1.2142\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 4.1070 - mae: 1.5642\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 4.3965 - mae: 1.6289\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 2.3951 - mae: 1.1174\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 4.0711 - mae: 1.5652\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.6192 - mae: 1.1995\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 2.9956 - mae: 1.3235\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 5.1470 - mae: 1.7513\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.2384 - mae: 1.0864\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.4111 - mae: 1.1594\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 3.5208 - mae: 1.5122\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 3.7988 - mae: 1.5143\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.8161 - mae: 0.9616\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 4.4328 - mae: 1.6523\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.5902 - mae: 1.2160\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.5824 - mae: 1.2056\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 3.4578 - mae: 1.5007\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.4039 - mae: 1.1906\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 3.3338 - mae: 1.4863\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 3.0287 - mae: 1.3801\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.4214 - mae: 1.2228\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 3.1057 - mae: 1.4197\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.5146 - mae: 1.2766\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.8769 - mae: 1.3906\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.2489 - mae: 1.1766\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.6726 - mae: 1.2988\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.8585 - mae: 1.2648\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.1941 - mae: 1.0396\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 2.2172 - mae: 1.1315\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 3.5034 - mae: 1.4347\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.6053 - mae: 0.9935\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 2.4239 - mae: 1.3332\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.7770 - mae: 1.3783\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.2814 - mae: 0.8726\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.7634 - mae: 1.3757\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.8367 - mae: 1.0345\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.4599 - mae: 0.9183\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 4.0014 - mae: 1.4979\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.6859 - mae: 1.0296\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.2735 - mae: 0.8486\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 623us/step - loss: 3.2979 - mae: 1.5584\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 623us/step - loss: 1.3218 - mae: 0.8610\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.7762 - mae: 1.2846\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.7430 - mae: 1.2130\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.9177 - mae: 0.7284\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.8062 - mae: 1.2984\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.9260 - mae: 0.7341\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.2877 - mae: 1.3941\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.7738 - mae: 0.6391\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.7331 - mae: 1.2849\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.6971 - mae: 1.0386\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 872us/step - loss: 2.5243 - mae: 1.2636\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8269 - mae: 0.6998\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.0041 - mae: 1.1475\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.5897 - mae: 0.9644\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.3868 - mae: 1.2352\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.9159 - mae: 1.1221\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.4950 - mae: 0.9246\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 872us/step - loss: 2.2895 - mae: 1.1529\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.2478 - mae: 0.8720\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3198 - mae: 1.3111\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.1465 - mae: 0.8134\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.1144 - mae: 1.2355\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7393 - mae: 0.6729\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.0907 - mae: 1.1986\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.7787 - mae: 0.7090\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.4139 - mae: 1.2614\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.2624 - mae: 1.2710\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.8546 - mae: 0.6831\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.2805 - mae: 1.0709\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6873 - mae: 0.5959\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.4999 - mae: 1.3202\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.7765 - mae: 1.1082\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4507 - mae: 0.5060\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.4565 - mae: 1.2791\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6444 - mae: 0.5933\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.6415 - mae: 1.2957\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.9827 - mae: 0.8022\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.7680 - mae: 1.0559\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6499 - mae: 0.6259\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 5.1546 - mae: 2.121 - 0s 873us/step - loss: 2.2681 - mae: 1.1740\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.0380 - mae: 0.8353\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.6501 - mae: 1.0328\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.3625 - mae: 1.0003\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.4392 - mae: 1.3160\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.7066 - mae: 0.6479\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.6384 - mae: 1.1243\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6566 - mae: 0.6305\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.1307 - mae: 1.2493\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5903 - mae: 0.5918\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1660 - mae: 1.2214\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.8493 - mae: 0.7553\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.6850 - mae: 1.0051\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7028 - mae: 1.1193\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.2774 - mae: 0.9126\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.8047 - mae: 0.7072\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.8029 - mae: 1.1573\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.2342 - mae: 0.9213\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.9182 - mae: 1.1149\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.4337 - mae: 0.5035\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.9770 - mae: 1.0968\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4782 - mae: 0.5482\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.2031 - mae: 1.2504\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4771 - mae: 0.5544\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.1899 - mae: 1.2695\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.7646 - mae: 0.6983\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.1602 - mae: 0.9371\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.7251 - mae: 1.1453\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6490 - mae: 0.6396\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.6014 - mae: 1.1189\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5568 - mae: 0.5727\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 872us/step - loss: 1.6491 - mae: 1.0334\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.4750 - mae: 0.5065\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.9468 - mae: 1.0566\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.8254 - mae: 0.7165\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.0655 - mae: 0.8405\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.0038 - mae: 0.8181\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.5638 - mae: 0.9877\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.0230 - mae: 0.8699\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.0570 - mae: 0.8395\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.7739 - mae: 1.0966\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4546 - mae: 0.4785\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.5663 - mae: 1.0842\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.5489 - mae: 0.5454\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.4452 - mae: 0.8708\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 872us/step - loss: 0.2057 - mae: 0.3446\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.9782 - mae: 1.0695\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.2084 - mae: 0.3603\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.0655 - mae: 1.1894\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.6937 - mae: 0.5947\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.0163 - mae: 0.7641\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.4310 - mae: 0.9701\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4073 - mae: 0.5075\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3855 - mae: 0.9694\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.9243 - mae: 0.8207\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.1271 - mae: 0.9398\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.9890 - mae: 0.8114\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.3223 - mae: 1.0059\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.9356 - mae: 0.6828\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.3433 - mae: 1.0214\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6619 - mae: 0.6786\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.4529 - mae: 1.0581\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.9131 - mae: 0.8084\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.4470 - mae: 0.4964\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.6408 - mae: 1.1184\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6652 - mae: 0.6900\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.0519 - mae: 0.8694\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 872us/step - loss: 0.5998 - mae: 0.6470\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.2997 - mae: 0.9149\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.5596 - mae: 0.5986\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.2517 - mae: 0.9298\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.7871 - mae: 0.7423\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.4572 - mae: 1.0221\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4232 - mae: 0.5023\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.8913 - mae: 0.6621\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.8728 - mae: 0.7574\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.7119 - mae: 0.6968\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.4857 - mae: 1.0237\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5368 - mae: 0.5966\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.9188 - mae: 0.7721\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.2052 - mae: 0.8543\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5033 - mae: 0.5771\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.3519 - mae: 1.0378\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4262 - mae: 0.5018\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3460 - mae: 0.9714\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6224 - mae: 0.6286\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.2798 - mae: 0.9954\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6707 - mae: 0.6932\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6786 - mae: 0.7168\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6766 - mae: 0.6695\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.3614 - mae: 0.9285\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2476 - mae: 0.3837\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.6643 - mae: 1.0918\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.2185 - mae: 0.3642\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.0828 - mae: 0.8044\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.4268 - mae: 0.9096\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.2102 - mae: 0.3541\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.1167 - mae: 0.8806\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.7873 - mae: 0.6830\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5038 - mae: 0.5538\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8458 - mae: 0.7019\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.9478 - mae: 0.8039\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.4681 - mae: 0.9734\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.2721 - mae: 0.3908\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.0237 - mae: 0.8284\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.7265 - mae: 0.7148\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.9528 - mae: 0.8205\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.4771 - mae: 0.5315\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.3384 - mae: 0.9854\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.3264 - mae: 0.4486\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.2693 - mae: 0.9590\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.5443 - mae: 0.6271\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.1226 - mae: 0.9087\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.6859 - mae: 0.6979\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.7844 - mae: 0.7657\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.8350 - mae: 0.7935\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.7084 - mae: 0.7102\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.7583 - mae: 0.7477\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.7652 - mae: 0.7056\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.9616 - mae: 0.8283\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.4022 - mae: 0.4860\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.8558 - mae: 0.7274\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.2587 - mae: 0.9805\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.1541 - mae: 0.2984\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.4873 - mae: 1.0182\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.2556 - mae: 0.4118\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.3584 - mae: 0.9382\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 623us/step - loss: 0.2229 - mae: 0.3597\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.8796 - mae: 0.8114\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.9651 - mae: 0.8303\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.1137 - mae: 0.2709\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.4717 - mae: 0.9572\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.0965 - mae: 0.2429\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.4024 - mae: 0.9781\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.2482 - mae: 0.3974\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.7611 - mae: 0.7173\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.1080 - mae: 0.9086\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.3670 - mae: 0.4928\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.8725 - mae: 0.8144\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.6665 - mae: 0.6958\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.7551 - mae: 0.7604\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.7323 - mae: 0.7176\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.1608 - mae: 0.3053\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 623us/step - loss: 1.3581 - mae: 0.8733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28409baef40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model with 300 epochs\n",
    "model_reg.fit(x_train_rnn,y_train_rnn, epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 997us/step - loss: 19.2583 - mae: 3.4562\n",
      "4.388426315031499 3.456176280975342\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model \n",
    "mse, mae = model_reg.evaluate(x_test_rnn, y_test_rnn)\n",
    "#take the square root of mse so it is rmse\n",
    "rmse_rnn = np.sqrt(mse)\n",
    "#print the measures\n",
    "print(rmse_rnn, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a larger model with convolution regularisation and droput. \n",
    "def build_model_reg_2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',input_shape=(x_train_rnn.shape[1],)))\n",
    "    model.add(layers.Dense(64,kernel_regularizer=regularizers.l1(0.001), activation='relu'))\n",
    "    model.add(layers.Dense(64,kernel_regularizer=regularizers.l1(0.001), activation='relu'))\n",
    "    model.add(layers.Dense(64,kernel_regularizer=regularizers.l1(0.001), activation='relu'))\n",
    "    model.add(layers.Reshape((64,1)))\n",
    "    model.add(layers.Conv1D(64,2,activation='relu'))\n",
    "    model.add(layers.Conv1D(128,4,activation='relu'))\n",
    "    model.add(layers.Conv1D(64,2,activation='relu'))\n",
    "    model.add(layers.Conv1D(64,8,activation='relu'))\n",
    "    model.add(layers.Conv1D(32,4,activation='relu'))\n",
    "    model.add(layers.Conv1D(64,2,activation='relu'))\n",
    "    model.add(layers.Dense(128,kernel_regularizer=regularizers.l1(0.001), activation='relu'))\n",
    "    model.add(layers.Dense(128,kernel_regularizer=regularizers.l1(0.001), activation='relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128,kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n",
    "    model.add(layers.Dense(128,kernel_regularizer=regularizers.l1(0.05), activation='relu'))\n",
    "    model.add(layers.Dense(128,kernel_regularizer=regularizers.l1(0.006), activation='relu'))\n",
    "    model.add(layers.Dense(128,kernel_regularizer=regularizers.l1(0.009), activation='relu'))\n",
    "    model.add(layers.Dense(128,kernel_regularizer=regularizers.l1(0.002), activation='relu'))\n",
    "    model.add(layers.Dense(64,kernel_regularizer=regularizers.l1(0.001), activation='relu'))\n",
    "    model.add(layers.Reshape((64,1)))\n",
    "    model.add(layers.Conv1D(64,2,activation='relu'))\n",
    "    model.add(layers.Conv1D(128,4,activation='relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 1)             0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 63, 64)            192       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 60, 128)           32896     \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 59, 64)            16448     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 52, 64)            32832     \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 49, 32)            8224      \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 48, 64)            4160      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 48, 128)           8320      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 48, 128)           16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48, 128)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6144)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               786560    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 64, 1)             0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 63, 64)            192       \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 60, 128)           32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 60, 128)           0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 7680)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                491584    \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,522,337\n",
      "Trainable params: 1,522,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_reg_2 = build_model_reg_2()\n",
    "model_reg_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "9/9 [==============================] - 3s 28ms/step - loss: 326.0627 - mae: 11.3700\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 179.4683 - mae: 7.5027\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 118.3904 - mae: 4.4621\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 110.8285 - mae: 4.5695\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 106.1664 - mae: 4.8480\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 108.7439 - mae: 5.4354\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 91.9145 - mae: 4.8108\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 76.9595 - mae: 3.9018\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 76.2658 - mae: 4.3951\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 62.8557 - mae: 3.7849\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 58.6796 - mae: 3.7429\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 57.9777 - mae: 4.1050\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 48.0908 - mae: 3.4778\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 47.3956 - mae: 3.6716\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 41.5904 - mae: 3.4328\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 57.6832 - mae: 4.9413\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 39.1301 - mae: 3.5752\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 36.3258 - mae: 3.2993\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 39.3845 - mae: 3.8000\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 34.9813 - mae: 3.3619\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 35.6488 - mae: 3.6363\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 33.1291 - mae: 3.4173\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 35.2300 - mae: 3.7343\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 32.9418 - mae: 3.5200\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 31.6686 - mae: 3.4309\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 32.8775 - mae: 3.6724 0s - loss: 28.9641 - mae: \n",
      "Epoch 27/500\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 30.5441 - mae: 3.4291\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 27.0905 - mae: 3.0091\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 33.1347 - mae: 3.8154\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 29.0779 - mae: 3.4376\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 28.8194 - mae: 3.4300\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 26.1432 - mae: 3.1820\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 29.7129 - mae: 3.5205\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 24.8764 - mae: 3.0492\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 30.0717 - mae: 3.6190\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 22.9777 - mae: 2.8724\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 34.1043 - mae: 4.0884\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 22.8769 - mae: 2.8606\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 20.8033 - mae: 2.7147\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 24.9618 - mae: 3.1298\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 23.5862 - mae: 3.0878\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 23.0714 - mae: 2.9272\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 22.7968 - mae: 3.0080\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 24.2703 - mae: 3.1434\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 18.5776 - mae: 2.4596\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 19.9205 - mae: 2.7513\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 20.3203 - mae: 2.7417\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 23.7295 - mae: 3.2482\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 23.2242 - mae: 3.0898\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 16.8503 - mae: 2.3158\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 15.2845 - mae: 2.1325\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 20.5102 - mae: 2.6905\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 21.8600 - mae: 2.9296\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 15.1326 - mae: 2.1922\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 24.1599 - mae: 3.0998\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 14.7675 - mae: 2.1209\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 16.9435 - mae: 2.4496\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 14.9882 - mae: 2.1757\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 16.4352 - mae: 2.3874\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 21.4266 - mae: 3.0483\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 16.1385 - mae: 2.3651\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 17.5098 - mae: 2.5780\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 14.9311 - mae: 2.2430\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 18.3190 - mae: 2.6322\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 16.2344 - mae: 2.4110\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 17.3390 - mae: 2.5443\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 13.7197 - mae: 1.9950\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 17.4327 - mae: 2.5339\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 16.5732 - mae: 2.4430\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 11.3274 - mae: 1.6011\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 18.2536 - mae: 2.5238\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 14.9114 - mae: 2.2629\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 14.8926 - mae: 2.2207\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 15.0064 - mae: 2.2731\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 11.8589 - mae: 1.7378\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 17.0065 - mae: 2.4864\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 15.6175 - mae: 2.2569\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 12.2267 - mae: 1.7587\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 15.1480 - mae: 2.2295\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 13.4528 - mae: 2.0618\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 13.4678 - mae: 2.0266\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 13.7983 - mae: 2.0301\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 14.7979 - mae: 2.0396\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 11.7890 - mae: 1.7197\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 13.4354 - mae: 2.1383\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 14.5134 - mae: 2.1787\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 9.9217 - mae: 1.3953\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 17.1806 - mae: 2.5558\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 11.8586 - mae: 1.7984\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 10.6797 - mae: 1.5361\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 15.2112 - mae: 2.2599\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 11.8800 - mae: 1.7374\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 12.3975 - mae: 1.8913\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 12.7000 - mae: 1.8886\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 13.3172 - mae: 2.0330\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 14.1499 - mae: 2.0642\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 10.7009 - mae: 1.6317\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 15.7215 - mae: 2.2685\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 11.5476 - mae: 1.7912\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 11.2908 - mae: 1.7013\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 12.5217 - mae: 1.9509\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 13.1593 - mae: 1.9963\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 12.0867 - mae: 1.6542\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 11.2030 - mae: 1.6435\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 9.5294 - mae: 1.3535\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 16.6476 - mae: 2.4224\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.3454 - mae: 1.0524\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 11.8123 - mae: 1.8845\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 12.5937 - mae: 1.8932\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 12.9497 - mae: 1.9051\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 9.0218 - mae: 1.2516\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 12.2047 - mae: 1.8271\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 12.7411 - mae: 1.9850\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 10.8861 - mae: 1.6700\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 12.1296 - mae: 1.7957\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 11.3798 - mae: 1.8361\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 11.6372 - mae: 1.8035\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 13.1847 - mae: 1.9029\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 9.2532 - mae: 1.3033\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 12.5547 - mae: 1.8196\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 8.6733 - mae: 1.1983\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 11.5751 - mae: 1.7492\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 11.6391 - mae: 1.7624\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 9.2751 - mae: 1.4183\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 9.4604 - mae: 1.3346\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 12.1798 - mae: 1.8613\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 11.1896 - mae: 1.7042\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 9.6649 - mae: 1.4190\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.9192 - mae: 1.4747\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 11.2221 - mae: 1.7870\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 9.0913 - mae: 1.3528\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 10.7235 - mae: 1.6905\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 10.4272 - mae: 1.5726\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 9.5130 - mae: 1.4552\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 12.0501 - mae: 1.7905\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 12.2848 - mae: 1.8674\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 9.1217 - mae: 1.3522\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 8.7595 - mae: 1.1811\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 10.4560 - mae: 1.6246\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.6919 - mae: 1.4270\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 10.5761 - mae: 1.7327\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.9675 - mae: 1.5037\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 11.0377 - mae: 1.5790\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 9.7331 - mae: 1.4248\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 11.4494 - mae: 1.6785\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.2595 - mae: 1.3727\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 9.0996 - mae: 1.3681\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 9.3381 - mae: 1.3839\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 10.7700 - mae: 1.7417\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 8.8581 - mae: 1.2076\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 11.3011 - mae: 1.7738\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 11.0662 - mae: 1.6008\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 10.4272 - mae: 1.6358\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.9198 - mae: 1.4845\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 9.4822 - mae: 1.4162\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 8.8135 - mae: 1.2940\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 10.0707 - mae: 1.6330\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 9.1769 - mae: 1.4730\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 9.0034 - mae: 1.3915\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 8.3591 - mae: 1.1959\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 10.2179 - mae: 1.6110\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 9.2093 - mae: 1.3744\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 9.0771 - mae: 1.3654\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 9.4047 - mae: 1.5110\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 8.9198 - mae: 1.3181\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 9.1231 - mae: 1.3561\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 9.3105 - mae: 1.5219\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.0801 - mae: 1.1653\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.2857 - mae: 1.4575\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 9.7482 - mae: 1.5082\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.7814 - mae: 1.3143\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 10.5333 - mae: 1.5717\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 8.8567 - mae: 1.3030\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 8.8508 - mae: 1.3385\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.0812 - mae: 1.0524\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 10.1704 - mae: 1.6130\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 9.5834 - mae: 1.4494\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 9.1565 - mae: 1.3466\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 10.2748 - mae: 1.5285\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 8.8390 - mae: 1.2799\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.6208 - mae: 0.9930\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 9.7775 - mae: 1.5091\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.6011 - mae: 1.4467\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.7882 - mae: 1.0657\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.0235 - mae: 0.8210\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 12.2806 - mae: 1.7006\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.5796 - mae: 0.7331\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 8.0761 - mae: 1.2427\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.1516 - mae: 1.3939\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 8.8343 - mae: 1.1873\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 7.0070 - mae: 0.8727\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 8.9174 - mae: 1.3950\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.0042 - mae: 1.2233\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 8.9610 - mae: 1.2981\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 9.2337 - mae: 1.4125\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 8.6920 - mae: 1.2374\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 9.4833 - mae: 1.5009\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.4937 - mae: 1.1957\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.8341 - mae: 0.7896\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 8.7287 - mae: 1.2937\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.6153 - mae: 0.6749\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 10.0956 - mae: 1.4213\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.9408 - mae: 1.2042\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 8.2690 - mae: 0.9971\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 8.4048 - mae: 1.1020\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 9.3125 - mae: 1.4549\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.5737 - mae: 1.2439\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.5435 - mae: 1.0306\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.2804 - mae: 1.1999\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.7963 - mae: 1.1516\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.9928 - mae: 1.1709\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 9.2636 - mae: 1.4406\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.9125 - mae: 0.7912\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 10.0034 - mae: 1.4922\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 8.1609 - mae: 1.2452\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 9.2617 - mae: 1.2836\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 7.6566 - mae: 1.0763\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 8.6548 - mae: 1.3249\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.6387 - mae: 1.0858\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 7.2437 - mae: 0.9254\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 8.0397 - mae: 1.2558\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.8082 - mae: 1.1497\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.9285 - mae: 1.0410\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.2284 - mae: 1.4162\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.3496 - mae: 1.0054\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 7.5457 - mae: 0.9328\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 8.4914 - mae: 1.2162\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 8.2103 - mae: 1.2013\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 8.1837 - mae: 1.1707\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.3760 - mae: 1.3175\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.0755 - mae: 0.9240\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.5992 - mae: 1.0883\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.8374 - mae: 0.8502\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 9.6636 - mae: 1.4236\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 8.5206 - mae: 1.2288\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 7.0311 - mae: 0.8911\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 7.9042 - mae: 1.2326\n",
      "Epoch 238/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.4282 - mae: 0.8912\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 9.1805 - mae: 1.2116\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 8.2713 - mae: 1.1768\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 8.3949 - mae: 1.1932\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 8.1283 - mae: 1.2888\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.6223 - mae: 0.7832\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.2391 - mae: 1.5175\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.2798 - mae: 0.6224\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.2048 - mae: 1.3178\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.6801 - mae: 0.7585\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 8.2882 - mae: 1.2055\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.7727 - mae: 0.8699\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 8.5650 - mae: 1.3318\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.2829 - mae: 1.5094\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.6797 - mae: 0.7535\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.6048 - mae: 0.7300\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 8.3056 - mae: 1.2821\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.3303 - mae: 1.2514\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.9764 - mae: 0.9553\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 9.2406 - mae: 1.3468\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 8.4673 - mae: 1.3018\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.9007 - mae: 0.8550\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.0122 - mae: 0.8709\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 7.8228 - mae: 1.1501\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 9.2207 - mae: 1.3578\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.5167 - mae: 0.6273\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 7.9222 - mae: 1.1537\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.6658 - mae: 1.0535\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.3188 - mae: 0.9104\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 8.8891 - mae: 1.3147\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 7.0886 - mae: 0.9962\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.8864 - mae: 1.1602\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 6.3052 - mae: 0.6321\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.5575 - mae: 1.0987\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.1934 - mae: 1.0463\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 7.1538 - mae: 0.9939\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 7.2373 - mae: 0.9512\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.4446 - mae: 1.0485\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.5665 - mae: 0.9916\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.6559 - mae: 1.2030\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 7.3848 - mae: 1.0370\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.5839 - mae: 0.7210\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.0165 - mae: 0.9306\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.8257 - mae: 1.1026\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.6318 - mae: 0.7931\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.6256 - mae: 1.1644\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.0541 - mae: 0.9970\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.6116 - mae: 0.7112\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.5359 - mae: 1.0425\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 8.4713 - mae: 1.2702\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.9230 - mae: 0.9483\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.5560 - mae: 0.7231\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.2092 - mae: 0.8556\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.8456 - mae: 1.2704\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 6.2388 - mae: 0.5570\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 7.0621 - mae: 0.9358\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.0724 - mae: 0.9783\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.2165 - mae: 1.0073\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.4204 - mae: 0.7250\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.9766 - mae: 1.1610\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.7977 - mae: 0.8074\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.9869 - mae: 1.1570\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.1430 - mae: 0.5893\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 7.4544 - mae: 1.0710\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.8270 - mae: 1.1654\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.4440 - mae: 0.6957\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.7732 - mae: 1.0578\n",
      "Epoch 305/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.5736 - mae: 0.6550\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.7734 - mae: 1.0761\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 7.0293 - mae: 0.9364\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 7.3792 - mae: 1.0521\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.7368 - mae: 0.7810\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.9737 - mae: 1.4674\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 7.0923 - mae: 0.9212\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 7.1160 - mae: 0.8089\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 8.1985 - mae: 1.0957\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.9569 - mae: 1.3453\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.0937 - mae: 0.5667\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.5703 - mae: 1.1877\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.3161 - mae: 0.7185\n",
      "Epoch 318/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.7249 - mae: 1.1667\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 7.9828 - mae: 1.1016\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 8.5087 - mae: 1.2678\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 6.8268 - mae: 0.8875\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 7.3868 - mae: 1.0271\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.0917 - mae: 1.2180\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.2818 - mae: 0.6762\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.2725 - mae: 1.0048\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.1751 - mae: 1.1174\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.0540 - mae: 1.0476: 0s - loss: 6.6414 - mae: 0.\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.5560 - mae: 0.8813\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 7.4851 - mae: 1.1223\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 5.8606 - mae: 0.4988\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 8.2098 - mae: 1.3219\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.5189 - mae: 0.6549\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.6920 - mae: 1.0852\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 5.9146 - mae: 0.5353\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.3111 - mae: 1.1157\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 7.1461 - mae: 0.9502\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 6.7585 - mae: 0.7487\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 5.9745 - mae: 0.4866\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.8881 - mae: 1.4854\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.2419 - mae: 0.6769\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.2327 - mae: 0.6629\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.0163 - mae: 0.8616\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.7434 - mae: 0.9254\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.8196 - mae: 0.8753\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.7408 - mae: 0.8264\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.8520 - mae: 0.7914\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 6.7295 - mae: 0.7724\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.3834 - mae: 1.1184\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 5.8866 - mae: 0.5436\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.4514 - mae: 1.0176\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.3544 - mae: 0.9748\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 5.9879 - mae: 0.5626\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.7690 - mae: 1.1326\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.4337 - mae: 0.7879\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 7.0505 - mae: 0.8818\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.1465 - mae: 0.9648\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.1977 - mae: 0.6472: 0s - loss: 5.7884 - mae: 0.43\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 9.5450 - mae: 1.4329\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 5.7947 - mae: 0.4800\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.8060 - mae: 0.9501\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.0656 - mae: 0.5742\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.4145 - mae: 1.0098\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 6.2233 - mae: 0.7347\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.7389 - mae: 1.1085\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.9594 - mae: 0.9644\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.5322 - mae: 0.8945\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.0605 - mae: 0.7031\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.7077 - mae: 0.9463\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 5.9978 - mae: 0.5929\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.4582 - mae: 1.0601\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.5185 - mae: 0.7708\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.2032 - mae: 0.9355\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.0160 - mae: 0.9513\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.2668 - mae: 0.7351\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.0889 - mae: 1.0233\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 5.8185 - mae: 0.5309\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.1232 - mae: 1.0575\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 5.7455 - mae: 0.4554\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.3017 - mae: 1.1025\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 6.6711 - mae: 0.8986\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.4214 - mae: 0.8322\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.8822 - mae: 0.9206\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 7.0756 - mae: 0.9998\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.2803 - mae: 0.7008\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.1898 - mae: 0.6202\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.6610 - mae: 0.8554\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.3312 - mae: 1.1063\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.8357 - mae: 0.6751\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 7.7137 - mae: 1.1766\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 6.9227 - mae: 0.8387\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.3519 - mae: 1.0746\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.0943 - mae: 0.6108\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.7857 - mae: 1.0426\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.4432 - mae: 0.7889\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 6.5146 - mae: 0.8753\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.7160 - mae: 0.8432\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 6.6518 - mae: 0.8663\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 6.1099 - mae: 0.7001\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.4505 - mae: 0.7428\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.0203 - mae: 0.9625\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 5.7608 - mae: 0.4429\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.0125 - mae: 1.0023\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.2837 - mae: 1.0271\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.3168 - mae: 0.6430\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.0600 - mae: 0.9980\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 6.4594 - mae: 0.8107\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.5426 - mae: 0.7662\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.3358 - mae: 0.7737\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.1005 - mae: 0.9076\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.7818 - mae: 0.7835\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.2771 - mae: 0.6828\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.2905 - mae: 0.9565\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 6.3188 - mae: 0.7498\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.6971 - mae: 1.2149\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 5.9954 - mae: 0.5363\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.0665 - mae: 1.0455\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 5.8142 - mae: 0.4687\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 8.1821 - mae: 1.3561\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.3669 - mae: 0.7761\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 7.2969 - mae: 0.9728\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.4710 - mae: 0.8190\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.0303 - mae: 0.5501\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.0639 - mae: 0.9399\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.9907 - mae: 1.0245\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.1712 - mae: 0.6704\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.5865 - mae: 0.8646\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 7.2834 - mae: 0.9064\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 7.5260 - mae: 1.0534\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.2050 - mae: 0.5184\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.8825 - mae: 1.2289\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.2164 - mae: 0.5751\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.0392 - mae: 1.0015\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.2882 - mae: 1.0395\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.4131 - mae: 0.8130\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.6873 - mae: 0.9070\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.9359 - mae: 0.9228\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.6141 - mae: 0.8139\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.7005 - mae: 0.8438\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.9855 - mae: 0.9090\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.4578 - mae: 0.8300\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.3641 - mae: 0.8021\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 5.9851 - mae: 0.6011\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 6.9096 - mae: 0.9433\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.8400 - mae: 0.8080\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 6.4173 - mae: 0.8386\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.0815 - mae: 0.7265\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.2925 - mae: 0.7832\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.2918 - mae: 0.7121\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.5826 - mae: 1.1665\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 6.1148 - mae: 0.6030\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.9240 - mae: 0.8924\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 6.3451 - mae: 0.8339\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 5.6000 - mae: 0.4252\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.8262 - mae: 0.9318\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.4496 - mae: 0.8404\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.1877 - mae: 0.7546\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.4697 - mae: 0.8768\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 6.5048 - mae: 0.8200\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.4592 - mae: 1.0286\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 5.8373 - mae: 0.4901\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.2686 - mae: 0.7046\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.7366 - mae: 0.9385\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 6.0187 - mae: 0.7122\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.5279 - mae: 0.8430\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.4613 - mae: 0.8485\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.1615 - mae: 0.7409\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.4415 - mae: 0.8499\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.6528 - mae: 0.8958\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.3539 - mae: 0.7938\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.3114 - mae: 0.6854\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.4030 - mae: 0.8763\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.2646 - mae: 0.7299\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.3363 - mae: 0.9557\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.3374 - mae: 0.7839\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.1101 - mae: 0.6955\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.2365 - mae: 0.7754\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 5.8848 - mae: 0.5853\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 7.7258 - mae: 1.0593\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 6.0409 - mae: 0.5978\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.4347 - mae: 0.7987\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.1182 - mae: 0.6695\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.5850 - mae: 0.8081\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 6.5257 - mae: 0.8173\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 5.5531 - mae: 0.4033\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 7.1368 - mae: 1.0238\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 5.6692 - mae: 0.4867\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 6.6138 - mae: 0.9215\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 8.1759 - mae: 1.1662\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 6.4600 - mae: 0.6639\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.8553 - mae: 0.9193\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.4508 - mae: 0.8353\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 6.1744 - mae: 0.7284\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 5.8381 - mae: 0.5356\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.0428 - mae: 1.0782\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 5.6421 - mae: 0.4652\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 6.6070 - mae: 0.9522\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 6.2856 - mae: 0.7629\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 5.7205 - mae: 0.5188\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 7.3929 - mae: 1.0147\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 6.4751 - mae: 0.6821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2840c215bb0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model with 500 epochs\n",
    "model_reg_2.fit(x_train_rnn,y_train_rnn, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 26.3441 - mae: 3.4571\n",
      "5.132648807975346 3.457054615020752\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model \n",
    "mse, mae = model_reg_2.evaluate(x_test_rnn, y_test_rnn)\n",
    "#take the square root of mse so it is rmse\n",
    "rmse_rnn = np.sqrt(mse)\n",
    "#print the measures\n",
    "print(rmse_rnn, mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this the training seems to be ok but when looking at test data the MAE and MSE of around 6 and 4 respectively are a lot worse than the basic model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is at this point that i feel the regression is not correct and I should do classification in grades similar to the research paper. \n",
    "\n",
    "This is upon looking at the study in europe site as above for attainnig the grades. It does not appear to have any decimal grades so it will be better to attempt to classify the results rather than predict a likely value for them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 21) (119, 21)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#when splitting the data there is between 20 and 21 options so it causes the netwoek to have an error.\n",
    "#this was from testing where errors would happen depending on the splitting of the data rerutning 20 or 21 lines\n",
    "y_test_nn = to_categorical(y_test,21)\n",
    "y_train_nn = to_categorical(y_train,21)\n",
    "print(y_train_nn.shape,y_test_nn.shape)\n",
    "print(y_test_nn[1])\n",
    "print(y_train_nn[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a basic model for a classification NN. \n",
    "def build_model_class():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(21, activation=\"softmax\"))\n",
    " \n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 21)                693       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,253\n",
      "Trainable params: 15,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build a basic model for the \n",
    "model_class = build_model_class()\n",
    "\n",
    "model_class.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 1s 2ms/step - loss: 3.1234 - accuracy: 0.0761\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.7316 - accuracy: 0.1087\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.5989 - accuracy: 0.2065\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.5095 - accuracy: 0.2283\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3760 - accuracy: 0.2754\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 2.2724 - accuracy: 0.2717\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1852 - accuracy: 0.3116\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0850 - accuracy: 0.3188\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 811us/step - loss: 2.0005 - accuracy: 0.3587\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.9373 - accuracy: 0.3696\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.8731 - accuracy: 0.3659\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.7973 - accuracy: 0.4094\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.7594 - accuracy: 0.3841\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.7209 - accuracy: 0.4348\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 937us/step - loss: 1.6562 - accuracy: 0.4239\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.6109 - accuracy: 0.4420\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.5993 - accuracy: 0.4674\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 623us/step - loss: 1.5341 - accuracy: 0.4493\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.5020 - accuracy: 0.4855\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.5128 - accuracy: 0.4493\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.4286 - accuracy: 0.5072\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.3912 - accuracy: 0.5217\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.3767 - accuracy: 0.4928\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3344 - accuracy: 0.5217\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.3291 - accuracy: 0.5326\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.3014 - accuracy: 0.5580\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 623us/step - loss: 1.2483 - accuracy: 0.5543\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.2611 - accuracy: 0.5217\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.2142 - accuracy: 0.5435\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.1739 - accuracy: 0.5761\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.2084 - accuracy: 0.5616\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.1781 - accuracy: 0.5688\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.1630 - accuracy: 0.5688\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.0951 - accuracy: 0.6232\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.0845 - accuracy: 0.6196\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 623us/step - loss: 1.0861 - accuracy: 0.6123\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.0547 - accuracy: 0.6304\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 1.0440 - accuracy: 0.6377\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.0378 - accuracy: 0.6449\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.0159 - accuracy: 0.6558\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 1.0199 - accuracy: 0.6196\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.9964 - accuracy: 0.6377\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.0240 - accuracy: 0.6341\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.9971 - accuracy: 0.6268\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 872us/step - loss: 0.9523 - accuracy: 0.6558\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.9388 - accuracy: 0.6630\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.9291 - accuracy: 0.6848\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.8972 - accuracy: 0.6775\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.9116 - accuracy: 0.6667\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.8608 - accuracy: 0.68 - 0s 748us/step - loss: 0.9177 - accuracy: 0.6884\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.8740 - accuracy: 0.6957\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.8377 - accuracy: 0.7283\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.8721 - accuracy: 0.6848\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.8778 - accuracy: 0.6848\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.8521 - accuracy: 0.6920\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.8318 - accuracy: 0.7391\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.7702 - accuracy: 0.7645\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.8208 - accuracy: 0.7101\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.7556 - accuracy: 0.7681\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.7769 - accuracy: 0.7174\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.7725 - accuracy: 0.7283\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.7671 - accuracy: 0.7464\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.7025 - accuracy: 0.7826\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.7157 - accuracy: 0.7754\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 811us/step - loss: 0.7231 - accuracy: 0.7609\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.7070 - accuracy: 0.7717\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.6743 - accuracy: 0.7899\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.6923 - accuracy: 0.7645\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.6767 - accuracy: 0.7681\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.6401 - accuracy: 0.8043\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.6606 - accuracy: 0.7790\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.6635 - accuracy: 0.7790\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.6138 - accuracy: 0.8225\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.5838 - accuracy: 0.8225\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.6189 - accuracy: 0.7971\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 811us/step - loss: 0.6176 - accuracy: 0.7935\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.5664 - accuracy: 0.8007\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.5985 - accuracy: 0.8225\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.5460 - accuracy: 0.8261\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.6045 - accuracy: 0.8007\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.5712 - accuracy: 0.8297\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.5395 - accuracy: 0.8297\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.5479 - accuracy: 0.8297\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 623us/step - loss: 0.5569 - accuracy: 0.8370\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.4825 - accuracy: 0.8623\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.5428 - accuracy: 0.8261\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.4994 - accuracy: 0.8587\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 811us/step - loss: 0.4825 - accuracy: 0.8406\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.5232 - accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.4718 - accuracy: 0.8732\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.4445 - accuracy: 0.8696\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.4527 - accuracy: 0.8732\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.4931 - accuracy: 0.8478\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.4265 - accuracy: 0.8913\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.4726 - accuracy: 0.8406\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.4100 - accuracy: 0.9094\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.4888 - accuracy: 0.8587\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.3943 - accuracy: 0.9022\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.3866 - accuracy: 0.9094\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.3873 - accuracy: 0.8841\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.3786 - accuracy: 0.9022\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.4217 - accuracy: 0.8804\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.3544 - accuracy: 0.9167\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.4305 - accuracy: 0.8514\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.3197 - accuracy: 0.9348\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.3510 - accuracy: 0.9058\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.3616 - accuracy: 0.9058\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.3448 - accuracy: 0.9275\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.3360 - accuracy: 0.9348\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.3409 - accuracy: 0.9094\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.3098 - accuracy: 0.9203\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.3714 - accuracy: 0.8913\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.2741 - accuracy: 0.9529\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.2911 - accuracy: 0.9275\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.3548 - accuracy: 0.9022\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.2789 - accuracy: 0.9167\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.2834 - accuracy: 0.9384\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 623us/step - loss: 0.2651 - accuracy: 0.9457\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3689 - accuracy: 0.8913\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.9638\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.2595 - accuracy: 0.9348\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.2319 - accuracy: 0.9457\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.9130\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.2456 - accuracy: 0.9384\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.2406 - accuracy: 0.9565\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.9457\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.2943 - accuracy: 0.9239\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9457\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9746\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9529\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2430 - accuracy: 0.9529\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.9022\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9638\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9493\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.9674\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9638\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9529\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9348\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9928\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9638\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.9601\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9601\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9710\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1698 - accuracy: 0.9674\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.9746\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.9420\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9783\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9891\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9457\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9819\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9855\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9819\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.9384\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9964\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9891\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9783\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1384 - accuracy: 0.9746\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9819\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9928\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9855\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9493\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9964\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0999 - accuracy: 0.9819\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9855\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9674\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9928\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9891\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.9783\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9855\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.9348\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9964\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0811 - accuracy: 0.9928\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9964\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9819\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.9928\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9891\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0667 - accuracy: 0.9964\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9855\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9783\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9783\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0585 - accuracy: 0.9964\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9384\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9928\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9964\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9638\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9819\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0388 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9746\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0393 - accuracy: 0.9964\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0441 - accuracy: 0.9964\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0769 - accuracy: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2840f0f8910>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build the model with 200 epochs \n",
    "\n",
    "model_class.fit(x_train,y_train_nn, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 4.8253 - accuracy: 0.3193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.825283050537109, 0.3193277418613434]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model to see the results \n",
    "model_class.evaluate(x_test, y_test_nn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first model only has an accuracy of 31% for the test data which is not ideal in predicting anything. as it is less than 50% it would be better to randomly guess than to use the basic model as it is. \n",
    "I will make another more complex model to see if i can get a better prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_class_2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',input_shape=(x_train_rnn.shape[1],)))\n",
    "    model.add(layers.Dense(64,kernel_regularizer=regularizers.l1(0.001), activation='relu'))\n",
    "    model.add(layers.Dense(64,kernel_regularizer=regularizers.l1(0.001), activation='relu'))\n",
    "    model.add(layers.Dense(64,kernel_regularizer=regularizers.l1(0.001), activation='relu'))\n",
    "    model.add(layers.Reshape((64,1)))\n",
    "    model.add(layers.Conv1D(64,2,activation='relu'))\n",
    "    model.add(layers.Conv1D(128,4,activation='relu'))\n",
    "    model.add(layers.Conv1D(64,2,activation='relu'))\n",
    "    model.add(layers.Conv1D(64,8,activation='relu'))\n",
    "    model.add(layers.Conv1D(32,4,activation='relu'))\n",
    "    model.add(layers.Conv1D(64,2,activation='relu'))\n",
    "    model.add(layers.Dense(128,kernel_regularizer=regularizers.l1(0.001), activation='relu'))\n",
    "    model.add(layers.Dense(128,kernel_regularizer=regularizers.l1(0.001), activation='relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(21, activation=\"softmax\"))\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 64, 1)             0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 63, 64)            192       \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 60, 128)           32896     \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 59, 64)            16448     \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 52, 64)            32832     \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 49, 32)            8224      \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 48, 64)            4160      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 48, 128)           8320      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 48, 128)           16512     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 48, 128)           0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6144)              0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 21)                129045    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 263,221\n",
      "Trainable params: 263,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build a basic model for the \n",
    "model_class_2 = build_model_class_2()\n",
    "\n",
    "model_class_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "9/9 [==============================] - 1s 16ms/step - loss: 5.9260 - accuracy: 0.1159\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 5.3805 - accuracy: 0.1413\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 5.1108 - accuracy: 0.1413\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 4.8480 - accuracy: 0.1196\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 4.6015 - accuracy: 0.1594\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 4.3214 - accuracy: 0.1667\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.9478 - accuracy: 0.2246\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 3.6701 - accuracy: 0.2246\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.4865 - accuracy: 0.2500\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 3.3262 - accuracy: 0.2754\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 3.1819 - accuracy: 0.2536\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.8206 - accuracy: 0.3370\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.8878 - accuracy: 0.3333\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.7625 - accuracy: 0.3261\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 2.6631 - accuracy: 0.3732\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.5164 - accuracy: 0.3514\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.5834 - accuracy: 0.3333\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.4534 - accuracy: 0.3623\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.3668 - accuracy: 0.3406\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.4467 - accuracy: 0.3406\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.1982 - accuracy: 0.4239\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 2.1289 - accuracy: 0.4457\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.2218 - accuracy: 0.4094\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.1782 - accuracy: 0.3913\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.1000 - accuracy: 0.4529\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.0241 - accuracy: 0.4493\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.0469 - accuracy: 0.4638\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.9937 - accuracy: 0.4312\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.9591 - accuracy: 0.4783\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 2.0400 - accuracy: 0.4710\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.8572 - accuracy: 0.5109\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.9004 - accuracy: 0.5036\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.9158 - accuracy: 0.4710\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.8345 - accuracy: 0.5072\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.7403 - accuracy: 0.5435\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.7964 - accuracy: 0.5290\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6639 - accuracy: 0.5652\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.7140 - accuracy: 0.5181\n",
      "Epoch 39/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.7615 - accuracy: 0.5109\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6301 - accuracy: 0.5942\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6182 - accuracy: 0.5870\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.5052 - accuracy: 0.6449\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6369 - accuracy: 0.5616\n",
      "Epoch 44/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6347 - accuracy: 0.5688\n",
      "Epoch 45/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.6195 - accuracy: 0.5833\n",
      "Epoch 46/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4758 - accuracy: 0.6196\n",
      "Epoch 47/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.5232 - accuracy: 0.6051\n",
      "Epoch 48/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.5424 - accuracy: 0.6341\n",
      "Epoch 49/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.5459 - accuracy: 0.6341\n",
      "Epoch 50/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.5381 - accuracy: 0.6268\n",
      "Epoch 51/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3352 - accuracy: 0.6630\n",
      "Epoch 52/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4892 - accuracy: 0.5906\n",
      "Epoch 53/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.2945 - accuracy: 0.7210\n",
      "Epoch 54/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.5689 - accuracy: 0.5870\n",
      "Epoch 55/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3704 - accuracy: 0.6413\n",
      "Epoch 56/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3941 - accuracy: 0.6449\n",
      "Epoch 57/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2744 - accuracy: 0.7174\n",
      "Epoch 58/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2416 - accuracy: 0.7283\n",
      "Epoch 59/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.4859 - accuracy: 0.6087\n",
      "Epoch 60/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2203 - accuracy: 0.6812\n",
      "Epoch 61/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3129 - accuracy: 0.6848\n",
      "Epoch 62/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1833 - accuracy: 0.7246\n",
      "Epoch 63/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.5084 - accuracy: 0.6522\n",
      "Epoch 64/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0930 - accuracy: 0.7935\n",
      "Epoch 65/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2027 - accuracy: 0.7355\n",
      "Epoch 66/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2292 - accuracy: 0.6993\n",
      "Epoch 67/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2147 - accuracy: 0.7174\n",
      "Epoch 68/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0728 - accuracy: 0.7754\n",
      "Epoch 69/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.1890 - accuracy: 0.7464\n",
      "Epoch 70/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.9985 - accuracy: 0.8333\n",
      "Epoch 71/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.3168 - accuracy: 0.7138\n",
      "Epoch 72/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0137 - accuracy: 0.8261\n",
      "Epoch 73/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9942 - accuracy: 0.7935\n",
      "Epoch 74/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1432 - accuracy: 0.7609\n",
      "Epoch 75/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9706 - accuracy: 0.8333\n",
      "Epoch 76/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0003 - accuracy: 0.8152\n",
      "Epoch 77/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9145 - accuracy: 0.8442\n",
      "Epoch 78/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1854 - accuracy: 0.7355\n",
      "Epoch 79/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8767 - accuracy: 0.8406\n",
      "Epoch 80/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8816 - accuracy: 0.8696\n",
      "Epoch 81/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0658 - accuracy: 0.8297\n",
      "Epoch 82/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8441 - accuracy: 0.8659\n",
      "Epoch 83/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2385 - accuracy: 0.7500\n",
      "Epoch 84/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8196 - accuracy: 0.8877\n",
      "Epoch 85/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.8957 - accuracy: 0.8768\n",
      "Epoch 86/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7789 - accuracy: 0.8877\n",
      "Epoch 87/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8403 - accuracy: 0.8696\n",
      "Epoch 88/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9037 - accuracy: 0.8406\n",
      "Epoch 89/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.8683 - accuracy: 0.8732\n",
      "Epoch 90/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6402 - accuracy: 0.9529\n",
      "Epoch 91/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3717 - accuracy: 0.7572\n",
      "Epoch 92/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5960 - accuracy: 0.9783\n",
      "Epoch 93/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8583 - accuracy: 0.8732\n",
      "Epoch 94/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8246 - accuracy: 0.8804\n",
      "Epoch 95/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7798 - accuracy: 0.9275\n",
      "Epoch 96/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8040 - accuracy: 0.8804\n",
      "Epoch 97/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8514 - accuracy: 0.8478\n",
      "Epoch 98/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7275 - accuracy: 0.9022\n",
      "Epoch 99/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9471 - accuracy: 0.8478\n",
      "Epoch 100/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.6060 - accuracy: 0.9638\n",
      "Epoch 101/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6152 - accuracy: 0.9239\n",
      "Epoch 102/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0217 - accuracy: 0.8116\n",
      "Epoch 103/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5357 - accuracy: 0.9891\n",
      "Epoch 104/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9367 - accuracy: 0.8478\n",
      "Epoch 105/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5158 - accuracy: 0.9928\n",
      "Epoch 106/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0471 - accuracy: 0.8370\n",
      "Epoch 107/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6511 - accuracy: 0.9420\n",
      "Epoch 108/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5206 - accuracy: 0.9855\n",
      "Epoch 109/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0568 - accuracy: 0.8406\n",
      "Epoch 110/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6915 - accuracy: 0.9203\n",
      "Epoch 111/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6438 - accuracy: 0.9312\n",
      "Epoch 112/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.8160 - accuracy: 0.8804\n",
      "Epoch 113/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8533 - accuracy: 0.8732\n",
      "Epoch 114/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4863 - accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1176 - accuracy: 0.8080\n",
      "Epoch 116/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4949 - accuracy: 0.9964\n",
      "Epoch 117/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4745 - accuracy: 0.9891\n",
      "Epoch 118/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4469 - accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4415 - accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.4027 - accuracy: 0.8007\n",
      "Epoch 121/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5145 - accuracy: 0.9891\n",
      "Epoch 122/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0654 - accuracy: 0.8080\n",
      "Epoch 123/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4899 - accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4449 - accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6314 - accuracy: 0.9638\n",
      "Epoch 126/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2284 - accuracy: 0.8587\n",
      "Epoch 127/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4847 - accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4445 - accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4305 - accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4254 - accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.1232 - accuracy: 0.8333\n",
      "Epoch 132/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.4981 - accuracy: 0.9928\n",
      "Epoch 133/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0446 - accuracy: 0.8370\n",
      "Epoch 134/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4832 - accuracy: 0.9891\n",
      "Epoch 135/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4314 - accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4215 - accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4170 - accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4120 - accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4066 - accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1444 - accuracy: 0.8406\n",
      "Epoch 141/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7654 - accuracy: 0.8804\n",
      "Epoch 142/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4685 - accuracy: 0.9891\n",
      "Epoch 143/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7942 - accuracy: 0.8841\n",
      "Epoch 144/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4348 - accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4081 - accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4029 - accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3979 - accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3937 - accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.8945 - accuracy: 0.9420\n",
      "Epoch 150/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.1208 - accuracy: 0.7899\n",
      "Epoch 151/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5650 - accuracy: 0.9312\n",
      "Epoch 152/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7823 - accuracy: 0.8768\n",
      "Epoch 153/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4741 - accuracy: 0.9855\n",
      "Epoch 154/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4000 - accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3921 - accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3872 - accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3836 - accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3791 - accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3957 - accuracy: 0.9964\n",
      "Epoch 160/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.5173 - accuracy: 0.7971\n",
      "Epoch 161/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4224 - accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4108 - accuracy: 0.9964\n",
      "Epoch 163/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3789 - accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3729 - accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3691 - accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3652 - accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.3872 - accuracy: 0.8116\n",
      "Epoch 168/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5902 - accuracy: 0.9493\n",
      "Epoch 169/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4806 - accuracy: 0.9674\n",
      "Epoch 170/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3840 - accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3718 - accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3655 - accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3674 - accuracy: 0.9964\n",
      "Epoch 174/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3875 - accuracy: 0.7826\n",
      "Epoch 175/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4245 - accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7007 - accuracy: 0.8913\n",
      "Epoch 177/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6280 - accuracy: 0.9058\n",
      "Epoch 178/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4044 - accuracy: 0.9855\n",
      "Epoch 179/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0043 - accuracy: 0.8188\n",
      "Epoch 180/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3922 - accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3721 - accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3605 - accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3564 - accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2438 - accuracy: 0.8406\n",
      "Epoch 185/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3982 - accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.3806 - accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3636 - accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1307 - accuracy: 0.7645\n",
      "Epoch 189/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4627 - accuracy: 0.9783\n",
      "Epoch 190/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3667 - accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3578 - accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3538 - accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3506 - accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3458 - accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3401 - accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.5826 - accuracy: 0.7899\n",
      "Epoch 197/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3957 - accuracy: 0.9891\n",
      "Epoch 198/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3585 - accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4937 - accuracy: 0.9565\n",
      "Epoch 200/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4310 - accuracy: 0.9710\n",
      "Epoch 201/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8084 - accuracy: 0.8696\n",
      "Epoch 202/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3623 - accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7740 - accuracy: 0.8768\n",
      "Epoch 204/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3941 - accuracy: 0.9891\n",
      "Epoch 205/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6349 - accuracy: 0.9130\n",
      "Epoch 206/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6277 - accuracy: 0.9094\n",
      "Epoch 207/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3638 - accuracy: 0.9964\n",
      "Epoch 208/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3420 - accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3370 - accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3347 - accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3319 - accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6520 - accuracy: 0.9746\n",
      "Epoch 213/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9174 - accuracy: 0.8732\n",
      "Epoch 214/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3577 - accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3405 - accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0190 - accuracy: 0.8261\n",
      "Epoch 217/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3551 - accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3366 - accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3308 - accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3277 - accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3240 - accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3204 - accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4970 - accuracy: 0.9674\n",
      "Epoch 224/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2216 - accuracy: 0.8732\n",
      "Epoch 225/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3431 - accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3273 - accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3205 - accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3174 - accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3145 - accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.8639 - accuracy: 0.8804\n",
      "Epoch 231/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4807 - accuracy: 0.9638\n",
      "Epoch 232/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3304 - accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9861 - accuracy: 0.7862\n",
      "Epoch 234/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3841 - accuracy: 0.9928\n",
      "Epoch 235/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3242 - accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3154 - accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3121 - accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3090 - accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3059 - accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3020 - accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2970 - accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1742 - accuracy: 0.7862\n",
      "Epoch 243/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4738 - accuracy: 0.9565\n",
      "Epoch 244/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3225 - accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3028 - accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2981 - accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2942 - accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2911 - accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2866 - accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.8712 - accuracy: 0.9493\n",
      "Epoch 251/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7817 - accuracy: 0.8261\n",
      "Epoch 252/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3852 - accuracy: 0.9746\n",
      "Epoch 253/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3070 - accuracy: 0.9964\n",
      "Epoch 254/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2895 - accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2854 - accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2830 - accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2805 - accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1918 - accuracy: 0.8370\n",
      "Epoch 259/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4017 - accuracy: 0.9746\n",
      "Epoch 260/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2927 - accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2846 - accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2816 - accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2791 - accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2767 - accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2137 - accuracy: 0.7681\n",
      "Epoch 266/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3526 - accuracy: 0.9783\n",
      "Epoch 267/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5775 - accuracy: 0.9457\n",
      "Epoch 268/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2932 - accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2840 - accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0109 - accuracy: 0.8116\n",
      "Epoch 271/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4020 - accuracy: 0.9783\n",
      "Epoch 272/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2968 - accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2875 - accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2837 - accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2805 - accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2764 - accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1071 - accuracy: 0.8551\n",
      "Epoch 278/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5076 - accuracy: 0.9457\n",
      "Epoch 279/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2976 - accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2818 - accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2767 - accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2737 - accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2705 - accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2673 - accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2636 - accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.4828 - accuracy: 0.7717\n",
      "Epoch 287/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5831 - accuracy: 0.9094\n",
      "Epoch 288/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3057 - accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2735 - accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2681 - accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2657 - accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2634 - accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2600 - accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.3451 - accuracy: 0.7935\n",
      "Epoch 295/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3761 - accuracy: 0.9674\n",
      "Epoch 296/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2743 - accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2690 - accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2661 - accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2628 - accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2602 - accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6762 - accuracy: 0.9348\n",
      "Epoch 302/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1470 - accuracy: 0.7645\n",
      "Epoch 303/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3281 - accuracy: 0.9964\n",
      "Epoch 304/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2763 - accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2653 - accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2616 - accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2585 - accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2549 - accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.4572 - accuracy: 0.8406\n",
      "Epoch 310/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4694 - accuracy: 0.9348\n",
      "Epoch 311/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2955 - accuracy: 0.9964\n",
      "Epoch 312/1000\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2610 - accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2577 - accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2532 - accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2521 - accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3209 - accuracy: 0.8043\n",
      "Epoch 317/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.3803 - accuracy: 0.9783\n",
      "Epoch 318/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2692 - accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2576 - accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2539 - accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2509 - accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2482 - accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.4540 - accuracy: 0.7899\n",
      "Epoch 324/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3755 - accuracy: 0.9710\n",
      "Epoch 325/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2633 - accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2557 - accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2524 - accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2494 - accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0371 - accuracy: 0.8442\n",
      "Epoch 330/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3985 - accuracy: 0.9493\n",
      "Epoch 331/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2661 - accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2531 - accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2487 - accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2468 - accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2445 - accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2421 - accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2392 - accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.6413 - accuracy: 0.7899\n",
      "Epoch 339/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3015 - accuracy: 0.9928\n",
      "Epoch 340/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2535 - accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2452 - accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2411 - accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2427 - accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3903 - accuracy: 0.7790\n",
      "Epoch 345/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2751 - accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2502 - accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2458 - accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2433 - accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2407 - accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2086 - accuracy: 0.7826\n",
      "Epoch 351/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3389 - accuracy: 0.9819\n",
      "Epoch 352/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2536 - accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2453 - accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2421 - accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2395 - accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4214 - accuracy: 0.9638\n",
      "Epoch 357/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.8798 - accuracy: 0.8261\n",
      "Epoch 358/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2743 - accuracy: 0.9964\n",
      "Epoch 359/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2554 - accuracy: 0.9964\n",
      "Epoch 360/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.8185 - accuracy: 0.8514\n",
      "Epoch 361/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2808 - accuracy: 0.9891\n",
      "Epoch 362/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4179 - accuracy: 0.9529\n",
      "Epoch 363/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5999 - accuracy: 0.8768\n",
      "Epoch 364/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2571 - accuracy: 0.9964\n",
      "Epoch 365/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2413 - accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2387 - accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2363 - accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2337 - accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9189 - accuracy: 0.8768\n",
      "Epoch 370/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4693 - accuracy: 0.9384\n",
      "Epoch 371/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2563 - accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2384 - accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2349 - accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2320 - accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2299 - accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0111 - accuracy: 0.8804\n",
      "Epoch 377/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4845 - accuracy: 0.9420\n",
      "Epoch 378/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2620 - accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2397 - accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2356 - accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2324 - accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2290 - accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2254 - accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2219 - accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2907 - accuracy: 0.9928\n",
      "Epoch 386/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.2008 - accuracy: 0.7536\n",
      "Epoch 387/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3229 - accuracy: 0.9819\n",
      "Epoch 388/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6411 - accuracy: 0.8732\n",
      "Epoch 389/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2409 - accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2262 - accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2228 - accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2205 - accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2184 - accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2160 - accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0390 - accuracy: 0.8297\n",
      "Epoch 396/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4868 - accuracy: 0.8986\n",
      "Epoch 397/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3113 - accuracy: 0.9710\n",
      "Epoch 398/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2273 - accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2212 - accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2187 - accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2166 - accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2143 - accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2117 - accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4196 - accuracy: 0.9855\n",
      "Epoch 405/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9757 - accuracy: 0.8116\n",
      "Epoch 406/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2693 - accuracy: 0.9891\n",
      "Epoch 407/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2337 - accuracy: 0.9964\n",
      "Epoch 408/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6631 - accuracy: 0.8406\n",
      "Epoch 409/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3219 - accuracy: 0.9746\n",
      "Epoch 410/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2196 - accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2150 - accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2129 - accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2106 - accuracy: 1.0000\n",
      "Epoch 414/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2080 - accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2066 - accuracy: 1.0000\n",
      "Epoch 416/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.2169 - accuracy: 0.8007\n",
      "Epoch 417/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2493 - accuracy: 0.9964\n",
      "Epoch 418/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4557 - accuracy: 0.9167\n",
      "Epoch 419/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3407 - accuracy: 0.9529\n",
      "Epoch 420/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2499 - accuracy: 0.9928\n",
      "Epoch 421/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2140 - accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2110 - accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2086 - accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2061 - accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2030 - accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1996 - accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1959 - accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4664 - accuracy: 0.7464\n",
      "Epoch 429/1000\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3268 - accuracy: 0.9746\n",
      "Epoch 430/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2279 - accuracy: 0.9928\n",
      "Epoch 431/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7642 - accuracy: 0.8406\n",
      "Epoch 432/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2459 - accuracy: 0.9928\n",
      "Epoch 433/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6818 - accuracy: 0.8442\n",
      "Epoch 434/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2515 - accuracy: 0.9928\n",
      "Epoch 435/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4566 - accuracy: 0.9167\n",
      "Epoch 436/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2219 - accuracy: 0.9928\n",
      "Epoch 437/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2025 - accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1994 - accuracy: 1.0000\n",
      "Epoch 439/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1979 - accuracy: 1.0000\n",
      "Epoch 440/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1963 - accuracy: 1.0000\n",
      "Epoch 441/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1942 - accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1915 - accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1881 - accuracy: 1.0000\n",
      "Epoch 444/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.2756 - accuracy: 0.8043\n",
      "Epoch 445/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4923 - accuracy: 0.9348\n",
      "Epoch 446/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2191 - accuracy: 1.0000\n",
      "Epoch 447/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1992 - accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1951 - accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1919 - accuracy: 1.0000\n",
      "Epoch 450/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1897 - accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1880 - accuracy: 1.0000\n",
      "Epoch 452/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9715 - accuracy: 0.8514\n",
      "Epoch 453/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3761 - accuracy: 0.9312\n",
      "Epoch 454/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2504 - accuracy: 0.9819\n",
      "Epoch 455/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1944 - accuracy: 1.0000\n",
      "Epoch 456/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1899 - accuracy: 1.0000\n",
      "Epoch 457/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1878 - accuracy: 1.0000\n",
      "Epoch 458/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1863 - accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1847 - accuracy: 1.0000\n",
      "Epoch 460/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0217 - accuracy: 0.8478\n",
      "Epoch 461/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6239 - accuracy: 0.8478\n",
      "Epoch 462/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2258 - accuracy: 1.0000\n",
      "Epoch 463/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1951 - accuracy: 1.0000\n",
      "Epoch 464/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1894 - accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1869 - accuracy: 1.0000\n",
      "Epoch 466/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1849 - accuracy: 1.0000\n",
      "Epoch 467/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1852 - accuracy: 1.0000\n",
      "Epoch 468/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1848 - accuracy: 0.8261\n",
      "Epoch 469/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2108 - accuracy: 1.0000\n",
      "Epoch 470/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1924 - accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1885 - accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1862 - accuracy: 1.0000\n",
      "Epoch 473/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1842 - accuracy: 1.0000\n",
      "Epoch 474/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1826 - accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0949 - accuracy: 0.7826\n",
      "Epoch 476/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2642 - accuracy: 0.9783\n",
      "Epoch 477/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1949 - accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1880 - accuracy: 1.0000\n",
      "Epoch 479/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1857 - accuracy: 1.0000\n",
      "Epoch 480/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1834 - accuracy: 1.0000\n",
      "Epoch 481/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1809 - accuracy: 1.0000\n",
      "Epoch 482/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2009 - accuracy: 0.9891\n",
      "Epoch 483/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6634 - accuracy: 0.7174\n",
      "Epoch 484/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2399 - accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1902 - accuracy: 1.0000\n",
      "Epoch 486/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1857 - accuracy: 1.0000\n",
      "Epoch 487/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1835 - accuracy: 1.0000\n",
      "Epoch 488/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1815 - accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1798 - accuracy: 1.0000\n",
      "Epoch 490/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1775 - accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.7573 - accuracy: 0.8152\n",
      "Epoch 492/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2199 - accuracy: 1.0000\n",
      "Epoch 493/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3794 - accuracy: 0.9529\n",
      "Epoch 494/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1897 - accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1857 - accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1829 - accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1804 - accuracy: 1.0000\n",
      "Epoch 498/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1785 - accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9926 - accuracy: 0.7717\n",
      "Epoch 500/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3507 - accuracy: 0.9638\n",
      "Epoch 501/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5395 - accuracy: 0.9058\n",
      "Epoch 502/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2241 - accuracy: 0.9928\n",
      "Epoch 503/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5466 - accuracy: 0.8877\n",
      "Epoch 504/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3970 - accuracy: 0.9601\n",
      "Epoch 505/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1892 - accuracy: 1.0000\n",
      "Epoch 506/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.7912 - accuracy: 0.7971\n",
      "Epoch 507/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2482 - accuracy: 0.9855\n",
      "Epoch 508/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2668 - accuracy: 0.9783\n",
      "Epoch 509/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1848 - accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1808 - accuracy: 1.0000\n",
      "Epoch 511/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1785 - accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1759 - accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1734 - accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1703 - accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3840 - accuracy: 0.8442\n",
      "Epoch 516/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3145 - accuracy: 0.9493\n",
      "Epoch 517/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1970 - accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2461 - accuracy: 0.9710\n",
      "Epoch 519/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1780 - accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1737 - accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1716 - accuracy: 1.0000\n",
      "Epoch 522/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1698 - accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5742 - accuracy: 0.9275\n",
      "Epoch 524/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5346 - accuracy: 0.9022\n",
      "Epoch 525/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1907 - accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1747 - accuracy: 1.0000\n",
      "Epoch 527/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1816 - accuracy: 0.9964\n",
      "Epoch 528/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7871 - accuracy: 0.8659\n",
      "Epoch 529/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2220 - accuracy: 0.9891\n",
      "Epoch 530/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1779 - accuracy: 1.0000\n",
      "Epoch 531/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1743 - accuracy: 1.0000\n",
      "Epoch 532/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1725 - accuracy: 1.0000\n",
      "Epoch 533/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1707 - accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1749 - accuracy: 0.9964\n",
      "Epoch 535/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3381 - accuracy: 0.7826\n",
      "Epoch 536/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2141 - accuracy: 0.9964\n",
      "Epoch 537/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1915 - accuracy: 0.9928\n",
      "Epoch 538/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8361 - accuracy: 0.8478\n",
      "Epoch 539/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1966 - accuracy: 1.0000\n",
      "Epoch 540/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1776 - accuracy: 1.0000\n",
      "Epoch 541/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1739 - accuracy: 1.0000\n",
      "Epoch 542/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1719 - accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1696 - accuracy: 1.0000\n",
      "Epoch 544/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1674 - accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9269 - accuracy: 0.9022\n",
      "Epoch 546/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3976 - accuracy: 0.9493\n",
      "Epoch 547/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1884 - accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1768 - accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1740 - accuracy: 1.0000\n",
      "Epoch 550/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1713 - accuracy: 1.0000\n",
      "Epoch 551/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1688 - accuracy: 1.0000\n",
      "Epoch 552/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1660 - accuracy: 1.0000\n",
      "Epoch 553/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9487 - accuracy: 0.8696\n",
      "Epoch 554/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2068 - accuracy: 0.9928\n",
      "Epoch 555/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1718 - accuracy: 1.0000\n",
      "Epoch 556/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1683 - accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1666 - accuracy: 1.0000\n",
      "Epoch 558/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1650 - accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1630 - accuracy: 1.0000\n",
      "Epoch 560/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1609 - accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9835 - accuracy: 0.8877\n",
      "Epoch 562/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4241 - accuracy: 0.9022\n",
      "Epoch 563/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1905 - accuracy: 0.9964\n",
      "Epoch 564/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1694 - accuracy: 1.0000\n",
      "Epoch 565/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1661 - accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1640 - accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1619 - accuracy: 1.0000\n",
      "Epoch 568/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1596 - accuracy: 1.0000\n",
      "Epoch 569/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.8556 - accuracy: 0.9094\n",
      "Epoch 570/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5832 - accuracy: 0.8587\n",
      "Epoch 571/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2264 - accuracy: 0.9891\n",
      "Epoch 572/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3128 - accuracy: 0.9601\n",
      "Epoch 573/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1795 - accuracy: 0.9928\n",
      "Epoch 574/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1628 - accuracy: 1.0000\n",
      "Epoch 575/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1606 - accuracy: 1.0000\n",
      "Epoch 576/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1583 - accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1564 - accuracy: 1.0000\n",
      "Epoch 578/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1543 - accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1517 - accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.3234 - accuracy: 0.7826\n",
      "Epoch 581/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3139 - accuracy: 0.9710\n",
      "Epoch 582/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3000 - accuracy: 0.9601\n",
      "Epoch 583/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2806 - accuracy: 0.9601\n",
      "Epoch 584/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2354 - accuracy: 0.9746\n",
      "Epoch 585/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4977 - accuracy: 0.9167\n",
      "Epoch 586/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1656 - accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1593 - accuracy: 1.0000\n",
      "Epoch 588/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1572 - accuracy: 1.0000\n",
      "Epoch 589/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9179 - accuracy: 0.8297\n",
      "Epoch 590/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2201 - accuracy: 0.9891\n",
      "Epoch 591/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1685 - accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1602 - accuracy: 1.0000\n",
      "Epoch 593/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1580 - accuracy: 1.0000\n",
      "Epoch 594/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1560 - accuracy: 1.0000\n",
      "Epoch 595/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1542 - accuracy: 1.0000\n",
      "Epoch 596/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3396 - accuracy: 0.9710\n",
      "Epoch 597/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9609 - accuracy: 0.8370\n",
      "Epoch 598/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2501 - accuracy: 0.9674\n",
      "Epoch 599/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5376 - accuracy: 0.8913\n",
      "Epoch 600/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1699 - accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1620 - accuracy: 1.0000\n",
      "Epoch 602/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1580 - accuracy: 1.0000\n",
      "Epoch 603/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1558 - accuracy: 1.0000\n",
      "Epoch 604/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1535 - accuracy: 1.0000\n",
      "Epoch 605/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1508 - accuracy: 1.0000\n",
      "Epoch 606/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1483 - accuracy: 1.0000\n",
      "Epoch 607/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1092 - accuracy: 0.8152\n",
      "Epoch 608/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2085 - accuracy: 0.9891\n",
      "Epoch 609/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1625 - accuracy: 1.0000\n",
      "Epoch 610/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1562 - accuracy: 1.0000\n",
      "Epoch 611/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1537 - accuracy: 1.0000\n",
      "Epoch 612/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1513 - accuracy: 1.0000\n",
      "Epoch 613/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1496 - accuracy: 1.0000\n",
      "Epoch 614/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2535 - accuracy: 0.8297\n",
      "Epoch 615/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4283 - accuracy: 0.9130\n",
      "Epoch 616/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1643 - accuracy: 1.0000\n",
      "Epoch 617/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1570 - accuracy: 1.0000\n",
      "Epoch 618/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1542 - accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1521 - accuracy: 1.0000\n",
      "Epoch 620/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1503 - accuracy: 1.0000\n",
      "Epoch 621/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1487 - accuracy: 1.0000\n",
      "Epoch 622/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.1624 - accuracy: 0.7645\n",
      "Epoch 623/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3291 - accuracy: 0.9493\n",
      "Epoch 624/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2412 - accuracy: 0.9746\n",
      "Epoch 625/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1963 - accuracy: 0.9891\n",
      "Epoch 626/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1551 - accuracy: 1.0000\n",
      "Epoch 627/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7150 - accuracy: 0.8514\n",
      "Epoch 628/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2178 - accuracy: 0.9819\n",
      "Epoch 629/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1584 - accuracy: 1.0000\n",
      "Epoch 630/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1536 - accuracy: 1.0000\n",
      "Epoch 631/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1518 - accuracy: 1.0000\n",
      "Epoch 632/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1499 - accuracy: 1.0000\n",
      "Epoch 633/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1477 - accuracy: 1.0000\n",
      "Epoch 634/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2204 - accuracy: 0.8297\n",
      "Epoch 635/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2572 - accuracy: 0.9710\n",
      "Epoch 636/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1627 - accuracy: 1.0000\n",
      "Epoch 637/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1559 - accuracy: 1.0000\n",
      "Epoch 638/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1533 - accuracy: 1.0000\n",
      "Epoch 639/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1499 - accuracy: 1.0000\n",
      "Epoch 640/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1479 - accuracy: 1.0000\n",
      "Epoch 641/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1457 - accuracy: 1.0000\n",
      "Epoch 642/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7183 - accuracy: 0.8949\n",
      "Epoch 643/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3755 - accuracy: 0.9094\n",
      "Epoch 644/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1590 - accuracy: 1.0000\n",
      "Epoch 645/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1504 - accuracy: 1.0000\n",
      "Epoch 646/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1481 - accuracy: 1.0000\n",
      "Epoch 647/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1466 - accuracy: 1.0000\n",
      "Epoch 648/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1450 - accuracy: 1.0000\n",
      "Epoch 649/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1428 - accuracy: 1.0000\n",
      "Epoch 650/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2829 - accuracy: 0.7862 0s - loss: 1.9588 - accuracy: 0.\n",
      "Epoch 651/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1736 - accuracy: 1.0000\n",
      "Epoch 652/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1525 - accuracy: 1.0000\n",
      "Epoch 653/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1488 - accuracy: 1.0000\n",
      "Epoch 654/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1467 - accuracy: 1.0000\n",
      "Epoch 655/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1449 - accuracy: 1.0000\n",
      "Epoch 656/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1429 - accuracy: 1.0000\n",
      "Epoch 657/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1415 - accuracy: 1.0000\n",
      "Epoch 658/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1391 - accuracy: 1.0000\n",
      "Epoch 659/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.3951 - accuracy: 0.7899\n",
      "Epoch 660/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1868 - accuracy: 0.9964\n",
      "Epoch 661/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1503 - accuracy: 1.0000\n",
      "Epoch 662/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1474 - accuracy: 1.0000\n",
      "Epoch 663/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1454 - accuracy: 1.0000\n",
      "Epoch 664/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1433 - accuracy: 1.0000\n",
      "Epoch 665/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1413 - accuracy: 1.0000\n",
      "Epoch 666/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7476 - accuracy: 0.8225\n",
      "Epoch 667/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4554 - accuracy: 0.9203\n",
      "Epoch 668/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2755 - accuracy: 0.9674\n",
      "Epoch 669/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6421 - accuracy: 0.8623\n",
      "Epoch 670/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1611 - accuracy: 1.0000\n",
      "Epoch 671/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1459 - accuracy: 1.0000\n",
      "Epoch 672/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1431 - accuracy: 1.0000\n",
      "Epoch 673/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1413 - accuracy: 1.0000\n",
      "Epoch 674/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1396 - accuracy: 1.0000\n",
      "Epoch 675/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1377 - accuracy: 1.0000\n",
      "Epoch 676/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6618 - accuracy: 0.8949\n",
      "Epoch 677/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5191 - accuracy: 0.8804\n",
      "Epoch 678/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3988 - accuracy: 0.9094\n",
      "Epoch 679/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1506 - accuracy: 1.0000\n",
      "Epoch 680/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1456 - accuracy: 1.0000\n",
      "Epoch 681/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1431 - accuracy: 1.0000\n",
      "Epoch 682/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1410 - accuracy: 1.0000\n",
      "Epoch 683/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1387 - accuracy: 1.0000\n",
      "Epoch 684/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0760 - accuracy: 0.8841\n",
      "Epoch 685/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3541 - accuracy: 0.9312\n",
      "Epoch 686/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1540 - accuracy: 1.0000\n",
      "Epoch 687/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1428 - accuracy: 1.0000 0s - loss: 0.1428 - accuracy: 1.00\n",
      "Epoch 688/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1408 - accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1392 - accuracy: 1.0000\n",
      "Epoch 690/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1378 - accuracy: 1.0000\n",
      "Epoch 691/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1361 - accuracy: 1.0000\n",
      "Epoch 692/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1797 - accuracy: 0.7862\n",
      "Epoch 693/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3080 - accuracy: 0.9565\n",
      "Epoch 694/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1978 - accuracy: 0.9819\n",
      "Epoch 695/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1426 - accuracy: 1.0000\n",
      "Epoch 696/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1396 - accuracy: 1.0000\n",
      "Epoch 697/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1375 - accuracy: 1.0000\n",
      "Epoch 698/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1360 - accuracy: 1.0000\n",
      "Epoch 699/1000\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.1342 - accuracy: 1.0000\n",
      "Epoch 700/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1320 - accuracy: 1.0000\n",
      "Epoch 701/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2264 - accuracy: 0.7283\n",
      "Epoch 702/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2188 - accuracy: 0.9783\n",
      "Epoch 703/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2176 - accuracy: 0.9819\n",
      "Epoch 704/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1401 - accuracy: 1.0000\n",
      "Epoch 705/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1374 - accuracy: 1.0000\n",
      "Epoch 706/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1357 - accuracy: 1.0000\n",
      "Epoch 707/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1339 - accuracy: 1.0000\n",
      "Epoch 708/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1323 - accuracy: 1.0000\n",
      "Epoch 709/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1303 - accuracy: 1.0000\n",
      "Epoch 710/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1617 - accuracy: 0.7826\n",
      "Epoch 711/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2711 - accuracy: 0.9710\n",
      "Epoch 712/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2019 - accuracy: 0.9783\n",
      "Epoch 713/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1400 - accuracy: 1.0000\n",
      "Epoch 714/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1372 - accuracy: 1.0000\n",
      "Epoch 715/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1349 - accuracy: 1.0000\n",
      "Epoch 716/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1329 - accuracy: 1.0000\n",
      "Epoch 717/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1308 - accuracy: 1.0000\n",
      "Epoch 718/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1283 - accuracy: 1.0000\n",
      "Epoch 719/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3490 - accuracy: 0.7790\n",
      "Epoch 720/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1851 - accuracy: 0.9964\n",
      "Epoch 721/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1383 - accuracy: 1.0000\n",
      "Epoch 722/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1337 - accuracy: 1.0000\n",
      "Epoch 723/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1320 - accuracy: 1.0000\n",
      "Epoch 724/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1307 - accuracy: 1.0000\n",
      "Epoch 725/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1295 - accuracy: 1.0000\n",
      "Epoch 726/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1317 - accuracy: 0.9964\n",
      "Epoch 727/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8602 - accuracy: 0.8225\n",
      "Epoch 728/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3267 - accuracy: 0.9348\n",
      "Epoch 729/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3321 - accuracy: 0.9348\n",
      "Epoch 730/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2661 - accuracy: 0.9529\n",
      "Epoch 731/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4147 - accuracy: 0.9203\n",
      "Epoch 732/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1508 - accuracy: 0.9964\n",
      "Epoch 733/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3643 - accuracy: 0.9022\n",
      "Epoch 734/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1372 - accuracy: 1.0000\n",
      "Epoch 735/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1330 - accuracy: 1.0000\n",
      "Epoch 736/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1314 - accuracy: 1.0000\n",
      "Epoch 737/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1299 - accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1283 - accuracy: 1.0000\n",
      "Epoch 739/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1265 - accuracy: 1.0000\n",
      "Epoch 740/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5646 - accuracy: 0.9710\n",
      "Epoch 741/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0957 - accuracy: 0.7065\n",
      "Epoch 742/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2005 - accuracy: 0.9928\n",
      "Epoch 743/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1395 - accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1333 - accuracy: 1.0000\n",
      "Epoch 745/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1304 - accuracy: 1.0000\n",
      "Epoch 746/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1286 - accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1266 - accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1248 - accuracy: 1.0000\n",
      "Epoch 749/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1229 - accuracy: 1.0000\n",
      "Epoch 750/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.7034 - accuracy: 0.7174\n",
      "Epoch 751/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2297 - accuracy: 0.9710\n",
      "Epoch 752/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1461 - accuracy: 0.9964\n",
      "Epoch 753/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1318 - accuracy: 1.0000\n",
      "Epoch 754/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1295 - accuracy: 1.0000\n",
      "Epoch 755/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1272 - accuracy: 1.0000\n",
      "Epoch 756/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1256 - accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1239 - accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1223 - accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2785 - accuracy: 0.8261\n",
      "Epoch 760/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2166 - accuracy: 0.9746\n",
      "Epoch 761/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2033 - accuracy: 0.9783\n",
      "Epoch 762/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3527 - accuracy: 0.9348\n",
      "Epoch 763/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1463 - accuracy: 0.9964\n",
      "Epoch 764/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1318 - accuracy: 1.0000\n",
      "Epoch 765/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1291 - accuracy: 1.0000\n",
      "Epoch 766/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1274 - accuracy: 1.0000\n",
      "Epoch 767/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1256 - accuracy: 1.0000\n",
      "Epoch 768/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1237 - accuracy: 1.0000\n",
      "Epoch 769/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1213 - accuracy: 1.0000\n",
      "Epoch 770/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.3173 - accuracy: 0.7283\n",
      "Epoch 771/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1621 - accuracy: 1.0000\n",
      "Epoch 772/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4183 - accuracy: 0.9203\n",
      "Epoch 773/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2196 - accuracy: 0.9819\n",
      "Epoch 774/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1406 - accuracy: 0.9964\n",
      "Epoch 775/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1276 - accuracy: 1.0000\n",
      "Epoch 776/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1259 - accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1242 - accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1223 - accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1428 - accuracy: 0.9928\n",
      "Epoch 780/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.7457 - accuracy: 0.8442\n",
      "Epoch 781/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1402 - accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1278 - accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1253 - accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1238 - accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1220 - accuracy: 1.0000\n",
      "Epoch 786/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1204 - accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1189 - accuracy: 1.0000\n",
      "Epoch 788/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0180 - accuracy: 0.7971\n",
      "Epoch 789/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1712 - accuracy: 0.9964\n",
      "Epoch 790/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1306 - accuracy: 1.0000\n",
      "Epoch 791/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1247 - accuracy: 1.0000\n",
      "Epoch 792/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1222 - accuracy: 1.0000\n",
      "Epoch 793/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1204 - accuracy: 1.0000\n",
      "Epoch 794/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1834 - accuracy: 0.9819\n",
      "Epoch 795/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2425 - accuracy: 0.7645\n",
      "Epoch 796/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1633 - accuracy: 0.9964\n",
      "Epoch 797/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1819 - accuracy: 0.9928\n",
      "Epoch 798/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1276 - accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1245 - accuracy: 1.0000\n",
      "Epoch 800/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1224 - accuracy: 1.0000\n",
      "Epoch 801/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1205 - accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1595 - accuracy: 0.9928\n",
      "Epoch 803/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9440 - accuracy: 0.7754\n",
      "Epoch 804/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2096 - accuracy: 0.9819\n",
      "Epoch 805/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1287 - accuracy: 1.0000\n",
      "Epoch 806/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1253 - accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1221 - accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1205 - accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1186 - accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1167 - accuracy: 1.0000\n",
      "Epoch 811/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.5423 - accuracy: 0.8877\n",
      "Epoch 812/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1395 - accuracy: 1.0000\n",
      "Epoch 813/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1254 - accuracy: 1.0000\n",
      "Epoch 814/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1215 - accuracy: 1.0000\n",
      "Epoch 815/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1199 - accuracy: 1.0000\n",
      "Epoch 816/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1183 - accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1170 - accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1160 - accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2063 - accuracy: 0.7754\n",
      "Epoch 820/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1443 - accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1260 - accuracy: 1.0000\n",
      "Epoch 822/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1230 - accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1211 - accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1192 - accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.8301 - accuracy: 0.7935\n",
      "Epoch 826/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5917 - accuracy: 0.8261\n",
      "Epoch 827/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1966 - accuracy: 0.9819\n",
      "Epoch 828/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1653 - accuracy: 0.9819\n",
      "Epoch 829/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1983 - accuracy: 0.9855\n",
      "Epoch 830/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7698 - accuracy: 0.8225\n",
      "Epoch 831/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1719 - accuracy: 0.9891\n",
      "Epoch 832/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1304 - accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1243 - accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1224 - accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1204 - accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1180 - accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1155 - accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.0076 - accuracy: 0.7500\n",
      "Epoch 839/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2709 - accuracy: 0.9529\n",
      "Epoch 840/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5704 - accuracy: 0.8623\n",
      "Epoch 841/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1617 - accuracy: 0.9964\n",
      "Epoch 842/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1268 - accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1223 - accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1205 - accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1190 - accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1169 - accuracy: 1.0000\n",
      "Epoch 847/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1150 - accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.8998 - accuracy: 0.8333\n",
      "Epoch 849/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3192 - accuracy: 0.9529\n",
      "Epoch 850/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1325 - accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1198 - accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1176 - accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1159 - accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1140 - accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0025 - accuracy: 0.7935\n",
      "Epoch 856/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2331 - accuracy: 0.9819\n",
      "Epoch 857/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1335 - accuracy: 0.9928\n",
      "Epoch 858/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1233 - accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1196 - accuracy: 1.0000\n",
      "Epoch 860/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1177 - accuracy: 1.0000\n",
      "Epoch 861/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1161 - accuracy: 1.0000\n",
      "Epoch 862/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1139 - accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1160 - accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 1.9520 - accuracy: 0.8551\n",
      "Epoch 865/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1332 - accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1200 - accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1170 - accuracy: 1.0000\n",
      "Epoch 868/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1153 - accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1141 - accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1128 - accuracy: 1.0000\n",
      "Epoch 871/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1112 - accuracy: 1.0000\n",
      "Epoch 872/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1122 - accuracy: 1.0000\n",
      "Epoch 873/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1948 - accuracy: 0.8188\n",
      "Epoch 874/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2503 - accuracy: 0.9601\n",
      "Epoch 875/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1765 - accuracy: 0.9891\n",
      "Epoch 876/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1323 - accuracy: 0.9964\n",
      "Epoch 877/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6208 - accuracy: 0.8877\n",
      "Epoch 878/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1257 - accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1171 - accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1150 - accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1134 - accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1120 - accuracy: 1.0000\n",
      "Epoch 883/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1105 - accuracy: 1.0000\n",
      "Epoch 884/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.8986\n",
      "Epoch 885/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4013 - accuracy: 0.9239\n",
      "Epoch 886/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1415 - accuracy: 0.9928\n",
      "Epoch 887/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1263 - accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1141 - accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1122 - accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1106 - accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1091 - accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1077 - accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1068 - accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1473 - accuracy: 0.7826\n",
      "Epoch 895/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1345 - accuracy: 0.9964\n",
      "Epoch 896/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1129 - accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1106 - accuracy: 1.0000\n",
      "Epoch 898/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1091 - accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1079 - accuracy: 1.0000\n",
      "Epoch 900/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1068 - accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9548 - accuracy: 0.8768\n",
      "Epoch 902/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2936 - accuracy: 0.9384\n",
      "Epoch 903/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1527 - accuracy: 0.9928\n",
      "Epoch 904/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4583 - accuracy: 0.8804\n",
      "Epoch 905/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1785 - accuracy: 0.9819\n",
      "Epoch 906/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1141 - accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1109 - accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1093 - accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1084 - accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1071 - accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1054 - accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.1060 - accuracy: 0.8514\n",
      "Epoch 913/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2097 - accuracy: 0.9819\n",
      "Epoch 914/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5207 - accuracy: 0.8442\n",
      "Epoch 915/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1518 - accuracy: 0.9964\n",
      "Epoch 916/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1143 - accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1108 - accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1091 - accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1077 - accuracy: 1.0000\n",
      "Epoch 920/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1063 - accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1048 - accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1029 - accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.1014 - accuracy: 0.7826\n",
      "Epoch 924/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1348 - accuracy: 0.9964\n",
      "Epoch 925/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1107 - accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1083 - accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1065 - accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1050 - accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.9960 - accuracy: 0.7935\n",
      "Epoch 930/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1621 - accuracy: 0.9891\n",
      "Epoch 931/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1138 - accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1100 - accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1083 - accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1068 - accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1056 - accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.2937 - accuracy: 0.8116\n",
      "Epoch 937/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2001 - accuracy: 0.9891\n",
      "Epoch 938/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1188 - accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1125 - accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1096 - accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1085 - accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1067 - accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1052 - accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1035 - accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4795 - accuracy: 0.7609\n",
      "Epoch 946/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1604 - accuracy: 0.9964\n",
      "Epoch 947/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1127 - accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1091 - accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1070 - accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1058 - accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1043 - accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1028 - accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1011 - accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2754 - accuracy: 0.7464\n",
      "Epoch 955/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2440 - accuracy: 0.9384\n",
      "Epoch 956/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1433 - accuracy: 0.9891\n",
      "Epoch 957/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7184 - accuracy: 0.8406\n",
      "Epoch 958/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2315 - accuracy: 0.9746\n",
      "Epoch 959/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1143 - accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1090 - accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1077 - accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1065 - accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1054 - accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0323 - accuracy: 0.7899\n",
      "Epoch 965/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1526 - accuracy: 0.9964\n",
      "Epoch 966/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1113 - accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1083 - accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1064 - accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1052 - accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1037 - accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1021 - accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3869 - accuracy: 0.9746\n",
      "Epoch 973/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7839 - accuracy: 0.8043\n",
      "Epoch 974/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1386 - accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2662 - accuracy: 0.9819\n",
      "Epoch 976/1000\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.5874 - accuracy: 0.8587\n",
      "Epoch 977/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2797 - accuracy: 0.9420\n",
      "Epoch 978/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1152 - accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1071 - accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1053 - accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1038 - accuracy: 1.0000\n",
      "Epoch 982/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1025 - accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1009 - accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1031 - accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.7936 - accuracy: 0.8406\n",
      "Epoch 986/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1219 - accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1068 - accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1028 - accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1014 - accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1001 - accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0990 - accuracy: 1.0000\n",
      "Epoch 992/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0978 - accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0965 - accuracy: 1.0000\n",
      "Epoch 994/1000\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 1.6320 - accuracy: 0.7572\n",
      "Epoch 995/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1607 - accuracy: 0.9891\n",
      "Epoch 996/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1942 - accuracy: 0.9783\n",
      "Epoch 997/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1227 - accuracy: 0.9964\n",
      "Epoch 998/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1058 - accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1018 - accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1003 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2840c51fcd0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class_2.fit(x_train,y_train_nn, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 7.5838 - accuracy: 0.3277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.583767890930176, 0.32773110270500183]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model to see the results \n",
    "model_class_2.evaluate(x_test, y_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [callbacks.EarlyStopping(monitor='accuracy',patience=20,)\n",
    "    #callbacks.ModelCheckpoint(filepath='my_model.h5',monitor='val_loss',save_best_only=True,)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "9/9 [==============================] - 1s 13ms/step - loss: 5.9627 - accuracy: 0.0797\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.3614 - accuracy: 0.1449\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 5.0918 - accuracy: 0.1304\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.8965 - accuracy: 0.1196\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.6059 - accuracy: 0.1232\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.3270 - accuracy: 0.2065\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.0113 - accuracy: 0.2065\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.6157 - accuracy: 0.3043\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.3592 - accuracy: 0.3152\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.1831 - accuracy: 0.3188\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.0165 - accuracy: 0.3551\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.8357 - accuracy: 0.3696\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.7869 - accuracy: 0.3587\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.6257 - accuracy: 0.3949\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.5717 - accuracy: 0.3551\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 2.4034 - accuracy: 0.4203\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.4364 - accuracy: 0.3949\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.3270 - accuracy: 0.4565\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.2259 - accuracy: 0.4167\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.1685 - accuracy: 0.4457\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.1635 - accuracy: 0.4348\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.0496 - accuracy: 0.4384\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.0929 - accuracy: 0.4493\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.9977 - accuracy: 0.4819\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.9801 - accuracy: 0.4819\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.9861 - accuracy: 0.4384\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.0182 - accuracy: 0.4746\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.8173 - accuracy: 0.4891\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.8862 - accuracy: 0.4855\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.7993 - accuracy: 0.4746\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.7886 - accuracy: 0.4891\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.7544 - accuracy: 0.4891\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6826 - accuracy: 0.5254\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6694 - accuracy: 0.5471\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.7115 - accuracy: 0.5399\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6281 - accuracy: 0.5471\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6359 - accuracy: 0.5471\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6234 - accuracy: 0.5399\n",
      "Epoch 39/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.5619 - accuracy: 0.5870\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.5503 - accuracy: 0.5761\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.5443 - accuracy: 0.5543\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6457 - accuracy: 0.5435\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.5385 - accuracy: 0.5978\n",
      "Epoch 44/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4793 - accuracy: 0.6196\n",
      "Epoch 45/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.5378 - accuracy: 0.5507\n",
      "Epoch 46/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4439 - accuracy: 0.5797\n",
      "Epoch 47/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3459 - accuracy: 0.6232\n",
      "Epoch 48/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.5093 - accuracy: 0.6196\n",
      "Epoch 49/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2821 - accuracy: 0.6812\n",
      "Epoch 50/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4334 - accuracy: 0.6667\n",
      "Epoch 51/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3522 - accuracy: 0.6413\n",
      "Epoch 52/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3304 - accuracy: 0.6703\n",
      "Epoch 53/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3799 - accuracy: 0.6449\n",
      "Epoch 54/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2309 - accuracy: 0.6884\n",
      "Epoch 55/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2876 - accuracy: 0.6884\n",
      "Epoch 56/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1952 - accuracy: 0.6993\n",
      "Epoch 57/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3069 - accuracy: 0.6304\n",
      "Epoch 58/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1580 - accuracy: 0.7428\n",
      "Epoch 59/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4854 - accuracy: 0.6630\n",
      "Epoch 60/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1880 - accuracy: 0.7065\n",
      "Epoch 61/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1051 - accuracy: 0.7645\n",
      "Epoch 62/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1830 - accuracy: 0.7391\n",
      "Epoch 63/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1766 - accuracy: 0.7536\n",
      "Epoch 64/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1066 - accuracy: 0.7645\n",
      "Epoch 65/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1012 - accuracy: 0.7536\n",
      "Epoch 66/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0447 - accuracy: 0.7899\n",
      "Epoch 67/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1631 - accuracy: 0.7101\n",
      "Epoch 68/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0237 - accuracy: 0.7899\n",
      "Epoch 69/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0540 - accuracy: 0.7645\n",
      "Epoch 70/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1014 - accuracy: 0.7717\n",
      "Epoch 71/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9815 - accuracy: 0.8261\n",
      "Epoch 72/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.0936 - accuracy: 0.7717\n",
      "Epoch 73/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.9689 - accuracy: 0.8080\n",
      "Epoch 74/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0133 - accuracy: 0.7645\n",
      "Epoch 75/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1032 - accuracy: 0.7681\n",
      "Epoch 76/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9593 - accuracy: 0.8333\n",
      "Epoch 77/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1061 - accuracy: 0.7645\n",
      "Epoch 78/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7872 - accuracy: 0.9203\n",
      "Epoch 79/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0543 - accuracy: 0.8478\n",
      "Epoch 80/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9435 - accuracy: 0.7971\n",
      "Epoch 81/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8913 - accuracy: 0.8333\n",
      "Epoch 82/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0036 - accuracy: 0.8043\n",
      "Epoch 83/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8766 - accuracy: 0.8551\n",
      "Epoch 84/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8983 - accuracy: 0.8442\n",
      "Epoch 85/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.7242 - accuracy: 0.9203\n",
      "Epoch 86/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9578 - accuracy: 0.8261\n",
      "Epoch 87/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.2746 - accuracy: 0.7790\n",
      "Epoch 88/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6698 - accuracy: 0.9457\n",
      "Epoch 89/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8895 - accuracy: 0.8333\n",
      "Epoch 90/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6219 - accuracy: 0.9457\n",
      "Epoch 91/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9165 - accuracy: 0.8551\n",
      "Epoch 92/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7188 - accuracy: 0.9167\n",
      "Epoch 93/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0969 - accuracy: 0.8188\n",
      "Epoch 94/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6325 - accuracy: 0.9565\n",
      "Epoch 95/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8560 - accuracy: 0.8587\n",
      "Epoch 96/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7894 - accuracy: 0.8587\n",
      "Epoch 97/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6397 - accuracy: 0.9275\n",
      "Epoch 98/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8178 - accuracy: 0.8732\n",
      "Epoch 99/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9297 - accuracy: 0.8877\n",
      "Epoch 100/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7616 - accuracy: 0.9094\n",
      "Epoch 101/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7252 - accuracy: 0.9058\n",
      "Epoch 102/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8451 - accuracy: 0.9058\n",
      "Epoch 103/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7742 - accuracy: 0.9130\n",
      "Epoch 104/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6234 - accuracy: 0.9493\n",
      "Epoch 105/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8038 - accuracy: 0.8732\n",
      "Epoch 106/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7587 - accuracy: 0.8986\n",
      "Epoch 107/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6103 - accuracy: 0.9529\n",
      "Epoch 108/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8929 - accuracy: 0.8696\n",
      "Epoch 109/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8087 - accuracy: 0.8877\n",
      "Epoch 110/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5584 - accuracy: 0.9746\n",
      "Epoch 111/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4892 - accuracy: 0.9891\n",
      "Epoch 112/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1090 - accuracy: 0.7899\n",
      "Epoch 113/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5139 - accuracy: 0.9855\n",
      "Epoch 114/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4629 - accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2610 - accuracy: 0.8297\n",
      "Epoch 116/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5185 - accuracy: 0.9891\n",
      "Epoch 117/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4674 - accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.0254 - accuracy: 0.8696\n",
      "Epoch 119/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.7252 - accuracy: 0.9130\n",
      "Epoch 120/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4978 - accuracy: 0.9891\n",
      "Epoch 121/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7193 - accuracy: 0.9203\n",
      "Epoch 122/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6195 - accuracy: 0.9312\n",
      "Epoch 123/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6139 - accuracy: 0.9529\n",
      "Epoch 124/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4521 - accuracy: 0.9964\n",
      "Epoch 125/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4647 - accuracy: 0.9855\n",
      "Epoch 126/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0335 - accuracy: 0.8261\n",
      "Epoch 127/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4728 - accuracy: 0.9855\n",
      "Epoch 128/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4440 - accuracy: 0.9964\n",
      "Epoch 129/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9694 - accuracy: 0.8732\n",
      "Epoch 130/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6135 - accuracy: 0.9493\n",
      "Epoch 131/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4551 - accuracy: 0.9964\n",
      "Epoch 132/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7982 - accuracy: 0.9239\n",
      "Epoch 133/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7619 - accuracy: 0.9022\n",
      "Epoch 134/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4464 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2840db391c0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class_3 = build_model_class_2()\n",
    "model_class_3.fit(x_train,y_train_nn, epochs = 1000,callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 5.7450 - accuracy: 0.2941\n",
      "29.411765933036804\n"
     ]
    }
   ],
   "source": [
    "#test the model to see the results \n",
    "bce, accc = model_class_3.evaluate(x_test, y_test_nn)\n",
    "print(accc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "9/9 [==============================] - 2s 14ms/step - loss: 5.8980 - accuracy: 0.0906\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.3584 - accuracy: 0.0942\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.0723 - accuracy: 0.1196\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.8153 - accuracy: 0.1268\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.5737 - accuracy: 0.1594\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.0812 - accuracy: 0.2355\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.8084 - accuracy: 0.2899\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.5055 - accuracy: 0.2971\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.2873 - accuracy: 0.2790\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.1765 - accuracy: 0.3080\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.9637 - accuracy: 0.3551\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.8209 - accuracy: 0.3949\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.7238 - accuracy: 0.3514\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.5421 - accuracy: 0.3659\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 2.5980 - accuracy: 0.3732\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 2.4442 - accuracy: 0.3913\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.3679 - accuracy: 0.4203\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.2765 - accuracy: 0.4457\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.2454 - accuracy: 0.4457\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.1629 - accuracy: 0.4601\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.1268 - accuracy: 0.5072\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.0416 - accuracy: 0.4565\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.1442 - accuracy: 0.4384\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.0122 - accuracy: 0.4964\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.0550 - accuracy: 0.4457\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.8453 - accuracy: 0.5290\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.9480 - accuracy: 0.4891\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.9111 - accuracy: 0.5181\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.8378 - accuracy: 0.5290\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.9053 - accuracy: 0.5036\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.8177 - accuracy: 0.5362\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.7439 - accuracy: 0.5688\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.8092 - accuracy: 0.5217\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.6907 - accuracy: 0.5652\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.6620 - accuracy: 0.5761\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.8486 - accuracy: 0.5290\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.7082 - accuracy: 0.5870\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.5651 - accuracy: 0.5870\n",
      "Epoch 39/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.6338 - accuracy: 0.5797\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.5212 - accuracy: 0.6123\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.5532 - accuracy: 0.6232\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4466 - accuracy: 0.6341\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.4968 - accuracy: 0.6304\n",
      "Epoch 44/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.4563 - accuracy: 0.6449\n",
      "Epoch 45/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.5466 - accuracy: 0.6377\n",
      "Epoch 46/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3260 - accuracy: 0.6993\n",
      "Epoch 47/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.4106 - accuracy: 0.6486\n",
      "Epoch 48/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4973 - accuracy: 0.6377\n",
      "Epoch 49/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3892 - accuracy: 0.6594\n",
      "Epoch 50/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3702 - accuracy: 0.6775\n",
      "Epoch 51/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2991 - accuracy: 0.7101\n",
      "Epoch 52/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3348 - accuracy: 0.7210\n",
      "Epoch 53/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3984 - accuracy: 0.7101\n",
      "Epoch 54/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2290 - accuracy: 0.7355\n",
      "Epoch 55/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4051 - accuracy: 0.6667\n",
      "Epoch 56/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2154 - accuracy: 0.7391\n",
      "Epoch 57/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2278 - accuracy: 0.7101\n",
      "Epoch 58/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2309 - accuracy: 0.7536\n",
      "Epoch 59/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.2453 - accuracy: 0.7645\n",
      "Epoch 60/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0310 - accuracy: 0.7935\n",
      "Epoch 61/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2340 - accuracy: 0.7174\n",
      "Epoch 62/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1502 - accuracy: 0.7609\n",
      "Epoch 63/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.2761 - accuracy: 0.7283\n",
      "Epoch 64/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9427 - accuracy: 0.8659\n",
      "Epoch 65/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0537 - accuracy: 0.8080\n",
      "Epoch 66/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2574 - accuracy: 0.7391\n",
      "Epoch 67/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9378 - accuracy: 0.8297\n",
      "Epoch 68/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0721 - accuracy: 0.8261\n",
      "Epoch 69/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0047 - accuracy: 0.8225\n",
      "Epoch 70/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1057 - accuracy: 0.7826\n",
      "Epoch 71/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9277 - accuracy: 0.8442\n",
      "Epoch 72/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0517 - accuracy: 0.7754\n",
      "Epoch 73/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8601 - accuracy: 0.8841\n",
      "Epoch 74/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0907 - accuracy: 0.7971\n",
      "Epoch 75/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9623 - accuracy: 0.8188\n",
      "Epoch 76/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7494 - accuracy: 0.9275\n",
      "Epoch 77/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1718 - accuracy: 0.7754\n",
      "Epoch 78/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9110 - accuracy: 0.8514\n",
      "Epoch 79/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.8302 - accuracy: 0.8986\n",
      "Epoch 80/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0847 - accuracy: 0.8152\n",
      "Epoch 81/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6660 - accuracy: 0.9457\n",
      "Epoch 82/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2367 - accuracy: 0.8080\n",
      "Epoch 83/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6758 - accuracy: 0.9457\n",
      "Epoch 84/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9777 - accuracy: 0.8478\n",
      "Epoch 85/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9098 - accuracy: 0.8841\n",
      "Epoch 86/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8139 - accuracy: 0.8804\n",
      "Epoch 87/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9903 - accuracy: 0.8007\n",
      "Epoch 88/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0444 - accuracy: 0.8442\n",
      "Epoch 89/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6682 - accuracy: 0.9674\n",
      "Epoch 90/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7641 - accuracy: 0.8949\n",
      "Epoch 91/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8809 - accuracy: 0.8768\n",
      "Epoch 92/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7824 - accuracy: 0.8841\n",
      "Epoch 93/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0285 - accuracy: 0.8225\n",
      "Epoch 94/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5560 - accuracy: 0.9891\n",
      "Epoch 95/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2365 - accuracy: 0.8080\n",
      "Epoch 96/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.5854 - accuracy: 0.9855\n",
      "Epoch 97/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9001 - accuracy: 0.8659\n",
      "Epoch 98/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5811 - accuracy: 0.9746\n",
      "Epoch 99/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9154 - accuracy: 0.8623\n",
      "Epoch 100/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5972 - accuracy: 0.9710\n",
      "Epoch 101/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9568 - accuracy: 0.8659\n",
      "Epoch 102/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5902 - accuracy: 0.9638\n",
      "Epoch 103/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4926 - accuracy: 0.9964\n",
      "Epoch 104/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1141 - accuracy: 0.8152\n",
      "Epoch 105/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.5535 - accuracy: 0.9783\n",
      "Epoch 106/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4869 - accuracy: 0.9964\n",
      "Epoch 107/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4739 - accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6689 - accuracy: 0.8188\n",
      "Epoch 109/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6569 - accuracy: 0.9529\n",
      "Epoch 110/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5141 - accuracy: 0.9964\n",
      "Epoch 111/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4763 - accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.9660 - accuracy: 0.8732\n",
      "Epoch 113/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5013 - accuracy: 0.9964\n",
      "Epoch 114/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.9008 - accuracy: 0.8659\n",
      "Epoch 115/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.8500 - accuracy: 0.9203\n",
      "Epoch 116/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4859 - accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4601 - accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4514 - accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.4528 - accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6248 - accuracy: 0.7681\n",
      "Epoch 121/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4994 - accuracy: 0.9928\n",
      "Epoch 122/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4597 - accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4469 - accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4403 - accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4846 - accuracy: 0.9855\n",
      "Epoch 126/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.8515 - accuracy: 0.7717\n",
      "Epoch 127/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6474 - accuracy: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28411978880>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class_4 = build_model_class_2()\n",
    "model_class_4.fit(x_train,y_train_nn, epochs = 1000,callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_class_3(x_training):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',input_shape=(x_training.shape[1],)))\n",
    "    #model.add(layers.Dense(128,kernel_regularizer=regularizers.l1(0.02), activation='relu'))\n",
    "    #model.add(layers.Dense(256,kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "    #model.add(layers.Dense(64,kernel_regularizer=regularizers.l1(0.016), activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Reshape((64,1)))\n",
    "    model.add(layers.Conv1D(64,2,activation='relu'))\n",
    "    model.add(layers.Conv1D(128,4,activation='relu'))\n",
    "    model.add(layers.Conv1D(64,2,activation='relu'))\n",
    "    model.add(layers.Conv1D(64,8,activation='relu'))\n",
    "    model.add(layers.Conv1D(32,4,activation='relu'))\n",
    "    model.add(layers.Conv1D(64,2,activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(21, activation=\"softmax\"))\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x0000028420C59C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002840C7938B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "acc_vals_test = []\n",
    "\n",
    "col_names_class = []\n",
    "#create a model\n",
    "\n",
    "#model_class_4 = build_model_class_3()\n",
    "#model_class_4.fit(x_train,y_train_nn, epochs = 1000,callbacks = callbacks_list)\n",
    "#start at 2 columns.\n",
    "k_val = 2\n",
    "#loop over 30 times for the different k values \n",
    "for i in range(30):\n",
    "    #create selector and get column names \n",
    "\n",
    "    selector = SelectKBest(mutual_info_classif, k=k_val+i)\n",
    "    x_fregress_loop = selector.fit_transform(x, y)\n",
    "    x.columns[selector.get_support(indices=True)]\n",
    "    vector_names_loop = list(x.columns[selector.get_support(indices=True)])\n",
    "    #add the list of columns to the list\n",
    "    col_names_class.append(vector_names_loop)\n",
    "    #test train split\n",
    "    x_train_fr_loop,x_test_fr_loop, y_train_fr_loop,y_test_fr_loop = train_test_split(x_fregress_loop, y, test_size=0.2)\n",
    "    #set the size of the target values.\n",
    "    y_test_nn_loop = to_categorical(y_test_fr_loop,21)\n",
    "    y_train_nn_loop = to_categorical(y_train_fr_loop,21)\n",
    "    #train the model\n",
    "    model_class_4 = build_model_class_3(x_train_fr_loop)\n",
    "    model_class_4.fit(x_train_fr_loop,y_train_nn_loop, epochs = 250,callbacks = callbacks_list,verbose = 0)\n",
    "\n",
    "    #evaluate the model on the training data.\n",
    "    bce, acc = model_class_4.evaluate(x_test_fr_loop,y_test_nn_loop, verbose = 0)\n",
    "     \n",
    "\n",
    "    #add the accuracy for the test values to a list. \n",
    "    acc_vals_test.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3544303774833679, 0.4430379867553711, 0.3417721390724182, 0.37974682450294495, 0.3417721390724182, 0.39240506291389465, 0.3544303774833679, 0.3291139304637909, 0.3544303774833679, 0.4556961953639984, 0.26582279801368713, 0.37974682450294495, 0.37974682450294495, 0.2405063360929489, 0.3291139304637909, 0.29113924503326416, 0.3291139304637909, 0.29113924503326416, 0.3037974536418915, 0.20253165066242218, 0.2405063360929489, 0.3037974536418915, 0.3544303774833679, 0.2405063360929489, 0.26582279801368713, 0.29113924503326416, 0.2531645596027374, 0.2278480976819992, 0.3037974536418915, 0.26582279801368713]\n",
      "best k val acc: 11  with a val of: 45.56961953639984  columns are: ['age', 'Medu', 'Fedu', 'reason', 'traveltime', 'failures', 'higher', 'romantic', 'goout', 'G1', 'G2'] 9\n"
     ]
    }
   ],
   "source": [
    "print(acc_vals_test)\n",
    "acc_highest = np.argmax(acc_vals_test)\n",
    "print(\"best k val acc: \" + str(acc_highest+2),\" with a val of: \"+str(acc_vals_test[acc_highest]*100),\" columns are: \"+str(col_names[acc_highest]),acc_highest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While looping through the different parameters it seems that less is better again. The list is showin many results under 40% and the best being an outlier. It seems that I will nt be improving from here. I have tried with regularizers and dropout but this appears to yield worse results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a knn classifier to predict an accuracy score. \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3277310924369748\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple KNN classifier above has shown a poor accuracy score. The neural network was better performing than this so maybe the network is a bit better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_vals_knn =0\n",
    "col_names_knn = 0\n",
    "current_best_acc = 0\n",
    "best_k_knn = 0 \n",
    "#create a model\n",
    "for j in range(20):\n",
    "    knn_loop = KNeighborsClassifier(n_neighbors=j+2)\n",
    "    #start at 2 columns.\n",
    "    k_val = 2\n",
    "    #loop over 30 times for the different k values \n",
    "    for i in range(30):\n",
    "        #create selector and get column names \n",
    "        selector = SelectKBest(mutual_info_classif, k=k_val+i)\n",
    "        x_fregress_loop = selector.fit_transform(x, y)\n",
    "        x.columns[selector.get_support(indices=True)]\n",
    "        vector_names_loop = list(x.columns[selector.get_support(indices=True)])\n",
    "        #add the list of columns to the list\n",
    "        #col_names_knn.append(vector_names_loop)\n",
    "        #test train split\n",
    "        x_train_knn_loop,x_test_knn_loop, y_train_knn_loop,y_test_knn_loop = train_test_split(x, y, test_size=0.3)\n",
    "        #train the model\n",
    "        knn.fit(x_train_knn_loop, y_train_knn_loop)\n",
    "        y_pred_knn = knn.predict(x_test_knn_loop)\n",
    "        current_acc = metrics.accuracy_score(y_test_knn_loop, y_pred_knn)\n",
    "        #if the current value is better than the best so far then set these values as the best ones\n",
    "        if current_acc > current_best_acc:\n",
    "\n",
    "            acc_vals_knn = current_acc\n",
    "            col_names_knn = vector_names_loop\n",
    "            current_best_acc = current_acc\n",
    "            best_k_knn = j+2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most accurate features for KNN: ['nursery', 'G1', 'G2'] This is: 3 Features with an accuracy: 0.46218487394957986. This is with 9 neighbours.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Most accurate features for KNN: \"+str(col_names_knn)+\" This is: \"+str(len(col_names_knn))+\" Features with an accuracy: \"+str(acc_vals_knn)+\". This is with \"+str(best_k_knn)+\" neighbours.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a82d037cdd8272f0f708c868c5062e44ab6fd9087eec253278f51a0bfe143d9b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('Genomeenvironment': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
